{"meta":{"title":"SFE's blog","subtitle":null,"description":"","author":"SFE","url":"https://sfegsq.github.io"},"pages":[{"title":"","date":"2017-01-12T06:51:28.000Z","updated":"2017-01-12T06:51:28.000Z","comments":true,"path":"about/index.html","permalink":"https://sfegsq.github.io/about/index.html","excerpt":"","text":"关于SFESFE简介SEF是Small Front End的缩写。 Small表示我们一群新人的面貌。我们是一群想搞事情的前端新人。 我们的愿景作为前端新人，一起共同成长，互相督促进步，同时聚在SFE下，一起搞点事情。 大事记 2017.1.9日 小羊建立github组织，我们发愿将SFE建设为一个搞事情的团队。 2017.1.10日 Wilson贡献组织logo 2017.1.11日 在灵儿的筛选下确定组织博客主题 团队成员大大15年武大计算机硕士毕业，目前就职于网易，SFE创始人。 jeri16年武大计算机硕士毕业，大大的同实验室师弟。目前就职于腾讯云。 小羊16年武大软院毕业，目前就职于饿了么。 逸飞头条 小草美团最萌前端开发。 灵儿上海滩一姐，17届华东师范计算机毕业，就职于点评。 Wilson17年华科电信系毕业，就职于腾讯理财通的一只萌新。"},{"title":"","date":"2017-01-09T10:35:58.000Z","updated":"2017-01-09T10:35:58.000Z","comments":true,"path":"project/index.html","permalink":"https://sfegsq.github.io/project/index.html","excerpt":"","text":"团队项目待填充"}],"posts":[{"title":"测试","slug":"测试","date":"2017-01-09T10:36:49.000Z","updated":"2017-01-12T06:26:21.000Z","comments":true,"path":"2017/01/09/测试/","link":"","permalink":"https://sfegsq.github.io/2017/01/09/测试/","excerpt":"","text":"测试测试一下","categories":[],"tags":[{"name":"测试","slug":"测试","permalink":"https://sfegsq.github.io/tags/测试/"}]},{"title":"聊聊这一年从技术麻瓜开始的奋斗史","slug":"聊聊这一年从技术麻瓜开始的奋斗史","date":"2016-12-14T01:03:57.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/12/14/聊聊这一年从技术麻瓜开始的奋斗史/","link":"","permalink":"https://sfegsq.github.io/2016/12/14/聊聊这一年从技术麻瓜开始的奋斗史/","excerpt":"技术麻瓜的大三狗，从初创公司唯一一个前端，到独自北漂在去哪儿进行寒假实习，最后南下腾讯暑期实习并成功转正。作为一只野生的程序员，经历了一年的野蛮生长。将这一年的经历记录下，回味这一年的成长。 背景介绍华科，通信工程专业学渣一枚，目前大四。","text":"技术麻瓜的大三狗，从初创公司唯一一个前端，到独自北漂在去哪儿进行寒假实习，最后南下腾讯暑期实习并成功转正。作为一只野生的程序员，经历了一年的野蛮生长。将这一年的经历记录下，回味这一年的成长。 背景介绍华科，通信工程专业学渣一枚，目前大四。大三暑假开始决定工作，便开始了一只技术麻瓜的技术学习史。想过做产品(没有项目跟进，不容易入门)，去实验室跟着看过大数据(门槛高，毕业的时候也难以有所小成去找工作)，最后于前后端之间选择了前端。一方面之前接触过一点点前端知识，另一方面，前端更有趣容易入门。而作为一只大三狗，学校技术团队是不会收留的。便开始了一只野生程序猿的修养。自己看书看资料看慕课的教学。 初入前端 2015.9.20 - 2015.10.20关键词： 校园创业团队 美食说 第一个项目 作为一个大一写个C代码 hello world 一个分号就能卡半个小时的我来说。入门也是非常痛苦的一件事，特别还没有组织，没人可以请教。于是加了一些群，扩展下信息的来源。在一个群里认识了一个研究生学长。研究生学长问我有没有团队，我说没有，他便欣然邀请我加入(当然事后证明这个学长还是满坑的)。学长在做一个”美食说“的项目，让我做商家管理后台。这时候也是第一次有人告诉我用Bootstrap(野生的什么都需要自己去探索)。一边我先自己买了本《深入理解Bootstrap》开始学习，另外一边他在催设计给图。 从2015.10.5号开始宅在寝室里开始coding，中间有不懂的却也没有人可以问，只能百度。问学长后台数据交互呢，却叫我先做了，把URL预留好就行（最后，后台也没有人写）。到10月末终于把设计稿都实现了。便把代码提交给他了，后来一直没有了回音。 虽然我知道这个项目水，但是我也知道我这样的菜鸡需要有项目的实践才能真正动起来。不然始终在看书，看视频的过程中。通过这个项目也算初步实践了。 美食说 github仓库地址 初创公司 2015.11.4 - 2015.12.14关键词： 聚美医 初创公司 唯一一个前端 找实习结束”美食说“项目之后，我知道了自己不足，继续资料学习，又开始脱产看起了书，把《深入理解Bootstrap》又重新看了一遍，仔细的学习其中组件，栅格，响应式等原理，学习其代码风格。 一两星期的学习之后，渐渐觉得学习进步的速度不够快。我开始打起了找家公司实习的想法。 先去了光谷创业街溜了溜，看到了很多公司，但是也不知道以何种方式去拿到实习机会，也有些胆怯。于是，回来后先看一些招聘网站。不管招不招实习，有邮箱就丢简历过去。当然都没有回音。这次不得不说起我加的一个前端群”小前端“，有次有人发了个招聘广告，我加了他好友，还没有主动询问，他却先向我问好，我和他说了情况，表示想找个实习。他说可以过来聊聊。约了第二天下午就过去了。 实习面试第二天下午怀揣着惴惴不安的心到了那家公司。却没想到对方直接就把我当面试的，就来面试我了。面我的人问了我做过什么项目，我就提到我之前做的项目，问我Bootstrap和jquery，还有一些栅格化，响应式布局的原理，好在之前都学习过。整个面试持续了近1小时，表示可以提供实习机会，想想已经11月了，再拖下去也不一定能够找到其他实习，也怕自己打消了继续找实习的勇气。于是答应了来实习，一周3天以上。 开始实习之后上班，每天7点多就起来了，在学习吃完早饭走到公司，往往第一个到达等待10-20分钟有人来开门。下班后，回学校吃完饭拖着上完一天班疲惫的身体，继续去自习室看书补充知识。 第一天上班，先是紧张而激动的整了整自己的工位，一边担心着自己太水而没办法完成任务。leader给我看了一个竞品的主页，让我用bootstrap做个静态页面出来。做了两天做好了(很easy的切图)，但是一直没有得到素材，产品那边的支持。便一直搁在那里。之后才了解到在公司，我是”唯一一个前端“，真是尴尬，我这样的水逼，真希望有个人来带我。公司就一个后台，一个安卓一个ios。我也就切好图就丢给后台老大了。当然，我也想说不是应该前后端分离么？就这么丢过去了？当然，我这样的水逼当时也只敢想想，我也不知道自己能否胜任。每天的工作内容就是设计切好图，把PSD丢给我，然后我把图上传到”标你妹“上，然后获得各个字体的大小，间距等等信息，然后开始制作移动端的页面。(现在回过头来看，那不应该是基于微信的网站么，但对我来说还是切图而已)。当然，也不是说切图就没什么好学习的。对于我这样一个新人，也是很好的熟悉前端的过程。在这过程中，我也去尝试了各种各样的CSS新属性，也学习了如何进行布局，也查阅了如何自定义radio的样式等等。 离职因为期末开始月的来临，越来越没法保证实习时间了。很多时候只能在学校切好图再丢过去。一边应付目不暇接的考试，一边还要切图真是考验人的意志。再加上一直拖着不发我的工资，百般催促之下也没有像一开始答应的那样付薪酬，导致我也不愿意继续去上班了。就选择了结束这段实习。同时，也是为自己去找寒假实习腾出了时间。github仓库 聚美医的实习总结 第一篇博客 2015.12.22日因为是一个野生的程序猿，所以格外注重扩展信息来源，于是经常逛社区，论坛，看博客。也知道大家推崇写博客，充实github，用google不用百度等等。为了尽力让自己更快的成长，我也尝试去写博客。 第一次博客是在 segmentfault 上发布的。源于我使用CSS3的新属性 Calc ,而android机器上这个属性兼容性很差，leader就让我去修复，然后我就不断就这个问题google，然后在 stackoverflow 上看到许多相关的东西，了解到另外一个新属性 box-sizing 也可以用来进行流式布局。 最后在 SF 发布了这篇文章 calc 与 box-sizing 的替代，审核了好几天，终于通过了，开心。本以为就此结束了，没想到SF的官方微博也转载了这篇文章一下帮我这条动态获得了6500的阅读量，之后也有另外几个论坛进行转载。这个事情很大的鼓舞了我继续写博客。 北漂去哪儿 2016.1.14 - 2016.2.24再起航结束了第一段实习之后，自知能力还远远不够，而明年3-4月份。BAT就要开始内推了。相比起学校那些从大一就开始专业搞编程的人来说，自觉还是差的太远了，为了实现弯道超车(当然也只是想追赶而已，知道还是存在许多差距的），决定在寒假前试试去北京或者上海找家大公司实习 —— 出来混的欠下的债都得还。 投简历，电面在寒假前又开始拼命投简历，从各个招聘网站和官网找邮箱丢简历，大部分都没有回音。当然也不出乎意料，毕竟寒假实习太非主流了，时间又短。投的的简历中，最后只有 头条 给了个电话面试的机会。2015.12.18 日接到一次电话面试，老激动了。无奈当时基础太渣，只知道怎么使用Bootstrap和jQuery。没有系统的去了解原生Javascript。于是一问就懵逼，不知道JS有哪几种基本变量类型等等基础知识。毕竟还年轻，当时也不知道有面经这种东西。所以不出意外再也没接到电话。 接下来，就要说到我的第一位贵人了，”小前端“的群里的”海哥“发去哪儿招寒假纯实习的广告。我便丢了份简历过去。因为本身也没指望着转正，觉得非常合适,能去大公司看看就太好了。2015.12.23 号晚上，去哪儿打了一次电话过来。又让我激动了一次，这次主要问的jQuery，回答的不怎么样，以至于最后面试官说，刚才我问你的几个都回答的不是很好，那你自己说说你知道的一些东西，这个时候平常看的书没白看。。。之前因为是野生的，就自己不断从图书馆借书看，囫囵吞枣的感觉。但也是记住了不少东西。这次回答的不错，面试官回答了一句，你旁边没有人吧？ 得到一丝认可的我，开心了一会。 当天下午，因为害怕找不到北京上海的实习，我去了一家武汉校友创办的企业面试，海豚浏览器，做了份试卷，先是技术过来面，然后产品最后HR，总共面了3面。让我回去等消息，两个星期内答复。 2015.12.25号圣诞节这一天早上，突然收到北京的来电，没想是去哪儿的HR，直接沟通发放实习offer的事情。真是圣诞老人送的一份大礼。(隔了几天也拿到了海豚的offer，拒绝了) 北漂初到北京期末考试结束，提前做完软件课设(写个课设系统，想锻炼原生JS的能力，写了一周，每天早上8点写到晚上1点多)，答辩前一天晚上调试到4点多，早上9点多去答辩，坐上了下午到北京的飞机。拖着本已被考试和课设项目拖的半垮的身子就过去了。周三晚上到北京，周四一早去报道，发现喉咙哑了，以为是雾霾太大喉咙发炎，leader说是空气太干了，涨知识了。第一天领了下机器，配了下环境，看了下文档。晚上回到住的地方，半夜突然又急性肠炎了。找了个药店买了点药，想想当时也是心酸。周末租了一个单间好好睡了一大觉，整个身体都恢复过来了。 工作生活因为是实习生，早出晚归，好好表现我还是知道的。第一次到大公司，熟悉开发流程，各种协同工作的流程。报道几天后，开始负责了一些小的需求和BUG的修复。因为实习时间较短的问题。一直也负责着这样的事情。在实习的时候，学会了使用fiddler本地调试，fekit构建代码，angular框架，git版本管理，断点调试等知识，同时利用空余时间阅读业务中的一些代码，了解整个运行过程，这一点还是非常有帮助的，阅读好的代码本身就是一种极佳的学习方式。空余时间，看看书，写写博客记录自己工作中遇到的问题。实习时间过的很快，一转眼就到了过年放假时间。 独自度过第一个年本身实习时间就短，过年只放7天回去的话又麻烦又浪费时间，便决定留在北京过年。老惨了，去哪哪关门，只有除夕夜下午提前吃了顿大餐，然后就是吃外卖~ 离职因为知道BAT这样的大公司，3-4月份就开始暑期实习的内推了。并且会问许多基础知识。于是，也正好乘着开学的时间结束去哪儿的实习，回来开始准备。去哪儿期间写的博文 ShellScript编程小结 正则表达小结与小知识点集锦 webpack替代fekit的折腾小记 第一个个人项目2.10号 正月初三，玩了几天后，便来公司继续学习，为了学以致用，实现自己的一个idea。kindle文字伴侣 github仓库kindle文字伴侣 网址传送门项目立意：kindle阅读中标记会产生一个mycliping.txt文件，每次都一小段一小段复制到诸如印象笔记， 为知笔记里。相信技术改变生活，本项目就是帮助自动解析mycliping.txt文本。 本是为了自己私用，有一次发到知乎上，结果收到很多人的赞赏，哈哈。知乎传送门:Kindle标注的重点和笔记可以导出吗？（当然，因为没有设计的原因，丑是丑了些） 南下腾讯 2016.6.18 - 2016.9.9关键词： 七次面试 计算机基础 php node 准备面试回来之后以考研的状态到图书馆里学习，早出晚归。过了一遍《JavaScript高级程序设计》，《CSS权威指南》，《数据结构》，《http权威指南》，《计算机网络》《微机原理》等书。作为一个学渣，之前计算机基础也是弱的不行。回过头来，自己再学习也是坎坷的。这次也学乖了，知道去网上参考许多面经，并且针对性的补全相应的知识。 之前问过一位学长:”面经的很重要么？”回答曰：”面经的重要程度就像你大学考前复习一样”。 面试内推又是“小前端”群里的武大学长“jeri”帮我内推的。腾讯的内推面试电话面试了4次，估计是流转了几个团队，但是因为有两次公司实习的经历，所以被几个团队从简历池中捞起了。当然当时也是不知道这个流程的。本以为面了4次该发offer了吧，或者拒掉我。结果让我周末去深圳现场面试，还好心理足够强大。去现场两轮技术一轮hr下来，拿到了offer，终于实现了自己的目标。面试的一些总结：FrontEndInterview github仓库面试期间的一些阅读笔记 网络相关 数据结构 开始腾讯的实习生活能够到腾讯这样的顶级公司实习自然是非常欣喜的。当然我也知道竞争也同样存在，继续好好表现，多多学习提高自己的能力是必须的。才去几天，就被leader拉去问：“写过PHP么？”，一脸懵逼的说没有–，但看过点(看过两本书，但是没有实践过)。leader继续说：“没事，这个简单”。就把我拉去开始写PHP的内部系统了。当然，其实我也很乐意，作为一个前端儿，一直被没有后端经历困惑住，许多东西只能停留在前端层面，一旦涉及到后端就一脸懵逼了。之后，另一个leader又让我负责迁移一个node的系统，艾玛，文档啥的都没有，还有一堆我不清楚的东西。也只能硬着头皮上。(我猜之所以给我做，其中一个原因是我带了本《深入浅出node.js》吧)。最后也做下来了，在这个过程中也仔细了解了一下express，以及node开发过程中的调试，线上部署的工具等等，收货颇多。PHP应用CI框架，在工作之余也仔细看了看其文档并简单分析了下其运行原理与流程。 并且运用早晚时间，浏览公司内网的帖子，扩展视野的同时，也解决了一些我过往存在的技术困惑。实习期间，前端方面的工作量倒不是很大，自主的阅读了下组内的前端模块代码，并了解了下代码组织方式与代码执行逻辑。整个实习下来，在加深前端认知的同时，帮我补足了后端这块空缺。 腾讯实习期间写的博文 阅读sea.js源码小结 深入阅读gulp源码小结 前后端交互过程中的编码 漫话密码存储 漫谈Web缓存 认识前端安全 最后大三这一年，过得最为辛苦，也是我成长最快的一年。总结这一年以来的成长史。有几点特别的经验。 想要成为什么样的人，先到这些人中去，去听，去看，去学(逛社区，看论坛，了解业内在发生些什么，知道自己怎么做才能和那些人一样优秀) 建立更多的连接(记得一本书上说过，当你想走出现有的生活的时候，给你打开思路的往往是那些微弱连接的人) 知道什么好，就去做。(诸如知道写博客是个好习惯，就好好去写) 过往的一年里，座右铭是《孙子兵法》第4篇《军形》中的不可胜在己，可胜在敌。故善战者，能为不可胜，不能使敌之必可胜。 故曰：胜可知，而不可为。 故善战者，立于不败之地，而不失敌之败也。 前几天突然产生了一个更有趣的想法，更适合作为我的座右铭。致力于做一个有故事的人。小时候听爸爸说他的故事，长大了去创造自己的故事；当爸爸后有故事可讲；老了以后有故事可以回味。","categories":[{"name":"过往历程","slug":"过往历程","permalink":"https://sfegsq.github.io/categories/过往历程/"}],"tags":[{"name":"前端","slug":"前端","permalink":"https://sfegsq.github.io/tags/前端/"},{"name":"实习","slug":"实习","permalink":"https://sfegsq.github.io/tags/实习/"}]},{"title":"前端也该了解的一些后端知识","slug":"前端也该了解的一些后端知识","date":"2016-12-13T09:32:10.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/12/13/前端也该了解的一些后端知识/","link":"","permalink":"https://sfegsq.github.io/2016/12/13/前端也该了解的一些后端知识/","excerpt":"前言作为一个有追求的前端，在学有余力的同时,不应该把自己仅仅局限于前端的世界中的。而后端的知识是与前端工作最密切相关的一部分内容，多了解些后端的知识也是大有裨益的。 本文简单叙述了三种构建大型架构的必备知识。也是我做前端这么久以来，一直想知道的如何突破现有的性能瓶颈做到高并发，高性能，高可靠。文中如有错误，欢迎指正。 优化数据库 负载均衡 缓存技术","text":"前言作为一个有追求的前端，在学有余力的同时,不应该把自己仅仅局限于前端的世界中的。而后端的知识是与前端工作最密切相关的一部分内容，多了解些后端的知识也是大有裨益的。 本文简单叙述了三种构建大型架构的必备知识。也是我做前端这么久以来，一直想知道的如何突破现有的性能瓶颈做到高并发，高性能，高可靠。文中如有错误，欢迎指正。 优化数据库 负载均衡 缓存技术 优化数据库对于使用数据库的Web站点来说，数据库性能关系整个web应用的性能，如果数据库性能不佳，其他的优化工作也是徒劳无功。所以优化数据库性能，对提高整个web应用的效率有着举足轻重的作用。 1、 表的设计要规范，即要符合数据库设计范式。2、 适当建立索引，在频繁作为检索条件，更新较少的字段上建立索引，以提高查询速度。3、 分表查询，有水平分割、垂直分割。4、 读写分离，读(read)、写(create、update、delete)。5、 建立存储过程。 这里特别想提到的是拆分表格这一点。最简单的诸如，根据用户ID的最后1位的数字将其拆分成10个表，即 0，1，2，3，4，5，6，7，9。这种平行的拆分方式，一方面，可以解决单个数据库并发连接数的限制，另外一方面可以控制单表的大小。很有效的一种优化方式，特别在于解决高并发的需求。 负载均衡单台Web服务器处理能力有限，单台服务器承受的压力达到极限时，需要有更多的服务器分担工作，我们需要想办法将流量合理分配到更多的服务器上。任何的负载均衡技术都要想办法建立某种一对多的映射机制: 一个请求的入口映射到多个处理请求的节点，从而实现分而治之（Divide and Conquer）。这种映射机制使得多个物理存在对外体现为一个虚拟的整体，对服务的请求者屏蔽了内部的结构。采用不同的机制建立映射关系，可以形成不同的负载均衡技术，常见的包括： CDN HTTP重定向 基于DNS的轮询解析 反向代理服务器 详细可以参考 亿级Web系统搭建——单机到分布式集群 缓存随着网络的发展，数据越来越多，从而导致运算的压力越来越大，为了解决这一问题，就需要合理分级计算资源，充分利用已有资源。缓存的工作实际上计算资源的合理分配。 缓存 (Cache) 原意是指可以进行高速数据交换的存储器。当CPU处理数据时，先到 Cache 中寻找，如果数据因之前的操作已经读取而被暂存其中，就不需要再从随机存取存储器中读取数据了。现在缓存的概念已被扩充,凡是位于速度相差较大的两种介质之间，用于协调两者数据传输速度差异的结构，均可以称之为 Cache 。在 web 世界，理论上每一层都可以被缓存。以PHP应用为例： 底层有CPU缓存，磁盘文件系统缓存 数据库层有 Table Cache,Query Cache Apache和Ngix的缓存 应用程序代码级别的Smarty实现的文件缓存 基于HTTP协议和浏览器自身实现的浏览器缓存 基于NoSQL系统的缓存(redis, memcached) 结语上述三种技术手段，是构建大型网络应用的必备技术，展开来每点的水都很深。而作为一个前端儿，许多技术可能无法在工程项目中亲自去实践，也只能从书，讲座，博文中学习了。 最后推荐一本PHP的书籍《PHP核心技术与最佳实践》，确实如同作者在其书中前言所述，没有讲述HTML,CSS,JS基础，也没有讲PHP语法基础，而是专注于web开发技术的最前沿，深入浅出，探讨高并发大流量的架构。 非常棒的一本进阶书籍。","categories":[{"name":"性能","slug":"性能","permalink":"https://sfegsq.github.io/categories/性能/"}],"tags":[{"name":"PHP","slug":"PHP","permalink":"https://sfegsq.github.io/tags/PHP/"}]},{"title":"H5数据推送","slug":"H5数据推送","date":"2016-12-06T07:15:16.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/12/06/H5数据推送/","link":"","permalink":"https://sfegsq.github.io/2016/12/06/H5数据推送/","excerpt":"前言众所周知，AJAX的出现是前端快速发展的一个标志，同时也是前后端得以分离的重要基础。作为一个C/S网络的web系统，网络通信在发挥着举足轻重的作用。大部分的场景下，我们是主动触发AJAX去调取后端数据，但是总有那么些场景是后端数据更新了再推送给前端。本文则试着和读者一起对这个数据推送的需求进行技术方案的探究。 首先，列一个常用可选的技术清单 websocket SSE(Server-Sent Event) 轮询(长轮询)","text":"前言众所周知，AJAX的出现是前端快速发展的一个标志，同时也是前后端得以分离的重要基础。作为一个C/S网络的web系统，网络通信在发挥着举足轻重的作用。大部分的场景下，我们是主动触发AJAX去调取后端数据，但是总有那么些场景是后端数据更新了再推送给前端。本文则试着和读者一起对这个数据推送的需求进行技术方案的探究。 首先，列一个常用可选的技术清单 websocket SSE(Server-Sent Event) 轮询(长轮询) 数据推送数据推送是由服务端选择向客户端发送新数据。当数据源有新数据时，服务端能立刻将它发送给一个或多个客户端，而不用等客户端来请求。 数据推送有两种替代方案：无更新方案和数据拉取方案。 数据拉取和数据推送的功能目标是一致的:让用户看到最新的数据。但数据推送有一些优势，即更低的延迟。但是在数据拉取的方式中，权衡会让你很纠结，要缩短延迟就要提高轮询的频次，要节省带宽和连接就要降低轮询的频次。 技术分析websocketwebSocket是html5新引入的技术，允许后台随时向前端发送文本或者二进制消息，WebSocket是一种全新的协议，不属于http无状态协议，协议名为”ws”，这意味着一个websocket连接地址会是这样的写法：ws://wilsonliu.cn:8080/webSocketServer。ws不是http，所以传统的web服务器不一定支持，需要服务器与浏览器同时支持,WebSocket才能正常运行，目前的支持还不普遍，需要特别的web服务器和现代的浏览器。 123456789// 在这里略去服务端实现,着重于比较客户端。 客户端实现可参考[参考链接2]var ws = new WebSocket(\"ws://localhost:4000\"); // 这里新建一个websocket连接，ws此时是一个websocket句柄ws.onopen = function()&#123; // 常见的前端事件回调 console.log(\"握手成功\");&#125;;ws.onmessage = function(e)&#123; // 事件有 open,close,error,message console.log(\"信息:\" + e.data); // 输出后台返回的信息&#125;;ws.send(\"测试\") SSESSE 是 HTML5 的 Server-Sent Events缩写，服务器端发送的事件。网页自动获取服务器端的数据更新。之前网页获取服务器端更新的数据是需要先想服务器发送情况，确定是否有数据变更，然后获取，而SSE是服务器 一旦有数据更新就主动向网页发送数据。 1234567891011121314// 前端 var es = new EventSource(\"sse.php\"); // 建立连接,EventSource只能单向通信，没有send函数 es.addEventListener(\"message\", function(e)&#123; // EventSource有3个事件， open,error,message console.log(e.data); &#125;,false);// php&lt;?phpheader(\"Content-Type: text/event-stream\"); while(true)&#123; echo \"data:\".date(\"Y-m-d H:i:s\").\"\\n\\n\"; @ob_flush();@flush(); // 立即将数据返回给客户端，而不是缓冲起来成批发送 sleep(1); &#125; 轮询轮询：客户端定时向服务器发送Ajax请求，服务器接到请求后马上返回响应信息并关闭连接。优点：后端程序编写比较容易。缺点：请求中有大半是无用，浪费带宽和服务器资源。 123456789function poll() &#123; setTimeout(function() &#123; $.get(\"/path/to/server\", function(data, status) &#123; console.log(data); // 发起下一次请求 poll(); &#125;); &#125;, 10000);&#125; 长轮询：客户端向服务器发送Ajax请求，服务器接到请求后hold住连接，直到有新消息才返回响应信息并关闭连接，客户端处理完响应信息后再向服务器发送新的请求。优点：在无消息的情况下不会频繁的请求，耗费资源小。缺点：服务器hold连接会消耗资源，返回数据顺序无保证，难于管理维护。 SSE与websocket的对比websocket是一种更为复杂的服务端实现技术，但它是真正的双向传输技术，既能从服务端向客户端推送数据，也能从客户端向服务端推送数据。websocket和SSE的浏览器支持率差不多。 SSE优势。 既存基础设施优势：不需要添加任何新组件，也不需要新建虚拟机，弄一个新的IP或新的端口号。 服务端更加简洁 文本协议，更方便调试 websocket优势 双向数据流(使用SSE时，一般通过独立的AJAX请求从客户端向服务端传送数据) 参考资料 知乎:WebSocket 是什么原理？为什么可以实现持久连接? 细说websocket - php篇 传统轮询、长轮询、服务器发送事件与WebSocket","categories":[{"name":"前端","slug":"前端","permalink":"https://sfegsq.github.io/categories/前端/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"}]},{"title":"JavaScript函数式编程","slug":"JavaScript函数式编程","date":"2016-12-04T05:10:35.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/12/04/JavaScript函数式编程/","link":"","permalink":"https://sfegsq.github.io/2016/12/04/JavaScript函数式编程/","excerpt":"摘要以往经常看到”函数式编程“这一名词，却始终没有花时间去学习，暑期实习结束之后一直忙于边养老边减肥，81天成功瘦身30斤+ ，开始回归正常的学习生活。便在看《JavaScript函数式编程》这本书，以系统了解函数式编程的知识。本文试图尽可能系统的描述JavaScript函数式编程。当然认识暂时停留于本书介绍的程度，如有错误之处，还请指正。","text":"摘要以往经常看到”函数式编程“这一名词，却始终没有花时间去学习，暑期实习结束之后一直忙于边养老边减肥，81天成功瘦身30斤+ ，开始回归正常的学习生活。便在看《JavaScript函数式编程》这本书，以系统了解函数式编程的知识。本文试图尽可能系统的描述JavaScript函数式编程。当然认识暂时停留于本书介绍的程度，如有错误之处，还请指正。注：本书采用的函数式库Underscore。一下部分代码运行时，需引入Underscore。 函数式编程简介我们用一句话来直白的描述函数式编程： 函数式编程通过使用函数来将值转换成抽象单元，接着用于构建软件系统。 概括的来说，函数式编程包括以下技术 确定抽象，并为其构建函数 利用已有的函数来构建更为复杂的抽象 通过将现有的函数传给其他函数来构建更加复杂的抽象 注：JavaScript并不仅限于函数式编程语言，以下是另外3种常用的编程方式。 命令式编程： 通过详细描述行为的编程方式 基于原型的面向对象编程： 基于原型对象及其实例的编程方式 元编程：对JavaScript执行模型数据进行编写和操作的编程方式函数式编程的一些特性纯函数纯函数坚持以下属性（坚持纯度的标准不仅将有助于使程序更容易测试，也更容易推理。） 其结果只能从它的参数的值来计算 不能依赖于能被外部操作改变的数据 不能改变外部状态不变性 —— 没有副作用所谓”副作用”（side effect），指的是函数内部与外部互动（最典型的情况，就是修改全局变量的值），产生运算以外的其他结果。函数式编程强调没有”副作用”，意味着函数要保持独立，所有功能就是返回一个新的值，没有其他行为，尤其是不得修改外部变量的值。 不修改状态上一点已经提到，函数式编程只是返回新的值，不修改系统变量。因此，不修改变量，也是它的一个重要特点。在其他类型的语言中，变量往往用来保存”状态”（state）。不修改变量，意味着状态不能保存在变量中。函数式编程使用参数保存状态，最好的例子就是递归。下面的代码是一个将字符串逆序排列的函数，它演示了不同的参数如何决定了运算所处的”状态”。1234567function reverse(string) &#123; if(string.length == 0) &#123; return string; &#125; else &#123; return reverse(string.substring(1, string.length)) + string.substring(0, 1); &#125; &#125; 函数是一等公民“一等”这个术语通常用来描述值。当函数被看作“一等公民”时，那它就可以去任何值可以去的地方，很少有限制。比如数字在Javascript里就是一等公民，同程作为一等公民的函数就会拥有类似数字的性质。123456789101112var fortytwo = function()&#123;return 42&#125; // 函数与数字一样可以存储为变量var fortytwo = [32, function()&#123;return 42&#125;] // 函数与数字一样可以存储为数组的一个元素var fortytwo = &#123;number: 32, fun: function()&#123;return 42&#125;&#125; // 函数与数字一样可以作为对象的成员变量32 + (function()&#123;return 42&#125;) () // 函数与数字一样可以在使用时直接创建出来// 函数与数字一样可以被传递给另一个函数function weirdAdd(n, f)&#123; return n + f()&#125;weirdAdd(32, function()&#123;return 42&#125;)// 函数与数字一样可以被另一个函数返回return 32;return function()&#123;return 42&#125; Applicative编程Applicative编程是特殊函数式编程的一种形式。Applicative编程的三个典型例子是map,reduce,filter 函数A作为参数提供给函数B。 (即定义一个函数，让它接收一个函数，然后调用它) 1234567891011_.find([\"a\",\"b\",3,\"d\"], _.isNumber) // _.find与_.isNumber都是Underscore中的方法// 自行实现一个Applicative函数function exam(fun, coll) &#123; return fun(coll);&#125;// 调用exam(function(e)&#123; return e.join(\",\")&#125;, [1,2,3])// 结果 ”1,2,3“ 高阶函数定义:一个高阶函数应该可以执行以下至少一项操作。 以一个函数作为参数 返回一个函数作为结果 以其他函数为参数的函数关于传递函数的思考： max，finder，best1234// max是一个高阶函数var people = [&#123;name: \"Fred\", age: 65&#125;, &#123;name: \"Lucy\", age: 36&#125;];_.max(people, function(p) &#123; return p.age &#125;); //=&gt; &#123;name: \"Fred\", age: 65&#125; 但是，在某些方面这个函数是受限的，并不是真正的函数式。具体来说，对于_.max而言,比较总是需要通过大于运算符（&gt;）来完成。 不过，我们可以创建一个新的函数finder。它接收两个函数：一个用来生成可比较的值，而另一个用来比较两个值并返回当中的”最佳“值。12345678function finder(valueFun, bestFun, coll) &#123; return _.reduce(coll, function(best, current) &#123; var bestValue = valueFun(best); var currentValue = valueFun(current); return (bestValue === bestFun(bestValue, currentValue)) ? best : current; &#125;);&#125; 在任何情况下，我们现在都可以用finder来找到不同类型的”最佳“值：1234567891011121314finder(function(e)&#123;return e.age&#125;, Math.max, people) // =&gt; &#123;name: ”Fred\", age: 65&#125;finder(function(e)&#123;return e.name&#125;, function(x, y)&#123; return (x.charAt((0) === \"L\") ? x : y),people&#125;) // 偏好首字母为L的人// =&gt; &#123;name:\"Lucy\", age: 36&#125;``` **缩减一点**函数`finder`短小精悍，并且能按照我们预期来工作，但为了满足最大程度的灵活性，它重复了一些逻辑。```Javascript// 在 finder函数中return (bestValue === bestFun(bestValue, currentValue)) ? best : current;// 在输入的函数参数中return (x.charAt((0) === \"L\") ? x : y 你会发现上述两者的逻辑是完全相同的。finder的实现可以根据以下两个假设来缩减。 如果第一个参数比第二个参数“更好”，比较最佳值的函数返回为true 比较最佳值的函数知道如何“分解”它的参数 在以上假设的基础下，我们可以实现一个更简洁的best函数。12345678function best(fun, coll) &#123; return _.reduce(coll, function(x, y) &#123; return fun(x, y) ? x : y; &#125;);&#125;best(function(x,y) &#123; return x &gt; y &#125;, [1,2,3,4,5]);//=&gt; 5 关于传递函数的更多思考：重复，反复和条件迭代首先，从一个简单的函数repeat开始。它以一个数字和一个值为参数，将该值进行多次复制，并放入一个数组中：123456function repeat(times, VALUE) &#123; return _.map(_.range(times), function() &#123; return VALUE; &#125;);&#125;repeat(4, \"Major\");//=&gt; [\"Major\", \"Major\", \"Major\", \"Major\"] 使用函数，而不是值通过将参数从值替换为函数，打开了一个充满可能性的世界。12345678function repeatedly(times, fun) &#123; return _.map(_.range(times), fun);&#125;repeatedly(3, function() &#123; return Math.floor((Math.random()*10)+1);&#125;);//=&gt; [1, 3, 8] 再次强调，“使用函数，而不是值”我们常常会知道函数应该被调用多少次，但有时候也知道什么时候推出并不取决于“次数”，而是条件！因此我可以定义另一个名为iterateUntil的函数。iterateUntil接收2个参数，一个用来执行一些动作，另一个用来进行结果检查。1234567891011function iterateUntil(fun, check, init) &#123; var ret = []; var result = fun(init); while (check(result)) &#123; ret.push(result); result = fun(result); &#125; return ret;&#125;; 返回其他函数的函数1234567891011121314151617function invoker (NAME, METHOD) &#123; // 接收一个方法，并在任何给定的对象上调用它 return function(target /* args ... */) &#123; if (!existy(target)) fail(\"Must provide a target\"); var targetMethod = target[NAME]; var args = _.rest(arguments); return doWhen((existy(targetMethod) &amp;&amp; METHOD === targetMethod), function() &#123; return targetMethod.apply(target, args); &#125;); &#125;;&#125;;var rev = invoker('reverse', Array.prototype.reverse);_.map([[1,2,3]], rev);//=&gt; [[3,2,1]] 高阶函数捕获参数高阶函数的参数是用来“配置”返回函数的行为的。对于makeAdder而言，它的参数配置了其返回函数每次添加数值的大小123456789function makeAdder(CAPTURED) &#123; return function(free) &#123; return free + CAPTURED; &#125;;&#125;var add10 = makeAdder(10);add10(32);//=&gt; 42 捕获变量的好处用闭包来捕获增加值，并用作后缀。（但这样并不具有引用透明）1234567891011121314function makeUniqueStringFunction(start) &#123; var COUNTER = start; return function(prefix) &#123; return [prefix, COUNTER++].join(''); &#125;&#125;;var uniqueString = makeUniqueStringFunction(0);uniqueString(\"dari\");//=&gt; \"dari0\"uniqueString(\"dari\");//=&gt; \"dari1\" 由函数构建函数函数式组合的精华 精华：使用现有的零部件来建立新的行为，这些新行为同样也成为了已有的零部件。12345678910111213141516171819202122232425262728// 接收一个或多个函数，然后不断尝试依次调用这些函数的方法，直到返回一个非`undefined`的值function dispatch(/* funs */) &#123; var funs = _.toArray(arguments); var size = funs.length; return function(target /*, args */) &#123; var ret = undefined; var args = _.rest(arguments); for (var funIndex = 0; funIndex &lt; size; funIndex++) &#123; var fun = funs[funIndex]; ret = fun.apply(fun, construct(target, args)); if (existy(ret)) return ret; &#125; return ret; &#125;;&#125;var str = dispatch(invoker('toString', Array.prototype.toString),invoker('toString', String.prototype.toString));str(\"a\");//=&gt; \"a\"str(_.range(10));//=&gt; \"0,1,2,3,4,5,6,7,8,9\" 在这里，我们想做的只是返回一个遍历函数数组，并apply给一个目标对象的函数，返回第一个存在的值。dispatch满足了多态JavaScript函数的定义。这样简化了委托具体方法的任务。例如，在underscore的实现中，你经常会看到许多不同的函数重复这样的模式。 确保目标的存在 检查是否有原生版本，如果是则使用它 如果没有，那么做一些实现这些行为的具体任务。 做特定类型的任务（如适用） 做特定参数的任务（如适用） 做特定个参数的任务（如适用） 同样的模式也体现在Underscore的函数_.map()的实现中：1234567891011_.map = _.collect = function(obj, iteratee, context) &#123; iteratee = cb(iteratee, context); var keys = !isArrayLike(obj) &amp;&amp; _.keys(obj), length = (keys || obj).length, results = Array(length); for (var index = 0; index &lt; length; index++) &#123; var currentKey = keys ? keys[index] : index; results[index] = iteratee(obj[currentKey], currentKey, obj); &#125; return results;&#125;; 使用dispatch可以简化一些这方面的代码，并且更容易扩展。想象一下，你正在写一个可以为数组和字符串类型生成字符描述的函数。使用dispatch则可以优雅的实现：12345678var str = dispatch(invoker('toString', Array.prototype.toString),invoker('toString', String.prototype.toString));str(\"a\");//=&gt; \"a\"str(_.range(10));//=&gt; \"0,1,2,3,4,5,6,7,8,9\" 柯里化 Curring 柯里化函数为每一个逻辑参数返回一个新函数。 例如：1234567891011// 除法function divide(n,d)&#123; return n/d;&#125;// 手动柯里化function curryDivide(n) &#123; return function(d) &#123; return n/d; &#125;;&#125; curryDivide是手动柯里化函数，也就是说，我显示地返回对应参数数量的函数。 自动柯里化参数 1234567891011121314151617181920212223// 接收一个函数，并返回一个只接受一个参数的函数。function curry(fun) &#123; // 柯里化一个参数，虽然似乎没什么用 return function(arg) &#123; return fun(arg); &#125;;&#125;function curry2(fun) &#123; // 柯里化两个参数 return function(secondArg) &#123; return function(firstArg) &#123; return fun(firstArg, secondArg); &#125;; &#125;;&#125;function curry3(fun) &#123; // 柯里化三个参数 return function(last) &#123; return function(middle) &#123; return function(first) &#123; return fun(first, middle, last); &#125;; &#125;; &#125;;&#125;; curry2函数接受一个函数并将其柯里化成两个深层参数的函数。可以用它来实现先前定义的除法函数。1234var divide10 = curry2(div)(10) divide10(50)// =&gt; 5 柯里化函数有利于指定JavaScript函数行为，并将现有函数“组合”为新函数。并且使用柯里化比较容易产生流利的函数式API。 部分应用柯里化函数逐渐返回消耗参数的函数，直到所有参数都耗尽。然而，部分应用函数是一个“部分“执行，等待接收剩余的参数立即执行的函数。 123456789101112131415161718192021222324// 部分应用一个或两个已知的参数function partial1(fun, arg1) &#123; return function(/* args */) &#123; var args = construct(arg1, arguments); // construct为拼接数组，在此代码略去 return fun.apply(fun, args); &#125;;&#125;function partial2(fun, arg1, arg2) &#123; return function(/* args */) &#123; var args = cat([arg1, arg2], arguments); // cat也为拼接数组，在此代码略去 return fun.apply(fun, args); &#125;;&#125;// 部分应用任意数量的参数function partial(fun /*, pargs */) &#123; var pargs = _.rest(arguments); return function(/* arguments */) &#123; var args = cat(pargs, _.toArray(arguments)); return fun.apply(fun, args); &#125;;&#125; 通过组合端至端的拼接函数一种理想化的函数式程序是向函数流水线的一端输送的一块数据，从另一端输出一个全新的数据块。!_.isString(name)这个流水线由_.isString和!组成 _.isString接收一个对象，并返回一个布尔值 !接收一个布尔值，并返回一个布尔值 1234567891011121314// 通过组合多个函数及其数据转换建立新的函数function isntString(str)&#123;return !_.isString(str)&#125;isntString(1)// =&gt; true// 还可以使用Underscore的_.compose函数实现同样的功能// _.compose函数从右往左执行。即最右边函数的结果会被送入其左侧的函数，一个接一个var isntString = _.compose(function(x) &#123; return !x &#125;, _.isString);isntString([]);//=&gt; true 递归理解递归对理解函数式编程来说非常重要，原因有三。 递归的解决方案包括使用对一个普通问题子集的单一抽象的使用 递归可以隐藏可变状态 递归是一种实现懒惰和无限大结构的方法自吸收函数在编写自递归函数时，规则如下 知道什么时候停止 决定怎样算一个步骤 把问题分解成一个步骤和一个较小的问题1234567function myLength(ary) &#123; if (_.isEmpty(ary)) // _.isEmpty何时停止 return 0; else // 进行一个步骤 1+ ； return 1 + myLength(_.rest(ary)); // 小一些的问题 _.rest(ary) &#125; 尾递归尾递归与一般自递归的明显区别是，”一个步骤“和”缩小的问题“中的元素都要进行递归调用。1234567891011function tcLength(ary, n) &#123; var l = n ? n : 0; if (_.isEmpty(ary)) return l; else return tcLength(_.rest(ary), l + 1);&#125;tcLength(_.range(10));//=&gt; 10 相互关联函数两个或多个函数相互调用被称为相互递归。下面看一个例子，用谓词函数来检查偶数和奇数： 12345678910111213141516171819function evenSteven(n) &#123; if (n === 0) return true; else return oddJohn(Math.abs(n) - 1);&#125;function oddJohn(n) &#123; if (n === 0) return false; else return evenSteven(Math.abs(n) - 1);&#125;// 相互递归调用来回反弹彼此之间递减某个绝对的值，知道一方或另一方达到0evenSteven(4)// =&gt; trueoddJohn(11)// =&gt;true 对递归的改进尽管递归技术上是可行的，但是因为JavaScript引擎没有优化递归调用，因此，在使用或写递归函数时，可能会碰到如下错误12evenSteven(10000) // 栈溢出 递归应该被看作一个底层操作，应该尽可能地避免（很容易造成栈溢出）。普通的共识是，首先是要函数组合，仅当需要的时才使用递归和蹦床。 蹦床（tramponline）:使用蹦床展平调用，而不是深度嵌套的递归调用。 首先，看看如何手动修复evenOline和oddOline使得递归调用不会溢出。一个办法是返回一个函数，它包装调用，而不是直接直接调用。1234567891011121314151617181920function evenOline(n) &#123; if (n === 0) return true; else return partial1(oddOline, Math.abs(n) - 1);&#125;function oddOline(n) &#123; if (n === 0) return false; else return partial1(evenOline, Math.abs(n) - 1);&#125;oddOline(3)()() // 返回的只是一个函数调用// =&gt; function()&#123;return evenOline(Math.abs(n) - 1)&#125;oddOline(3)()()() // 将函数调用执行// =&gt; trueoddOline(10000)()()()... // 10000个()去执行返回的函数调用// =&gt; true 当然，我们不能直接向用户暴露这个API，可以提高另外一个函数trampoline，从程序执行来进行扁平化处理。123456789101112function trampoline(fun /*, args */) &#123; // 不断调用函数的返回值，知道它不是一个函数为止 var result = fun.apply(fun, _.rest(arguments)); while (_.isFunction(result)) &#123; result = result(); &#125; return result;&#125;trampoline(oddOline, 10000)// false 由于调用链的间接性，使用蹦床增加了相互递归函数的一些开销。然而满总比溢出要好。同样，你可能不希望强迫用户使用trampoline，只是为了避免堆栈溢出。我们可以进一步隐藏其外观。12345678910111213function isEvenSafe(n) &#123; if (n === 0) return true; else return trampoline(partial1(oddOline, Math.abs(n) - 1));&#125;function isOddSafe(n) &#123; if (n === 0) return false; else return trampoline(partial1(evenOline, Math.abs(n) - 1));&#125; 基于流的编程链接使用jQuery等库经常会使用链接，链接可以让我们的代码更加简洁，如下是链接的实现示例。链接方法的原理在于。每个链接的方法都返回统一的宿主对象引用。12345678910111213141516171819202122232425function createPerson() &#123; var firstName = \"\"; var age = 0; return &#123; setFirstName: function(fn) &#123; firstName = fn; return this; &#125;, setAge: function(a) &#123; age = a; return this; &#125;, toString: function() &#123; return [firstName, lastName, age].join(' '); &#125; &#125;;&#125;createPerson() .setFirstName(\"Mike\") .setAge(108) .toString();//=&gt; \"Mike 108\" 惰性链 上述链接是直接执行，然而我们也可以实行惰性链，即使其先缓存待执行的函数，等到调用执行函数时一起执行。封装了一些行为的函数通常被称为thunk，存储在_calls中的thunk期待将作为接受force方法调用的对象的中间目标。123456789101112131415161718192021222324252627282930function LazyChain(obj) &#123; this._calls = []; // 用于缓存待执行函数的数组 thunk this._target = obj; // 目标对象&#125;LazyChain.prototype.invoke = function(methodName /*, args */) &#123; // 将函数压入的方法 var args = _.rest(arguments); this._calls.push(function(target) &#123; var meth = target[methodName]; return meth.apply(target, args); &#125;); return this;&#125;;LazyChain.prototype.force = function() &#123; // 强制执行this._calls中的函数 return _.reduce(this._calls, function(target, thunk) &#123; return thunk(target); &#125;, this._target);&#125;;// 使用，直到force方法被调用才将 concat, sort,join执行new LazyChain([2,1,3]) .invoke('concat', [8,5,7,6]) .invoke('sort') .invoke('join',' ') .force();// =&gt; \"1 2 3 4 5 6 7 8\" 管道链接模式有利于给对象的方法调用创建流程的API，但是对于函数式API则未必。方法连接有各种各样的缺点，包括紧耦合对象的set和get逻辑。主要问题是，函数链经常会做调用之间改变传递的共同引用。函数式API重点在操作值而不是引用。一下是管道的具体实现1234567function pipeline(seed /*, args */) &#123; return _.reduce(_.rest(arguments), function(l,r) &#123; return r(l); &#125;, seed);&#125;;pipeline(42, function(n)&#123;return -n&#125;,function(n)&#123;return n+1&#125;)// =&gt; -41 写在最后本文更多的是对《JavaScript函数式编程》一书的摘要，并透过一段段代码试图阐述函数式编程的思想。希望以后的工作中能够吸取函数式编程的好，并慢慢对其加深理解。从书中获取知识，最终还是要落于实践中去的。同时，希望能够通过这篇文章帮助不了解函数式编程的小伙伴建立系统的认识。","categories":[],"tags":[]},{"title":"漫谈Web缓存","slug":"漫谈Web缓存","date":"2016-08-21T05:09:15.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/08/21/漫谈Web缓存/","link":"","permalink":"https://sfegsq.github.io/2016/08/21/漫谈Web缓存/","excerpt":"背景说明缓存一直是前端性能优化中，浓墨重彩的一笔。了解前端缓存是打造高性能网站的必要知识。 之前，对于缓存的认知一直停留在看《HTTP权威指南》和一些相关帖子的深度，过了一段时间，又总是忘记，正好最近不是很忙，结合内网上的一些参考资料，结合实践，试着全面解析一下缓存以及其最佳实践。","text":"背景说明缓存一直是前端性能优化中，浓墨重彩的一笔。了解前端缓存是打造高性能网站的必要知识。 之前，对于缓存的认知一直停留在看《HTTP权威指南》和一些相关帖子的深度，过了一段时间，又总是忘记，正好最近不是很忙，结合内网上的一些参考资料，结合实践，试着全面解析一下缓存以及其最佳实践。 前后端交互中涉及到的缓存前端我们日常所见最多的也是我们最常利用的就是浏览器对于HTTP规范实现所进行的资源缓存，HTTP规范中，定义了4个缓存相关的字段。对HTTP感兴趣的同学也可以看我对《HTTP权威指南》的阅读笔记。《HTTP权威指南》 Request Headers Response Headers 说明 Expires Expires HTTP1.0中就开始支持的头字段，采用相对服务器时间来定义，但是因为服务器与浏览器时间不一定一致，所以不完全可靠 Cache-Control Cache-Control HTTP1.1开始支持的字段，优先级比expires高，但是目前来说通常两者并存，采用绝对时间Cache-Control: max-age=60单位是秒 If-Modified-Since Last-Modified Last-Modified表示上一次更改时间，注：这里的更改并非狭义上必须对内容进行相应的更改，哪怕是打开文件再直接进行保存也会刷新该时间。 If-None-Match Etag Etag则是与内容紧密相关的一个字段，是对文件内容进行Hash散列后得到的值(Hash会需要消耗一部分CPU时间)，比Last-Modified可靠 以上是HTTP中关于缓存的头字段，浏览器其实只是一个HTTP协议的代理client，在十几年的发展中，为了满足用户，而不端增强自身功能，并加入了许多特性，最终成为我们看到的这个样子，正如QQ本身应该只是一款即时通信工具，但现在也如此巨无霸。正常情况下，我们只会对GET请求进行缓存，当然是否能对POST等其他类型的请求进行缓存呢？规范中指出，是可以的，只要设置了相应的头字段，即Cache-Control,Expires等。但这里其实意义不大，我们之所以要做缓存，是因为当前互联网环境下，最影响性能，也就是最耗时的部分在于网络传输，在有限的带宽下，如何提高性能？这里就是缓存施展拳脚的天地了。 后端后端的话，有两种缓存，一种是存储在disk硬盘中的，一种是存储在内存中的。相对来说，内存缓存速度快，但是容易造成内存泄漏，所以这部分需要慎重，需要良好的管理(听说淘宝首页就是H5页面，为了提高性能，选择常驻在内存中以提高分发速度)。后端的缓存主要是为了防止前端穿透到DB(databases)，因为后台主要的性能瓶颈大部分存在于查表，所以通过后端缓存，减少用户请求直接穿透到DB这种情况的发生，从而提高性能。 本文以前端为主，后端因为并不是非常专业的原因，仅简介如上，有兴趣的朋友可以再进行深入的研究。 注：浏览器的缓存也是基于disk，缓存在硬盘上。 前端缓存的套路正如前文所说，前端的核心在于上述的4个头字段。 以常见的请求一个CSS样式来说。 第一次请求 通常服务器会传送这4个字段过来， 可能是4个都要，也可能一个字段也没有。这里主要讲解4个字段都存在的情况。 第二次请求 前端：首先，浏览器会检查Cache-Control与Expires，有Cache-Control的情况下,以其为标准，如果超时，则向后端发送请求，请求中会带上 If-Modified-Since,If-None-Match。 后台：后端服务器接收到请求之后，会对这两个字段进行对比，同样以If-None-Match为标准，没有If-None-Match的情况下,比对If-Modified-Since，如果比对后发现文件没有过期，即Etag没有发生变化，或者Last-Modified与If-Modified-Since一致(只存在If-Modified-Since时)。如果改变了，就会发送新的文件，反之，则直接返回304。 这里盗个图 上面就是大致的请求流程。但是仅仅如此的话，距离真正的实践还是有一些距离的。 浏览器提供的三种刷新方式我们之前假设的理想情况都是在第一种情况下，但是在现实场景中，不可能如规范那么如人意。所以浏览器提供了三种刷新方式。 url+enter或者a标签的超链接点击,点击前进后退按钮 F5刷新 或者 点击刷新按钮 ctrl+F5强制刷新 那么，这三种情况有什么区别呢？ 第一种，其实就是我们理想的情况，特别注意一下，如果缓存没有过期，借助于Chrome的Network，我们会发现状态码是200，因为这里并没有向后端发起请求而是直接重现上次请求的结果，所以仍然是200，唯一不同的是他的size栏并不是显示他的大小，而是显示from cache。 第二种，则会直接无视Cache-Control与Expires是否过期，而直接在requset headers中设置Cache-Control: max-age=0,直接向服务器发送请求。服务器根据If-None-Match和If-Modified-Since进行判断是否过期。大多数情况下，我们对静态资源设置时间比较久，很多没有过期。这时候，我们就会看见许多304(另一种情况是过期后请求得到304)。 第三种，同样直接无视Cache-Control与Expires是否过期，并且设置Cache-Control： no-cache,也不会发送If-None-Match和If-Modified-Since。服务器则必须返回新的资源。 如何开启缓存设置既然知道缓存的好处，那么有哪些设置缓存的方式呢？主要有如下三种 配置apache或者ngix服务器，开启相应缓存模块 后端代码中动态设置 前端HTML页面meta标签 最省心省力的应该是第一种，也是最为常用的一种方式，第二三种，只能说是对其进行补充。我的是在腾讯云上买的服务器，配置方式参加:ubuntu上配置apache缓存。 配置的指导思想 服务器配置主要针对对象是静态资源，如图片，css，js等。通常对其进行类型匹配，然后设置过期时间。比如照片的过期时间则是设置的越长越好，比如1个月，而CSS与JS脚本也可以设置的比较久一些，但是HTML脚本则万万不要设置缓存时间。生产实践中为了满足尽可能的缓存久与版本更新的需求，通常会在构建的时候打上MD5码，因为所有静态资源都是通过HTML引入或者通过HTML页面见解引入，所以只需要控制住HTML中的请求对应更新版本即可完美的达到上述要求。 第二种代码如下1res.set(&apos;Cache-Control&apos;, &apos;max-age=60000&apos;); // node express 第三种代码如下12&lt;meta http-equiv=&quot;cache-control&quot; content=&quot;max-age=60000&quot; /&gt;&lt;meta http-equiv=&quot;expires&quot; content=&quot;Tue, 01 Jan 1980 1:00:00 GMT&quot; /&gt; Cache-Control为了降低网络链路的拥塞，在许多局域网中会设置许多的代理服务器，而这些代理服务器会缓存本局域网内最常用的一些资源，并根据算法动态的更新缓存的资源，以保持一定的命中率。 这里Cache-Control就有一个public，private的属性值，默认是public。public表示允许代理服务器对其内容进行缓存，这样局域网内的其他主机要是第一次进行请求，如果在代理服务器上正好有相应的资源则可以避免前往遥远的目标服务器进行请求并返回相应的资源。当然这里结合CDN的使用会更好。 消灭304304 Not Modified 性能优化中，如果你经常看到许多304(当然，不包括你点击按钮这种刷新方式)。那么你该好好想想你设定的缓存时间是不是该延长一些了。304这个表示，你的请求发送到后端，后端判断并认为资源可以继续使用，直接使用本地缓存。但是这种方式下，虽然后端不会传相应的资源，但是请求的一来一回也是会花费时间的。并且给服务器一定的压力，所以性能优化中，有一条叫做 消灭304 。尽可能的设置久缓存时间，通过md5码来管理版本。 参考链接 浅谈Web缓存 Is it possible to cache POST methods in HTTP? 《HTTP权威指南》 ubuntu上配置apache缓存","categories":[{"name":"性能","slug":"性能","permalink":"https://sfegsq.github.io/categories/性能/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"},{"name":"PHP","slug":"PHP","permalink":"https://sfegsq.github.io/tags/PHP/"}]},{"title":"认识前端安全","slug":"认识前端安全","date":"2016-08-16T05:08:10.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/08/16/认识前端安全/","link":"","permalink":"https://sfegsq.github.io/2016/08/16/认识前端安全/","excerpt":"前端安全一直是一个蛮严苛的问题，特别如果设计到money更是如此。了解前端安全，在平时的coding中主动考虑，防范于未然，是一个有追求的程序猿应该做的。","text":"前端安全一直是一个蛮严苛的问题，特别如果设计到money更是如此。了解前端安全，在平时的coding中主动考虑，防范于未然，是一个有追求的程序猿应该做的。 未登录我们从弱弱的基本开始，第一步当然是登录鉴权了，如果一个需要用户身份鉴权的应用系统没有登录过滤那简直是没法想像的，方案基本都是用户输入用户名密码、或是三方 openID 授权后在 session 里保存用户此次登录的凭证来确保每次请求的合法性。由于 session有时效限制，所以若用户一段时间未与服务器交互则会过期重登，当然我们也可以通过把登录凭证存在 cookie 里来自由控制用户登录的有效时间。这个是最基本的鉴权我们就不深入细节。 登录了，但被CSRF虽然有了登录验证后，我们可以挡掉其他非登录用户的骚扰了，但悲剧的是坏人们还是可以欺骗我们善良的用户，借已登录用户的手来搞破坏。即 CSRF（Cross-site request forgery）跨站请求伪造。 举个栗子：有个黑客的网站 h.com，我们的网站 a.com。用户登录了a.com，但被诱点进入h.com（如收到 QQ 消息或邮件传播的h.com 的链接），当用户访问这个链接时，h.com 上自动发送一个请求到 a.com，由于用户已登录a.com，浏览器根据同源策略，会在该请求上自动附带了 cookie，而前面我们提到了鉴权是通过 cookie 里的某个 key 值凭证的，所以如若没有判断该请求的来源合法性，我们则通过了该伪造的请求，执行了相应的操作。比如这个请求是让该用户发一篇日志，或是发微博，或是严重的发起一笔转账。 常见的诸如放一张看不见的图片发起get请求 &lt;img src=http://www.a.com/Transfer.php?toUserId=999&amp;money=1000000&gt; post 请求会稍微麻烦些，但同样很好实现，可以构造一个表诱导用户点击，也可以直接利用ajax发送post请求。要防住此类伪造请求我们第一反应都是检查这个请求的来源，确实，在上述的情形下发来的请求报文里refferer字段的网址不是我们的自己站点，而会是一个三方的，如上假设的 h.com。但是很多情况下，refferer并不完全靠谱，比如如果众多二级域名之间需要通信，那么refferer可能会设得比较泛，如*.a.com。或是历史原因一些 refferer 为空的请求会漏过校验等。所以这种方式只是提高了破解成本，并不能完全杜绝。 现在业界比较通用的解决方案还是在每个请求上附带一个anti-CSRF token。例如，将sessionid加盐再散列处理。然后一起发送给后端。服务器端拿到 token 后用相同的算法对 sid 运算后匹对，相同则为已登录用户发出请求，没有或不对等则说明该请求是伪造的。token = MD5（ sid * salt ）其实这个算法的精髓在于使用了 cookie 中的 sid（用户登录后我们服务器种的 cookie 凭证），因为前端的代码对用户而言都是没有秘密的，只要花点时间即可推算出我们的算法，但由于攻击者无法登录，又拿不到 cookie 里的 sid（根据浏览器的同源策略，在 h.com 上无法获取属于 a.com 的 cookie），所以无法构造出 token。至于加 MD5当然是因为我们不会傻的把登录凭证 sid 放到 url 上给人直接拿了登录- -（以前还真有人干过），为什么要加 盐 salt 则是怕简单的一层MD5还是有可能被通过撞库的方式解出 sid，当然加了 salt 也不意味着100%防住，只是大大提高了破解的成本而已。 有防 CSRF了，但被 XSS从上面我们知道防住 CSRF 最关键的是要守住 cookie，如果用户的 cookie 被人窃取了，那上面的防护就形同虚设了。而 XSS 就可以很轻易的获取用户的 cookie，所以有句话叫Buy one XSS, get a CSRF for free。 用户输入的内容原封不动的通过服务器程序渲染在页面上 。 反射型举个栗子 前端get一个请求：www.a.com/xss.php?name=userA 后台处理:&lt;?php echo &#39;Hello&#39; . $_GET[&#39;name&#39;]; 代码本意是根据queryString 的 name 来动态展示用户名，但由于未对 name 做编码校验，当链接为： www.a.com?xss.php?name=&lt;script&gt;alert(document.cookie);&lt;/script&gt; 这时访问这个链接则会弹出我们的 cookie 内容，如果这时候再把 alert 改为一个发送函数，则可把 cookie 偷走。 前端DOM-Based XSS123&lt;script&gt;document.getElementById(&apos;intro-div&apos;).innerHTML = document.location.href.substring(document.location.href.indexOf(&quot;intro=&quot;)+6);&lt;/script&gt; 如上，直接将用户的输出输出到页面标签中。但是如果将链接中的内容设置为 http://www.a.com/index.html?intro=&lt;script&gt;alert(document.cookie)&lt;/script&gt; 那我们的 cookie 又没了。 持久型XSS也称为存储型 XSS，注入脚本跟 XSS 大同小异，只是脚本不是通过浏览器-&gt;服务器-&gt;浏览器这样的反射方式，而是多发生在富文本编辑器、日志、留言、配置系统等数据库保存用户输入内容的业务场景。即用户的注入脚本保存到了数据库里，其他用户只要一访问到都会中招。 前端get一个请求：www.a.com/xss.php?name=&lt;script&gt;alert(document.cookie);&lt;/script&gt; 后台处理:&lt;?php $db.set(&quot;name&quot;, $_GET[&quot;name&quot;]); 前端请求的页面：&lt;?php echo &#39;Hello&#39; . $db.get[&#39;name&#39;]; 这样但凡请求了该页面的都会被XSS攻击到。 解决XSS从上面我们可以看出各种攻击手段很重要的一点就是要获取 cookie，有了 cookie 就相当于获取了我们用户的身份信息，所以自然的我们要保护我们的 cookie。在 cookie 里有个 HttpOnly 属性可以让页面无法通过 JS 来读写 cookie。 res.cookie(&#39;a&#39;, &#39;1&#39;, { expires: new Date(Date.now() + 900000), httpOnly: true }); 开启这个属性后 document 将无法获取 cookie。当然这个方法也不是万能的，我们的 cookie 还是会在 header 中，还是有其他手段去获取 header 中的 cookie，不过使用后我们还是提高了攻击的成本。关键还是我们要不相信用户的一切输入，对编码输出在页面中会破坏原有代码（HTML、JavaScript甚至WML等）规则的特殊字符以及对某些标签的某些属性进行白名单检查。 XSS防护也做了,被用户SQL注入看个简单例子： 请求：www.a.com/query?userId=123 功能是查询userId为123的用户出来，这个请求到我们服务端最后sql语句是这样：select * from users where userid=123 如果不做任何校验，如果用户输入如下123; DROP TABLE users; 嘎嘎，整个表就没有了。所以同样的，还是那个原则，我们不能相信用户的任何输入，如果一个sql语句里包含了用户输入的内容，那我们要对内容做sql安全相关的过滤检查。同时，使用一些ORM工具，不使用拼凑字符串型的语句执行方式。 总结总的来说，前端最重要的就是一个sessionId这个代表用户身份的凭证，保护好这个凭证，同时利用同源策略以及自己加密token来识别用户，最后以最恶意的眼光对待用户的输入，不要相信用户的输入。这样就能屏蔽绝大部分常见的安全问题了。","categories":[{"name":"安全","slug":"安全","permalink":"https://sfegsq.github.io/categories/安全/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"},{"name":"PHP","slug":"PHP","permalink":"https://sfegsq.github.io/tags/PHP/"},{"name":"安全","slug":"安全","permalink":"https://sfegsq.github.io/tags/安全/"}]},{"title":"漫话密码存储","slug":"漫话密码存储","date":"2016-08-15T05:05:45.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/08/15/漫话密码存储/","link":"","permalink":"https://sfegsq.github.io/2016/08/15/漫话密码存储/","excerpt":"背景密码是用来进行鉴权(身份认证)一种手段,说白了就是证明你是谁。一般鉴权都可以总结为下面3种形式: 你知道什么? (如密码,密码提示问题等) 你有什么? (如信用卡,token卡等) 你是什么?(如指纹识别，瞳孔识别等)","text":"背景密码是用来进行鉴权(身份认证)一种手段,说白了就是证明你是谁。一般鉴权都可以总结为下面3种形式: 你知道什么? (如密码,密码提示问题等) 你有什么? (如信用卡,token卡等) 你是什么?(如指纹识别，瞳孔识别等) 常见攻击方式常见的针对密码的攻击方式有: 暴力破解(Brute-force) 字典攻击(Dictionary Attack) 彩虹表攻击(Rainbow table attacks) 暴力破解 暴力破解指的是尝试密码空间中所有的可能情况。 字典攻击 上面说了暴力搜索空间巨大，然而大部分用户选择的密码都是有一定规律的：如使用生日，姓名，单词缩写，电话，以及以上各种方法的混合。如果把这些常见的密码放到一个文件里，破解密码的时候就直接从这些常见的密码中尝试，这样尝试的空间和暴力破解相比就会小很多。这种存储了许多常见密码的文件就像是一本用户常见密码的字典，字典攻击因此得名。 彩虹表 彩虹表：彩虹表是计算机科学时间/空间权衡的典型体现。起核心思想和查找表是类似的，只是相对于查找表，彩虹表需要的存储空间相对较小，查找速度比查找表的O(1)要慢一点。通俗一点说就是：彩虹表牺牲了一点计算速度，换来的好处是较少的空间存储更多的密码数据。举个例子: 如果一个查找表里需要存储所有的10个字符小写字母的字典(至少需要存储用户名，密码hash输出)，需要的磁盘空间为 26^10 * (10+16) / (2^40) ~= 3338T，如果改用彩虹表存储，那么这个彩虹表可能只需要约300G的磁盘空间就能涵盖99.9%的组合。 密码存储的方式直接存储最简单直观的做法是将密码明文存储到数据库。这种方式数据库的一条记录类似: 。这种方式最简单但无安全可言。黑客获取了数据库就活得了所有用户信息。因此直接存储明文是不可取的，至少需要对明文做一些处理 hash存储先对明文密码进行hash计算，将hash函数的输出存储到数据库。这里的hash是指密码学中具有单向性和不可逆性的hash函数(如MD5，SHA1等)，不是数据结构中的hash算法。这种方式的数据库中记录格式类似: 。这种方法比存明文要好很多，恶意用户获得了密码数据库以后不能直接得到用户的密码。这种方法的问题是：抵抗不了字典和彩虹表攻击，一旦黑客针对数据库构造好彩虹表，就很容易破解了。因此，我们需要一种方法使恶意用户预先构造字典和彩虹表的代价变大。 密码hash加盐后存储密码学中的盐是指一段随机字节串，通常和密码一起作为hash函数的输入。密码加盐后，数据库记录类似 ，这种方法有一些变种如： 或 ，本质都是一样的。加盐后的数据库构造彩虹表需要的巨大存储空间，使得构造查找表和彩虹表的攻击方式失效。 大大增加构成字典和彩虹表的成本。 降低相同密码hash值相同的概率。 关于盐的使用有一点需要说明：加盐的目的是为了增加提前构造字典和彩虹表的代价，并不是为了加密或增加密码hash的计算复杂性。因此，盐并不需要加密存储，通常是明文和用户名一起存储于数据库的。 自适应加盐存储前面说了，密码加盐能有效的对抗提前构造字典和彩虹表的攻击，但是对于暴力破解还是无能为力，对于单个用户的密码，如果黑客采用多台计算机并行计算或者采用GPU等特殊硬件进行暴力破解，能很快的破解较弱的密码。因此，比较理想的密码存储方法要具备2点: 单次密码存储的计算要尽可能的慢，慢到对单个普通用户的鉴权来说计算时间刚好可以接受，但是对于需要尝试很多密码组合的恶意用户来说，计算代价将会大大增加。 可以动态的控制密码计算过程的复杂性,这样就可以应对摩尔定律下计算机计算能力越来越强的趋势。 总结密码的安全存储目前正确的做法是使用自适应加盐的方法进行存储，具体的说是可以使用pbkdf2, bcrypt, scrypt中的任何一种。本文主要讨论了如何安全的存储密码，如果是保证用户账户的安全，那么除了保证密码存储安全之外，通常需要综合使用下面的各种方法: 引导选择强度较高的密码 使用验证码 密码验证错误以后短时间锁住账号 敏感操作需要二次鉴权 使用two-factor验证 参考链接 加盐密码哈希：如何正确使用 密码破解之王：Ophcrack彩虹表(Rainbow Tables)","categories":[{"name":"安全","slug":"安全","permalink":"https://sfegsq.github.io/categories/安全/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"},{"name":"PHP","slug":"PHP","permalink":"https://sfegsq.github.io/tags/PHP/"},{"name":"安全","slug":"安全","permalink":"https://sfegsq.github.io/tags/安全/"}]},{"title":"前后端交互过程中的编码","slug":"前后端交互过程中的编码","date":"2016-07-25T05:04:03.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/07/25/前后端交互过程中的编码/","link":"","permalink":"https://sfegsq.github.io/2016/07/25/前后端交互过程中的编码/","excerpt":"起因最近在写PHP，本身对PHP不太熟练。然后遇到编码这个问题，困扰了大半天，索性，系统探索解决一番。","text":"起因最近在写PHP，本身对PHP不太熟练。然后遇到编码这个问题，困扰了大半天，索性，系统探索解决一番。 前后端交互过程中涉及的编码 Browser cilent: 首先，浏览器的设置里有设置编码格式，一般设置为UTF-8。 AJAX request: AJAX异步请求的过程中可以设置编码，contentType:&quot;application/x-www-form-urlencoded; charset=utf-8&quot; PHP cilent: PHP通过$_POST这个全局变量接收前端POST过来的数据，编码格式为AJAX在请求头中设置的charset=utf-8,PHP操作的过程中可以通过iconv函数库自行转码,例如iconv(&quot;UTF-8&quot;,&quot;GB2312//IGNORE&quot;,$data) connection: 在PHP与数据库连接的过程中可以设置connection过程中使用的编码格式，例如CodeIgniter框架可以在数据库配置文件database.php中，设置&#39;char_set&#39; =&gt; &#39;latin1&#39; databases: 数据会先把数据从php客户端的编码转为转为connection中设置的编码，再以字节流的形式传输并插入数据库。 字符编码常用的编码分为 UTF-8 万国码，就是它是一种变长的编码方式 latin1 又称“西欧语言”，是mysql数据库默认设置。为单字节编码 gb2312 一共收录了7445个字符，包括6763个汉字和682个其它符号。 GBK 汉字内码扩展规范,支持繁体与简体和许多符号 UTF-8走上国际化就靠它了。现在推荐使用UTF-8，这样外国人打开我们的网站的时候不需要转码，直接就能使用。不多说了，大家都认识。 看一下他的编码特质UTF-8的设计有以下的多字符组序列的特质 单字节字符的最高有效比特永远为0。 多字节序列中的首个字符组的几个最高有效比特决定了序列的长度。最高有效位为110的是2字节序列，而1110的是三字节序列，如此类推。 多字节序列中其余的字节中的首两个最高有效比特为10。 UTF-8的这些特质，保证了一个字符的字节序列不会包含在另一个字符的字节序列中。这确保了以字节为基础的部分字符串比对（sub-string match）方法可以适用于在文字中搜索字或词。有些比较旧的可变长度8位编码（如Shift JIS）没有这个特质，故字符串比对的算法变得相当复杂。虽然这增加了UTF-8编码的字符串的信息冗余，但是利多于弊。另外，数据压缩并非Unicode的目的，所以不可混为一谈。即使在发送过程中有部分字节因错误或干扰而完全丢失，还是有可能在下一个字符的起点重新同步，令受损范围受到限制。 另一方面，由于其字节序列设计，如果一个疑似为字符串的序列被验证为UTF-8编码，那么我们可以有把握地说它是UTF-8字符串。一段两字节随机序列碰巧为合法的UTF-8而非ASCII的概率为32分1。对于三字节序列的概率为256分1，对更长的序列的概率就更低了。 latin1latin1编码是单字节编码，向下兼容ASCII，其编码范围是0x00-0xFF，0x00-0x7F之间完全和ASCII一致，0x80-0x9F之间是控制字符，0xA0-0xFF之间是文字符号。 因为latin1编码范围使用了单字节内的所有空间，在支持latin1的系统中传输和存储其他任何编码的字节流都不会被抛弃。换言之，把其他任何编码的字节流当作latin1编码看待都没有问题。这是个很重要的特性，MySQL数据库默认编码是Latin1就是利用了这个特性，latin1编码是一个8位的容器。 把一个gbk编码的串写入latin1的表，不会有任何问题，保存的是原封不动的字节流，从表中读取已写入的串也不会有任何问题，且读出的字节流就和当初写入的完全一致。 读取出来以后，如果在终端下，就会理解成locale类型（如果locale系gbk，当时写入的gbk中文串可正常回显）读取出来以后，如果要写入文件，则文件编码方式即当时写入的字节流编码，如gbk写入的，读出存入文件后，文件编码也是gbk！但是如果混着写（utf-8 + gbk),那编辑器就犯蒙了，就可能会显示会有乱码。 当然，基于可维护的角度，还是统一为UTF-8编码格式，以免出现乱码。 GBK与gb2312因为历史原因，很多网页和数据库依然使用这个编码格式应该逐步升级为UTF-8。 文件编码每个文件都设置了其编码的格式,大部分推荐使用UTF-8。 VIM文件编码示例一个文本文件，vim打开的时候按某种编码A打开，转换成某种编码B，然后保存的时候转换成另一种编码C，其他文本编辑器类似，可能没有vim这么可以设置和自动完成。编码B：对于整个文件没有影响，只是事关显示的，就是vim与操作系统交互时候使用的编码。 编码A：使用 set fileencodings=ucs-bom,utf-8,gbk,cp936,latin-1设置。vim 按照设置的顺序检查检测文件的编码。因为某些编码里不存在某些二进制序列的组合，所以如果检测到就认为不是这种编码，检查下一种编码，否则就认为是这一种。因为latin-1可以出现任何二进制序列的组合，所以如果放到第一个，那么将永远以latin-1显示。 在一般的二进制文件里是不存在字符编码的标记的。但是Unicode里面有个特殊叫做零宽度空格（\\FE\\FF）而\\FF\\FE是不存在的编码，所以在Unicode的标准里可以人为的在开始加入这个字符（这个字符在任何字体下都是没有宽度的，在中文字符里面没有任何的效果跟没有一样，是为了照顾东南亚某些语言的显示而设置的）。这样就便于文本编辑器检查字符和字节顺序，但是在代码里include这种文件经常会出问题（这可是个大坑，编译器会认为这是一个非法字符，可是你又看不到）。 编码B：set fileencoding=utf-8，保存时候使用的编码，保存的时候自动转换为另一种编码。但是如果一开始打开的时候就识别错了编码，再转换的时候一个不存在的字符也是不会完转换的。 参考资料 mysql的latin1 支持中文 UTF-8维基百科 VIM 文件编码识别与乱码处理","categories":[{"name":"前端","slug":"前端","permalink":"https://sfegsq.github.io/categories/前端/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"}]},{"title":"阅读gulp源码小结","slug":"阅读gulp源码小结","date":"2016-07-18T05:01:51.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/07/18/阅读gulp源码小结/","link":"","permalink":"https://sfegsq.github.io/2016/07/18/阅读gulp源码小结/","excerpt":"简介gulp源码核心部分寥寥60+行。但是通过这60+行代码，gulp给我们带来的确是前端自动化构建的便利。以往以为其源码肯定蛮复杂，却没想到却是这么60+行，这60+行的背后，是来自于模块化的支撑。","text":"简介gulp源码核心部分寥寥60+行。但是通过这60+行代码，gulp给我们带来的确是前端自动化构建的便利。以往以为其源码肯定蛮复杂，却没想到却是这么60+行，这60+行的背后，是来自于模块化的支撑。gulp的四个接口分别来源于orchestrator,vinyl-fs两个模块。所以gulp的所有特性都来自于这两个模块。Orchestrator是用来任务管理，以及发布一些事件，vinyl-fs 则提供代表gulp灵魂的流式文件系统。研究清楚了这两个模块，也就了解了gulp。 gulp.task = Gulp.prototype.task = Gulp.prototype.add; Gulp.prototype.src = vfs.src; Gulp.prototype.dest = vfs.dest; Gulp.prototype.watch = function(glob, opt, fn) { ... return vfs.watch(glob, opt, fn);}; 同时gulp本身是直接继承于Orchestrator模块。123function Gulp() &#123; Orchestrator.call(this); // gulp直接继承于Orchestrator模块&#125; orchestrator模块介绍 A module for sequencing and executing tasks and dependencies in maximum concurrency 译：以最大并发能力顺序执行任务与其依赖的一个功能模块 1234567var Orchestrator = function () &#123; EventEmitter.call(this); //继承了EventEmitter对象 this.doneCallback = undefined; // 当task里所有的任务完成时调用这个函数 this.seq = []; // task以及task里依赖的执行顺序，（start里会有多个task，每个task又有可能有多个依赖，每个依赖又可能有多个依赖，所以需要保存其执行顺序） this.tasks = &#123;&#125;; // 任务对象，包括任务名，依赖，回调函数 this.isRunning = false; // 表示当前是否在执行任务&#125;; Orchestrator利用seq这个队列数组存储需要执行的task，这样如果计算机有能力执行，它就从队列里取走一个，如果还有能力就再取走一个，所以这其实是in maximum concurrency即以最大的并发能力来执行。 关于seq的构造，则是引入sequencify模块递归计算其依赖并压入队列。 同时通过继承EventEmitter对象，Orchestrator发布了一些列可订阅的事件，用于插件以及命令行里的gulp在事件发生时输出相应的信息。 var events = [&#39;start&#39;,&#39;stop&#39;,&#39;err&#39;,&#39;task_start&#39;,&#39;task_stop&#39;, &#39;task_err&#39;,&#39;task_not_found&#39;,&#39;task_recursion&#39;]; 系统暴露了这些事件以供插件调用，并且提供了2个方法 listenToEvent是监听某一个事件 onAll是不管events里的那个就监听 vinyl-fs模块介绍主要依赖于vinyl与glob-watcher。后者提供监视文件变化的watch接口，前者则在file的基础上封装一些属性与方法，构造出独特的vinyl文件对象。Gulp使用的是Stream，但却不是普通的Node Stream，而是基于vinyl对象的vinyl File Object Stream。 构造函数如下12345678910111213function File(file) &#123; if (!file) file = &#123;&#125;; // 保存该文件的路径变化记录 var history = file.path ? [file.path] : file.history; this.history = history || []; this.cwd = file.cwd || process.cwd(); // 当前文件所在目录,即current work directory this.base = file.base || this.cwd; // 用于相对路径，代表根目录 this.stat = file.stat || null; // 使用 fs.Stats得到的结果 this.contents = file.contents || null; // 文件内容 this._isVinyl = true; // 文件对象是否是vinyl对象，vinyl对象即对file对象封装后的结果&#125; Gulp为什么不使用普通的Node Stream呢？ 普通的Node Stream只传输String或Buffer类型，也就是只关注内容。但Gulp不只用到了文件的内容，而且还用到了这个文件的相关信息（比如路径）。 因此，Gulp的Stream是Object风格的，也就是Vinyl File Object了。所以需要有有contents、path这样的多个属性了。 写在末尾阅读gulp代码的这一次，是我第一次阅读这种开源的模块化项目。深深的被震撼到了，认识到了模块化的巨大力量。正如7层计算级机网络模型。将层级抽象出来，每一层只需要关注自己那一层的事情，直接调用下一层提供的API。就能完成非常复杂的事情，而不需要凡是亲力亲为，一行行代码，一个个小问题依次解决。能够解放双手做更多的事情。 参考文档 探究Gulp的Stream 从零单排之gulp实战 开源Nodejs项目推荐gulp核心模块：Orchestrator","categories":[{"name":"前端","slug":"前端","permalink":"https://sfegsq.github.io/categories/前端/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"}]},{"title":"阅读sea.js源码小结","slug":"阅读sea-js源码小结","date":"2016-06-26T04:59:35.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/06/26/阅读sea-js源码小结/","link":"","permalink":"https://sfegsq.github.io/2016/06/26/阅读sea-js源码小结/","excerpt":"想解决的问题 恼人的命名冲突 烦琐的文件依赖 对应带来的好处 Sea.js 带来的两大好处： 通过 exports 暴露接口。这意味着不需要命名空间了，更不需要全局变量。这是一种彻底的命名冲突解决方案。 通过 require 引入依赖。这可以让依赖内置，开发者只需关心当前模块的依赖，其他事情 Sea.js 都会自动处理好。对模块开发者来说，这是一种很好的 关注度分离，能让程序员更多地享受编码的乐趣。","text":"想解决的问题 恼人的命名冲突 烦琐的文件依赖 对应带来的好处 Sea.js 带来的两大好处： 通过 exports 暴露接口。这意味着不需要命名空间了，更不需要全局变量。这是一种彻底的命名冲突解决方案。 通过 require 引入依赖。这可以让依赖内置，开发者只需关心当前模块的依赖，其他事情 Sea.js 都会自动处理好。对模块开发者来说，这是一种很好的 关注度分离，能让程序员更多地享受编码的乐趣。 API速查12345671. seajs.config2. seajs.use3. define4. require5. require.async6. exports7. module.exports sea.js的执行过程启动用script标签引入sea.js文件，seajs.config(data)启动配置函数，config函数会会合并所有config配置，seajs.use = function(ids, callback),启用主脚本 运行过程主脚本启动之后，首先利用request模块请求主脚本(生成script标签插入head标签中)，然后根据正则解析模块define的依赖，并对依赖递归解析其依赖。在运行过程中，通过监听发布者模式，系统内置了8个事件，可用于开发插件。12345678resolve -- 将 id 解析成为 uri 时触发load -- 开始加载文件时触发fetch -- 具体获取某个 uri 时触发request -- 发送请求时触发define -- 执行 define 方法时触发exec -- 执行 module.factory 时触发config -- 调用 seajs.config 时触发error -- 加载脚本文件出现 404 或其他错误时触发 全局挂载所有相关数据最后全部挂载在window.seajs下，包括方法及模块数据。 小知识点exports与module.exportsexports 仅仅是 module.exports 的一个引用。在 factory 内部给 exports 重新赋值时，并不会改变 module.exports 的值。因此给 exports 赋值是无效的，不能用来更改模块接口。 1234567//源码如下// Exec factoryvar factory = mod.factory;var exports = isFunction(factory) ? factory.call(mod.exports = &#123;&#125;, require, mod.exports, mod) : factory 关于动态依赖有时会希望可以使用 require 来进行条件加载： 1234if (todayIsWeekend) require(\"play\");else require(\"work\"); 但请牢记，从静态分析的角度来看，这个模块同时依赖 play 和 work 两个模块，加载器会把这两个模块文件都下载下来。 这种情况下，推荐使用 require.async 来进行条件加载。 12345//sea.js源码如下require.async = function(ids, callback) &#123; //可传入回调函数 Module.use(ids, callback, uri + \"_async_\" + cid()) //——async_英语标识这个脚本是异步加载的，cid用于清除缓存 return require //返回require方便链式调用&#125; 在开发时，Sea.js 是如何知道一个模块的具体依赖呢？a.js 1234define(function(require, exports) &#123; var b = require('./b'); var c = require('./c');&#125;); Sea.js 在运行 define 时，接受 factory 参数，可以通过 factory.toString() 拿到源码，再通过正则匹配 require 的方式来得到依赖信息。依赖信息是一个数组，比如上面 a.js 的依赖数组是：[‘./b’, ‘./c’] 123456//源码如下// Parse dependencies according to the module factory codeif (!isArray(deps) &amp;&amp; isFunction(factory)) &#123; deps = typeof parseDependencies === \"undefined\" ? [] : parseDependencies(factory.toString()) //parseDependencies是利用正则解析依赖的一个函数&#125; 时间出发函数Emit1234567891011121314151617// Emit event, firing all bound callbacks. Callbacks receive the same// arguments as `emit` does, apart from the event namevar emit = seajs.emit = function(name, data) &#123; var list = events[name] if (list) &#123; // Copy callback lists to prevent modification list = list.slice() // Execute event callbacks, use index because it's the faster. for(var i = 0, len = list.length; i &lt; len; i++) &#123; list[i](data) &#125; &#125; return seajs&#125; 主要看这个部分list = list.slice(),注释是防止拷贝该时间的回调函数，防止修改，困惑了一下。 原因是Javascript中赋值时，对于引用数据类型，都是传地址。所以这里，如果想防止触发事件的过程中回调函数被更改，必须对这个list数组进行拷贝，而并非只是将list指向events[name]的地址。 根据debug值配置是否删除动态插入的脚本1234// Remove the script to reduce memory leak if (!data.debug) &#123; head.removeChild(node) &#125; 这里思考了蛮久，为什么可以删除动态插入的脚本？这样脚本还会生效吗？ 首先，必须了解计算机内存分为 静态数据区 (用来存放程序中初始化的全局变量的一块内存区域) 代码区 (通常用来存放执行代码的一块内存区域) 栈区 (栈在进程运行时产生，一个进程有一个进程栈。栈用来存储程序临时存放的局部变量，即函数内定义的变量 不包括static 类型的。函数被调用时，他的形参也会被压栈。 堆区 (用于存放进程运行中被动态分配的内存段，它的大小并且不固定，可动态扩展。当进程调用malloc等分配内存时，新分配的内存被动态的添加到堆上（堆被扩大），当利用free等函数释放内存时，被释放的‘ 内存从堆中剔除) 这些在Javascript中都被屏蔽了，大部分时候我们都不需要考虑，但是如果要深入了解的话，则是必须要知道的知识。 首先HTML文档中的JS脚本在计算机中作为指令被读入内存，之后开始执行，CPU开始一条一条指令读取，比如，读取到var cool = &quot;wilson&quot;时，就会在内存中分配一个6字符大小的内存，一个function也一样会在内存中占据一定大小。所以，当指令全部运行完之后，指令本身其实已经没有用了，但是仍然给占据了一部分内存。当你点击按钮触发一个回调函数时，并非去读取指令，而是读取内存中这个回调函数的地址。所以删除这些动态加载的JS文件是没有问题的。 ID 和路径匹配原则所谓 ID 和路径匹配原则 是指，使用 seajs.use 或 require 进行引用的文件，如果是具名模块（即定义了 ID 的模块），会把 ID 和 seajs.use 的路径名进行匹配，如果一致，则正确执行模块返回结果。反之，则返回 null。 对 module.exports 的赋值需要同步执行，不能放在回调函数里。下面这样是不行的123456789101112131415161718192021// x.jsdefine(function(require, exports, module) &#123; // 错误用法 setTimeout(function() &#123; module.exports = &#123; a: \"hello\" &#125;; &#125;, 0);&#125;);//在 y.js 里有调用到上面的 x.js:// y.jsdefine(function(require, exports, module) &#123; var x = require('./x'); // 无法立刻得到模块 x 的属性 a console.log(x.a); // undefined&#125;);","categories":[{"name":"前端","slug":"前端","permalink":"https://sfegsq.github.io/categories/前端/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"}]},{"title":"ShellScript编程小结","slug":"ShellScript编程小结","date":"2016-05-20T04:56:03.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/05/20/ShellScript编程小结/","link":"","permalink":"https://sfegsq.github.io/2016/05/20/ShellScript编程小结/","excerpt":"前言shell作为编程中不可或缺的一部分，平日里，我们经常会在shell中输入一些命令。有时候也需要完成一些复杂的操作，重复的输入多条相同的命令，过于费时和无趣。所以掌握shell script就显得非常有必要了，可以让你用编程的方式调用繁多的命令行工具。 最近，正好碰上一个一直拖着的需求，便抄起了shell解决掉了，写了人生中第一段shell script代码。","text":"前言shell作为编程中不可或缺的一部分，平日里，我们经常会在shell中输入一些命令。有时候也需要完成一些复杂的操作，重复的输入多条相同的命令，过于费时和无趣。所以掌握shell script就显得非常有必要了，可以让你用编程的方式调用繁多的命令行工具。 最近，正好碰上一个一直拖着的需求，便抄起了shell解决掉了，写了人生中第一段shell script代码。 需求如下 从一个文件夹中获取一个文本，这个文本里记录了链接以及他对应的版本号。并到另外一个html文件夹中遍历所有html文件，将其中的链接中的@VERSION替换为相应的版本号。 流程 创建一个shell脚本，例如touch test.sh 在命令行中输入chmod +x ./test.sh，使这个文件变成一个可执行文件 在这个脚本文件中书写代码，诸如”find .” 在命令行中输入./test.sh，即可运行。 结果，输出当前目录下所有文件夹与文件的名称 shell script介绍和所有的编程一样，shell脚本主要由自身语法，以及繁多的linux命令构成。我们只需要学习shell脚本自身的语法以及一些常用的linux命令即可，需要的时候可以查询相应的linux命令。 shell script语法因为篇幅限制，所以仅列出提纲，具体的学习可以参考文末的参考资料 变量 数组 传参 运算符 输入输出以及重定向 测试 test 流程控制 函数 文件包含 linux命令linux命令是linux强大的一个重要基础，分为以下5个部分。编程中，用对了指令可以减少许多工作。也正因为繁多的指令，给shell脚本带来了足够的能力。 系统管理 网络管理 软件 | 打印 | 开发 | 工具 文件目录管理 硬件 | 监测 | 内核 | Shell 实例讲解代码分为三个函数，第一个配置初始化函数init(),第二个遍历文件夹函数walk()，第三个是对html文件的处理函数，运用sed正则替换html中的链接html_into_ver() 想要实际操作的可以拿这个kindle文字伴侣进行测试,这个项目是用去哪儿的前端构建工具fekit构建的。脚本名字为export_html，可以在命令行中输入./export_html进行测试，会多出一个export_html的文件夹，里面存放着所有的输出html文件。 github项目地址 配置函数init()这一部分主要是默认配置的设置123456789101112131415161718192021222324252627function init()&#123; # html_into_ver配置区 de_reg_rule=&quot;\\(.*\\)\\(http://localhost/kindleClipingDeal/prd/\\)\\(.*\\)\\(@VERSION\\)\\(.*\\)\\&quot;.*&quot; de_cur_prefix=&quot;http://localhost/kindleClipingDeal&quot; #当前prd前面的路径 de_replace_prefix=&quot;http://wilsonliu.cn/kindleClipingDeal&quot; #当前前缀替换后路径 de_ver_file=&quot;ver/versions.mapping&quot; #当前存储版本号码的文件 de_target_dir=&quot;export_html&quot; #将html修改后，输出的目标文件夹 de_source_dir=&quot;html&quot; # 源文件夹为html # 如果目标文件夹存在，则先删除 if [ -e $&#123;de_target_dir&#125; ]; then rm -rf $&#123;de_target_dir&#125; fi #首先复制源文件夹为输出文件夹，在输出文件夹 cp -rf $&#123;de_source_dir&#125; $&#123;de_target_dir&#125; # walk 的3个参数配置 de_dir_to_walk=$&#123;de_target_dir&#125; #将要遍历操作文件夹 de_walk_file_callback=&quot;html_into_ver&quot; #文件处理回调函数 de_walk_dir_callback=&quot;&quot; #文件夹处理回调函数，非必要，可为空 # 调用walk函数 walk $de_dir_to_walk $de_walk_file_callback $de_walk_dir_callback&#125;init; # 程序初始化执行 遍历文件夹函数walk()1234567891011121314151617181920212223242526&lt;!-- #!/bin/bash --&gt;# walk 函数 三个配置# 第一个是遍历的目标文件，第二个是对文件处理的调用函数,第三个是对文件夹处理的调用函数，# 调用函数 有两个输入一个是遍历的文件夹，一个是当前文件夹function walk()&#123; # $&#123;1&#125;为调用walk函数时传入的第一个参数 for file in `ls $&#123;1&#125;` #ls输出当前路径下的所有文件以及文件夹，利用for in分别对其进行操作 do path=$&#123;1&#125;&quot;/&quot;$&#123;file&#125; #拼接当前将要处理的文件或文件夹路径 if [ -d $&#123;path&#125; ] #-d 是测试其是否是文件夹 then # 如果存在回调函数，则调用文件处理回调函数 并且输入遍历的目标文件夹以及当前文件夹路径 if [ $&#123;3&#125; ] # $&#123;3&#125; 即为调用walk时输入的第三个参数，应该为文件夹处理函数 then $3 $1 $&#123;path&#125; #调用$&#123;3&#125;指向的函数，并传入当前所在路径以及要处理的文件夹路径 fi # 对当前文件夹继续调用walk函数 walk $&#123;path&#125; $2 $3 #遍历文件夹 else # 调用文件处理函数对文件进行处理，并输入遍历的目标文件夹以及当前文件路径 $2 $1 $&#123;path&#125; fi done&#125; html文件处理函数html_into_ver()利用sed流编辑器进行正则匹配与替换12345678910111213141516171819202122232425262728293031# 将html中的所有链接中的 VERSION 改为正确的版本号码function html_into_ver()&#123; # 获取当前$2的html文件内所有的链接地址 link=`sed -n &quot;s#$&#123;de_reg_rule&#125;#\\2\\3\\4\\5#p&quot; $2` # 获取当前$2的html文件内所有的连接路径 link_path=`sed -n &quot;s#$&#123;de_reg_rule&#125;#\\3\\5#p&quot; $2` i=1 while [ `echo $&#123;link&#125; | cut -d &quot; &quot; -f $i` ]; do cur_link=`echo $&#123;link&#125; | cut -d &quot; &quot; -f $i` #html中的完整路径 cur_link_path=`echo $&#123;link_path&#125; | cut -d &quot; &quot; -f $i` #html中的完整路径 cur_version=`sed -n &quot;s*$&#123;cur_link_path&#125;#**p&quot; $&#123;de_ver_file&#125;` #当前文件的版本号 cur_replace_link=`echo $&#123;cur_link&#125; | sed -n &quot;s#\\(.*\\)\\(@VERSION\\)\\(.*\\)#\\1@$&#123;cur_version&#125;\\3#p&quot;` #当前替代cur_link的链接 #因为sed -i这个命令在mac与linux上存在差异，mac上强制要求sed -i 后多一个参数用来指替备份文件名，可以用空字符来解决，mac上输出为Darwin，依次判断 if [ `uname -s` == &quot;Darwin&quot; ]; then sed -i &quot;&quot; &quot;s#$&#123;cur_link&#125;#$&#123;cur_replace_link&#125;#&quot; $&#123;2&#125; #直接对当前文件进行VERSION修改 else sed -i &quot;s#$&#123;cur_link&#125;#$&#123;cur_replace_link&#125;#&quot; $&#123;2&#125; #直接对当前文件进行VERSION修改 fi # 循环的条件 i=`expr $i + 1` done #统一修改链接前缀 if [ `uname -s` == &quot;Darwin&quot; ]; then sed -i &quot;&quot; &quot;s#$&#123;de_cur_prefix&#125;#$&#123;de_replace_prefix&#125;#g&quot; $&#123;2&#125; #修改链接的前置部分 else sed -i &quot;s#$&#123;de_cur_prefix&#125;#$&#123;de_replace_prefix&#125;#g&quot; $&#123;2&#125; #修改链接的前置部分 fi&#125; 写在最后shell编程的好处在于可以批量化自动化操作以提高开发效率，同时也可以用来解决许多问题，本身并不复杂，简单易学，功能强大。希望大家都能够掌握这一工具。 参考资料 shell 教程 |菜鸟教程 linux命令大全","categories":[{"name":"前端","slug":"前端","permalink":"https://sfegsq.github.io/categories/前端/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"}]},{"title":"HTTP内容分发","slug":"HTTP内容分发","date":"2016-05-01T05:18:52.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/05/01/HTTP内容分发/","link":"","permalink":"https://sfegsq.github.io/2016/05/01/HTTP内容分发/","excerpt":"Web主机托管对内容资源的存储协调以及管理的职责统称为Web主机托管。","text":"Web主机托管对内容资源的存储协调以及管理的职责统称为Web主机托管。 虚拟服务器请求却反主机信息HTTP/1.0中的一个设计缺陷会使虚拟主机托管者疯狂。HTTP/1.0中没有为共享的Web服务器提供任何方法来识别要访问的是所托管的哪个虚拟网站。HTTP/1.0请求在报文中只发送URL的路径部分，如果要访问http://www.baidu.com/index.html，浏览器会连接到服务器http://www.baidu.com,但HTTP/1.0请求中却只提到GET /index.html，没有提到主机名。如果服务器虚拟托管了许多个站点，就没有足够的信息能指出要访问的是哪个虚拟主机网站。 并且HTTP反向代理和拦截代理也都需要明确的站点信息。 因此HTTP/1.1的确要求服务器能够处理HTTP报文请求行上的完整URL，但将现存的应用程序都升级都这个规范还需要时间，在此期间，涌现出了以下4种技术。 通过URL路径进行虚拟主机托管 —— 在URL中增添专门的路径部分，以便服务器判断是哪个网站 通过端口号进行主机托管 —— 为每个站点分配不同的端口号，这样请求就由web服务器的单独实例来处理 通过IP地址进行主机托管 —— 为不同的虚拟站点分配专门的IP地址 通过Host首部进行主机托管 镜像的服务器集群服务器集群是一排配置相同的Web服务器，互相可以替换。每个服务器上的内容可以通过镜像复制，这样当某个服务器出问题的时候，其他的可以顶上。镜像的服务器常常组成层次化的关系。某个服务器可能充当“内容权威”——它含有原始内容(可能就是内容作者上传的那个服务器)。这个服务器称为主原始服务器(master origin server)。从主原始服务器接收内容的镜像服务器称为复制原始服务器(replica origin server)。一种简单的部署服务器集群的方法是用网络交换机把请求分发给服务器。托管在服务器上的每个网站的IP地址就设置为交换机的IP地址。 镜像Web服务器可以在不同的地点包含同样内容的副本。可以有以下两种方法把客户端的请求导向特定的服务器。 HTTP重定向 —— 该内容的URL会解析到主服务器的IP地址，然后它会发生重定向到复制服务器 DNS重定向 —— 该内容的URL会解析到4个IP地址，DNS服务器可以选择发送给客户端的IP地址 内容分发网络 CDN简单地说，内容分发网络就是对特定内容进行分发的专门网络。这个网络中的节点可以是Web服务器，反向代理或缓存。 反向代理反向代理缓存可以像镜像服务器一样接收服务器请求，它们代表原始服务器中的一个特定集合来接收服务器请求。(根据内容所在的IP地址的广告方式，这是有可能的，原始服务器和反向代理缓存之间通常有协作关系，到特定的原始服务器的请求就由反向代理缓存来接收。) CDN中的代理缓存与反向代理不同，传统的代理缓存能够收到发往任何Web服务器的请求(在代理缓存与原始服务器之间不需要有任何工作关系或IP地址约定)。 重定向和负载均衡由于HTTP应用程序总是要做下列3件事情，所以在现代网络中重定向是普遍存在的: 可靠地执行HTTP事务 最小化时延 节约网络带宽出于这些原因，web内容通常分布在很多地方。这么做是出于可靠性的考虑。这样如果一个位置出现了问题，还有其他的可用；如果客户端能够访问较劲的资源，就可用更快的收到所请求的内容，以降低响应时间；将目标服务器分散，还可以减少网络拥塞。可用将重定向当做一组有助于找到”最佳”分布式内容的技术。而重定向和负载均衡总是共存的。 重定向方法通用的重定向方法 HTTP重定向 DNS重定向 任播寻址 IP MAC转发 IP地址转发 代理与缓存重定向技术 显示浏览器配置 代理自动配置(PAC) Web Proxy代理自动发现协议(WPAD) Web缓存协调协议(WCCP) 因特网缓存协议(ICP) 缓存分组路由协议(CARP) 超文本缓存协议(HTCP) 通用的重定向方法HTTP重定向与其他形式的重定向相比，HTTP重定向的优点之一就是重定向服务器知道客户端IP地址，理论上来讲，它可以做出更合理的选择。 HTTP重定向可以在服务器间引导请求，但有以下几个缺点。 需要原始服务器进行大量处理来判断要重定向到哪台服务器上去。有时，发布重定向所需的处理量几乎与提高页面本身所需的处理量一样。 增加了用户时延，因为访问页面时要进行两次往返。 如果重定向服务器出故障，站点就会瘫痪。 DNS重定向DNS允许将几个IP地址关联到一个域中，可以配置DNS解析程序，或对其进行编程，以返回可变的IP地址。解析程序返回IP地址时，所基于的原则可以很简单(轮转)，也可以很复杂(比如查看几台服务器上的负载均衡，并返回负载最轻的服务器的IP地址)。 DNS缓存带来的影响 DNS对服务器的每次查询都会得到不同的服务器地址序列，所以DNS地址轮转会将负载分摊。但是这种负载均衡也并不完美，因为DNS查找结果可能会被客户端记住并被反复重用，以减少DNS查找的开销，而且有些服务器也愿意保持与一台客户端的联系。 其他基于DNS的重定向算法 负载均衡算法 邻接路由算法 故障屏蔽算法 任播寻址在任播寻址中，几个地理上分散的Web服务器拥有完全相同的IP地址，而且会通过骨干路由器的”最短路径”路由功能将客户端的请求发送给离它最近的服务器。要使这种方法工作，每个路由器都要想邻近的骨干路由器广告，表明自己是一台路由器。 IP MAC转发支持MAC转发的第四次交换机通常会将请求转发给几个代理缓存，并在它们之间平衡负载，因为MAC地址转发是点对点的，所以服务器或代理只能位于离交换机一跳远的地方。 IP地址转发在IP地址转发中，交换机或其他第四层设备会检测输入分组中的TCP/IP地址，并通过修改目的IP地址(不是目的MAC地址)，对分组进行相应的转发。 代理的重定向方法 显式配置浏览器设置 代理自动配置 PAC Web代理自动发现协议 WPAD","categories":[{"name":"网络","slug":"网络","permalink":"https://sfegsq.github.io/categories/网络/"}],"tags":[{"name":"HTTP权威指南","slug":"HTTP权威指南","permalink":"https://sfegsq.github.io/tags/HTTP权威指南/"}]},{"title":"HTTP实体和编码","slug":"HTTP实体和编码","date":"2016-04-29T05:18:20.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/29/HTTP实体和编码/","link":"","permalink":"https://sfegsq.github.io/2016/04/29/HTTP实体和编码/","excerpt":"实体和编码每天都有数以亿计的各种媒体对象经由HTTP传送，如图像，文本，影片以及软件程序等。HTTP会确保它的报文被正确的传送，识别，提前以及适当的处理，则需要满足以下条件。","text":"实体和编码每天都有数以亿计的各种媒体对象经由HTTP传送，如图像，文本，影片以及软件程序等。HTTP会确保它的报文被正确的传送，识别，提前以及适当的处理，则需要满足以下条件。 可以被正确的识别(通过Content-Type首部说明媒体格式，Content-Language首部说明语言)，以便浏览器和其他客户端能够正确的处理内容 可以被正确的解包(通过Content-Length首部和Content-Encoding首部) 是最新的(通过实体验证码和缓存过期控制) 符合用户的需要(基于Accept系列的内容协商首部) 在网络上可以快速有效地传输(通过范围请求，差异编码以及其他数据压缩方法) 完整到达，未被篡改过(通过传输编码首部和Content-MD5校验和首部) 为了实现上述目标，HTTP/1.1版本定义了以下10个基本实体首部字段。 Content-Type Content-Length Content-Language Content-Encoding Content-Location Content-Range Content-MD5 Last-Modified Expires Allow Etag Cache-Control Content-Length:实体的大小Content-Length首部指示出报文中编码后实体主体的字节大小。使用Content-Length首部是为了能够检测出服务器崩溃而导致的报文截尾，并对共享持久连接的多个报文进行正确的分段。 Content-Length首部对于持久连接是必不可少的，如果响应通过持久连接传输，就可能有另一条HTTP响应紧随其后。客户端通过Content-Length首部就可以知道报文在何处结束，下一条报文从何处开始。因为连接是持久的，客户端无法依赖连接关闭来判别报文的结束。 在使用分块编码(chunked encoding)时，可以没有Content-Length，此时，数据是分为一系列的块来发送的，每块都有大小说明。 HTTP/1.1规范中建议对于带有主体但没有Content-Length首部的请求，服务器如果无法确定报文的长度，就应当发送400 Bad Request响应或411 Length Required响应，后一种表明服务器要求收到正确的Content-Length首部。 实体摘要为检测实体主体的数据是否被修改过，发送方可以在生成初始的主体时，生成一个数据的校验和。Content-MD5首部是在对内容作了所有需要的内容编码之后，还没做任何传输编码之前，计算出来的。 媒体类型和字符集Content-Type首部字段说明了实体主体的MIME类型，同时还支持可选的参数来进一步说明内容的类型。Content-Type: text/html; charset=iso-8859-4 多部分媒体类型MIME中的multipart电子邮件报文中包含多个报文，它们合在一起作为单一的复杂报文发送。每一部分都是独立的，有各自的描述其内容的集，不同的部分之间用分界字符串连接在一起。HTTP也支持多部分主体。不过，通常只用在下列两种情形之一:提交填写好的表格，或是作为承载若干文档片段的范围响应。HTTP使用Content-Type:multipart/form-data或Content-Type:multipart/mixed这样的首部以及多部分主体来发送这种请求。 内容编码 Content-EncodingHTTP应用程序有时在发送之前需要对内容进行编码，当内容经过编码之后，编好码的数据就防止实体主体中，像往常一样发送给接收方。此时Content-Length变为编码后的长度。同时，我们不希望服务器用客户端无法解码的方式来对内容进行编码，因此，客户端需要把自己能够支持的内容编码列表防止请求的Accept-Encoding首部。 传输编码和分块编码 Transfer-Encoding使用传输编码是为了改变报文中的数据在网络上传输的方式。 分块编码分块编码是HTTP规范唯一定义的传输编码方式。分块编码把报文分割为若干个大小已知的块。块之间是紧挨着发送的，这样就不需要在发送之前就知道整个报文的大小了。 范围请求 Range范围请求是指客户端实际上只请求文档的一部分，或者说某个范围。比如，下载电影下到一半网络故障，连接中断了，此时可利用范围请求来继续下载。Range: bytes=4000-代表客户端请求的是文档开头4000字节以后的步伐内容。 Range首部在流行的点对点(Peer-to-Peer)文件共享客户端软件中得到广泛的应用，他们从不同的对等实体同时下载多媒体文件的不同部分。 差异编码差异编码是HTTP协议的一个扩展，它通过交换对象改变的部分而不是完整的对象来优化传输性能。 请求报文12A-IM: diffe //Accept-Instance-ManipulationIf-None-Match: ababdisdksada //验证是否新鲜 响应报文123IM:diffe //差异编码的算法Etag: zdsdsfsafsd //更新后的版本号Delta-base: ababdisdksada //差异算法基于的Etag","categories":[{"name":"网络","slug":"网络","permalink":"https://sfegsq.github.io/categories/网络/"}],"tags":[{"name":"HTTP权威指南","slug":"HTTP权威指南","permalink":"https://sfegsq.github.io/tags/HTTP权威指南/"}]},{"title":"端到端的数据","slug":"端到端的数据","date":"2016-04-28T05:32:08.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/28/端到端的数据/","link":"","permalink":"https://sfegsq.github.io/2016/04/28/端到端的数据/","excerpt":"从网络的观点看，应用程序间彼此发送信息。每个消息只是一个未解释的字符串。然而，从应用程序的观点看，这些消息包含各种类型的数据——整型数组，视频帧，文本行，数字图像等。因此，我们需要考虑如何更好地对应用程序要转换成字符串的各种不同类型数据进行编码。 编码实质上涉及两个问题。第一是接收方能从信号中提取出于传送方发送的消息相同的消息，这就是组帧的问题。第二是尽可能地提高编码效率。","text":"从网络的观点看，应用程序间彼此发送信息。每个消息只是一个未解释的字符串。然而，从应用程序的观点看，这些消息包含各种类型的数据——整型数组，视频帧，文本行，数字图像等。因此，我们需要考虑如何更好地对应用程序要转换成字符串的各种不同类型数据进行编码。 编码实质上涉及两个问题。第一是接收方能从信号中提取出于传送方发送的消息相同的消息，这就是组帧的问题。第二是尽可能地提高编码效率。第一个问题，在发送方和接收方看到同样的数据时，就出现了发送方和接收方要统一消息格式的问题，通常称为表示格式(presentation format)。第二个问题，提高编码效率。实际上，人们朝着两个相反的方向努力，一方面，我们希望在数据中加入尽可能多的冗余，以便即使消息出现了错误，接收方仍然能够提取出正确的数据。另一方面，我们希望尽可能从数据中删掉更多的冗余，以便能用更少的位去编码。这就是数据压缩的目的(data compression) 表示格式化因为计算机用不同的方法表示数据，使得编码问题复杂。另外，不同应用程序使用不同的语言编码，而且即使使用同一种编程语言，也可能有不止一个编译程序，因此数据格式不统一。 分类方法数据类型第一个问题是系统打算支持什么样的数据类型。通常，我们可以将由参数排列机制支持的类型分为三级。每一级都使参数排列系统面对更复杂的任务。 在最低一级，参数排列系统对基本类型(base type)的某个集合进行操作。通常，基本类型包括证书，浮点数和字符。系统还可以支持序数类型和布尔型。如上所述，基本类型集合的含义是指，编码进程必须能将每一基本类型从一种表示法转换为另一种表示法，如，把整形从大字节序转换为小字节序表示。 再上一级是扁平类型(flat type):结构和数组。为了按字的边界对齐字段，编译程序在编译应用程序时习惯于在组成结构的字段之间加入填充。参数排列系统通常将结构压缩使得他们不含填充。 在最高一级，参数排列系统必须处理复杂类型(complex type)：使用指针建立的类型。也就是说，一个程序要发送给另一个程序的数据结构可以不包括在某个单一的结构中，而可能包含从一个结构指向另一结构的指针。树就是包含指针的复杂类型的一个很好的例子。显然，数据编码器必须为网上传输准备好数据结构，因为指针是通过内存寻址实现的，而且驻留在一台机器上某个内存地址的结构并不意味着在另一机器上有相同的驻留地址。换句话说，参数排列系统必须串行化(serialize)复杂数据结构。 转换策略一般有两个选择：标准中间形式和接收方调整。 标准中间形式的概念就是要确定每一种类型的所有外部表示法；在发送数据前，发送主机将数据由其内部表示转换成这种数据的外部表示，而在接收数据的过程中，接收主机又把这种数据的外部表示转换成本地表示。 接收方调整允许发送方用其内部格式传输数据；发送方不进行基本类型的转换，但通常要压缩和展开较复杂的数据结构。然后接收方负责把数据从发送方的格式翻译成其本地的格式。用这种策略的问题是，每个主机必须准备好转换来自所有其他机器体系结构的数据。 标记参数排列中的第三个问题是接收方如何知道它接收的消息中包含什么类型的数据。有两种常用的方法：带标记(tagged)数据和不带标记(untagged)数据。 标记是指包含在一个消息中的任何附加消息，它有助于接收方解码消息。如类型标记，长度标记，体系结构标记。不带标记，则需要在应用程序中指定数据信息。 桩 stub桩是实现参数排列的一段代码。在客户端，桩把过程参数排列成可以通过网络协议传输的消息。在服务器端，桩反过来把消息转换成一组用来调用远程过程的参数。 例子 XDR,ASN.1,NDRXDR外部数据表示法(External Data Representation)是用在SunRPC上的网络格式。 ASN.1抽象语法表示法1(Abstract Syntax Notation One)是一个ISO标准，他定义网上发送数据的一种表示方法。ASN.1用三元组形式表示每个数据项：&lt;tag,length,value&gt; NDR网络数据表示法(Network Data Representation)是用于分布式计算环境的数据编码标准。NDR使用的是接收方调整方式。NDR会在每个消息前插入一个体系结构标记，而对单个数据项是不带标记的。 数据压缩压缩算法有两类。 一类称为无损压缩(lossless compression)，保证从压缩/解压过程恢复的数据与原始数据完全相同。无损压缩算法常用于压缩文件数据，比如可执行代码，文本文件和数值数据，因为处理这种文件数据的程序不允许数据有错。 相反，有损压缩(lossy compression)不能保证接收到的数据与发送的数据完全相同。这是因为，有损压缩算法会删除以后不能恢复的信息。有损压缩常用于压缩静止图像，视频和音频数据。 无损压缩算法行程编码 RLE行程编码(Run Length Encoding)是一种极具简单性的压缩技术。其思想是，对连续出现的一个符号，只用此符号的一个副本加上符号出现的次数来替代；所以起名为“行程”。例如AAABBCDDDD串就被编码为3A2B1C4D。 差分脉码调制 DPCM首先输出一个参考符号，然后输出数据中的每个符号与参考符号的差。例如，使用符号A作为参考符号，字符串AAABBCDDDD将编码为A0001123333，因为A和参考符号相同，B和参考符号的差为1，依次类推。当差较小时，可以用比符号本身更少的比特去编码，在这个例子中，差的范围是0~3，每个符号可以用两个比特来表示，而用完全字符，就需要用7或8个比特。另外一种略有差别的方法称为delta编码(delta encoding)，简单地把一个符号编码为与前一个符号的差。比如，AAABBCDDDD将被表示为A001011000，delta编码后还可以再进行RLE(行程编码)。 基于字典的方法基于字典的压缩算法，其思想是为你希望在数据中查找的可变长字符串(把他们看做常用短语)建立一个字典，当这些串出现在数据中时，用相应的字典索引去替代每个串。例如，”compression”一词在特定的词典中的索引为4978；因为在/usr/share/dict/words文件中它是第4978个词。要压缩一个文本的正文，每次当这个串出现时，就会用4978来代替。由于在这个特定的字典中只有25000多个词，需要用15个比特来编码这个索引，意味着串”compression”可以用15个比特而不是按字符串编码为77个比特来表示。 图像压缩(JPEG)联合图像专家组(Joint Photographic Expert Group)压缩在三个阶段完成。在压缩端，以每次一个8 * 8数据块让图像经过这是哪个阶段。第一个阶段是对这个数据块进行离散余弦变换(Discrete Cosine Transform)。第二个阶段将产生的信号进行量化，并且在量化过程中丢失信号所包含的最低有效信息。第三阶段编码出最终的结果，但在编码过程中，为前两个阶段完成的有损压缩增添了一个无损压缩的成分。 视频压缩(MPEG)运动图像专家组(Moving Picture Experts Group)。粗略的说，运动图像(即视频)是简单地以某个视频速度连续显示的静止图像(也称为帧或图片)。 帧类型MPEG接收一个视频帧序列作为输入，然后将其压缩成3种类型的帧，分别称为I帧(内部图像)，P帧(预测图像)和B帧(双向预测图像)。每个输入的帧被压缩成这3种类型之一。I帧可以作为参考帧，它们是独立的，即不依赖前面的帧也不依赖后面的帧。粗略的说，I帧是视频源对应帧的JPEG压缩形式。P帧和B帧不是独立的；它们定义相对某个参考帧的差。更明确的说，P帧说明与前一个I帧的差，而B帧给出前一个I帧或P帧与后一个I帧或P帧之间的插值。 音频压缩(MP3)MP3使用MPEG压缩视频所使用的类似的技术。首先，将音频流拆分为某些频率的子波段。其次，每个子波段被分成一系列的块。最后，像MPEG视频一样，每个块用改进的DCT算法进行变化，量化和赫夫曼编码","categories":[{"name":"网络","slug":"网络","permalink":"https://sfegsq.github.io/categories/网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://sfegsq.github.io/tags/计算机网络/"}]},{"title":"HTTP的识别,认证与安全","slug":"HTTP的识别-认证与安全","date":"2016-04-28T05:17:44.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/28/HTTP的识别-认证与安全/","link":"","permalink":"https://sfegsq.github.io/2016/04/28/HTTP的识别-认证与安全/","excerpt":"第三部分的4章提供了一系列的技术和机器，可用来跟踪身份，进行安全性检测，控制对内容的访问。","text":"第三部分的4章提供了一系列的技术和机器，可用来跟踪身份，进行安全性检测，控制对内容的访问。 客户端识别与cookie机制 第十一章HTTP最初是一个匿名，无状态的请求/响应协议。服务器处理来自客户端的请求，然后向客户端回送一条响应。web服务器几乎没有什么信息可以用来判定是哪个用户发送的请求，也无法记录来访用户的请求序列。 用户识别机制 承载用户身份信息的HTTP首部 客户端IP地址跟踪，通过用户的IP地址对其进行识别 用户登录，用认证方式来识别用户 胖URL，一种在URL中嵌入识别信息的技术 cookie，一种功能强大且高效的持久身份识别技术 HTTP首部下表给出了7种常见的用来承载用户相关信息的HTTP请求首部。后面3个首部是扩展类型的请求首部。 首部名称 描述 From 用户的E-mail地址 User-Agent 用户的浏览器软件 Referer 用户是从这个页面上依照链接跳转过来的 Authorization 用户名和密码 Client-IP 客户端的IP地址 X-Forwarded-For 客户端的IP地址 Cookie 服务器产生的ID标签 用户登录为了使web站点的登录更加简便，HTTP中包含了一种内建机制，可以用WWW-Authenticate首部和Authorization首部向web站点传送用户的相关信息。一旦登录，浏览器就可以不断地在每条发往这个站点的请求中发送这个登录信息了。 缺点：保密性不强，不能跨站点，不同的站点需要重新输入账户密码。 胖URL可以通过胖URL将服务器上若干个独立的HTTP事务捆绑成一个”会话”或”访问”。用户首次访问这个web站点时，会生成一个唯一的ID，用服务器可以识别的方式将这个ID添加到URL中，然后服务器就会将客户端重新导向这个胖URL。 问题： 丑陋的URL 无法共享URL 破坏缓存 额外的服务器负荷 逃逸口 在会话间是非持久的 cookiecookie是当前识别用户，实现持久会话的最好方式。最初由网景公司开发，但现在所有的主要浏览器都支持他。 cookie的类型可以笼统的分为:会话cookie和持久cookie。会话cookie和持久cookie的唯一区别就是他们的过期时间。 如果设置了Discard参数，或者没有设置Expires或Max-Age参数来说明扩展的过期时间，这个cookie就是一个会话cookie。 不同的站点使用不同的cookiecookie的域属性产生cookie的服务器可以向Set-Cookie响应首部添加一个Domain属性来控制哪些站点开业看到那个cookie。1Set-cookie: user=&quot;wilson&quot;;domain=&quot;wilsonliu.cn&quot; 则用户访问的任何以wilsonliu.cn结尾的站点都会讲此cookie发布出去。 cookie的路径属性cookie规范甚至允许用户将cookie与部分web站点关联起来。可以通过Path属性来实现这一功能。1Set-cookie: year=&quot;21&quot;;domain=&quot;wilsonliu.cn&quot;;path=/year/ 则只会在/year/下的站点时才会发布此cookie。 cookie成分cookie版本0 (Netscape)Set-Cookie首部 Name=Value Expires domain Path Secure cookie首部客户端发送请求时，会将所有与域，路径，安全过滤器匹配的未过期的cookie都发送给这个站点。 cookie版本1 (RFC 2965)Set-Cookie2 Name = Value Version Comment CommentURL Discard domain Max-Age Path Port Secure cookie首部版本1的cookie会带回与传输的每个cookie相关的附加信息，用来描述每个cookie途径的过滤器。每个匹配的cookie都必须包含来自相应的Set-Cookie2首部的所有Domain,Port和Path属性。 基本认证机制 第十二章基本认证质询首部 12HTTP/1.0 401 UnauthorizedWWW-Authenticate: Basic realm=quoted-realm 响应首部(通过base64编码传输) 1Authorization:Basic base64-username-and-password 摘要认证 第十三章基本认证便捷灵活，但极不安全。用户名与密码明文传输，也没有采取任何措施防止对报文的篡改。安全使用基本认证的唯一方式就是将其与SSL配合使用。 摘要认证与基本认证兼容。但却更为安全。 摘要认证的改进 永远不会以明文的方式在网络上发送密码 可以防止恶意用户捕获并重放认证的握手过程 可以有选择地防止对报文内容的篡改 防范其他几种常见的攻击方式 用摘要保护密码摘要认证遵循的箴言是”绝不通过网络发送密码”。客户端不会发送密码，而是会发送一个“指纹”或密码的”摘要”，这是密码的不可逆扰码。 单向摘要摘要是”对信息主体的浓缩”。摘要是一种单向函数，主要用于将无限的输入值转换为有限的浓缩输出值。常见的摘要函数MD5，会将任意长度的字节序列转换为一个128位的摘要。有时也将摘要函数称为加密的校验和，单向散列函数或指纹函数。 用随机数防止重放攻击使用单向摘要就无需以明文形式发送密码，没有哪个而已用户能够轻易地从摘要中解码出原始密码。 但是仅仅隐藏密码并不能避免危险，因为即便不知道密码，也可以截获摘要，并重放给服务器。摘要和密码一样好用。 为防止此类重放攻击的发生服务器可以向客户端发送一个称为随机数(nonce)的特殊令牌，这个数会经常发生变化(可能是每毫秒，或者是每次认证都变化)。客户端在计算摘要之前要先将这个随机数令牌附加到密码上去。 摘要的计算摘要认证的核心就是对公共信息，保密信息和有时限的随机值这个组合的单项摘要。 数据 与安全性相关的数据(A1) ——包含有用户名，密码，保护域和随机数等内容 与报文有关的数据(A2) ——比如URL，请求方法和报文实体，A2有助于防止方法，资源或报文被篡改 预授权在普通的认证方式中，事务结束之前，每条请求都要有一次请求/质询的循环。如果客户端事先知道下一个随机数是什么，就可以取消这个请求/质询循环。 服务器预先在Authentication-Info成功首部中发送下一个随机数 服务器允许在一小段时间内使用同一个随机数 客户端和服务器使用同步的，可预测的随机数生成算法 应该考虑的实际问题 多重质询 差错处理 保护空间 重写URI 缓存 安全性考虑 首部篡改 重放攻击 多重认证机制 词典攻击 恶意代理攻击和中间人攻击 选择明文攻击 存储密码 安全HTTP 第十四章保护HTTP的安全 服务器认证 客户端认证 完整性 加密 效率 普适性 管理的可扩展性 适应性 在社会的可行性 HTTPSHTTPS是最流行的HTTP安全形式，它是由网景公司首创，所有主要的浏览器和服务器都支持此协议。使用HTTPS时，所有的HTTP请求和响应数据在发送到网络之前，都要进行加密。HTTPS在HTTP下面提供了一个传输级的密码安全层——可以使用SSL，也可以使用其后继者，传输层安全(Transport Layer Security,TLS)。 大部分困难的编码及解码工作都是在SSL库中完成的，所以web客户端和服务器在使用安全HTTP时无需过多地修改器协议处理逻辑。在大多数情况下，只需要用SSL的输入/输出调用取代TCP的调用，再增加其他几个调用来配置和管理安全信息就行了。 数字加密 密码 对文本进行编码，使偷窥者无法识别的算法 密钥 改变密码行为的数字化参数 对称密钥加密系统 编/解码使用相同密钥的算法 不对称密钥加密系统 编/解码使用不同密钥的算法 公开密钥加密系统 一种能够使数百万计算机便捷地发送机密报文的系统 数字签名 用来验证报文未被伪造或篡改的校验和 数字证书 由一个可信的组织验证和签发的识别信息 密码密码学基于一种名为密码(cipher)的秘密代码。密码是一套编码方案——一种特殊的报文编码方式和一种稍后使用的相应解码方式的结合体。加密之前的原始报文通常被称为明文(plaintext或cleartext)。使用了密码之后的编码报文通常被称作密文(ciphertext)。 使用密钥的密码编码算法和编码机器都可能落入敌人手中，所以大部分机器上都有一些盘号，可以将其设置为大量不同的值以改变密码的工作方式。这些密码参数被称为密钥(key)，要在密码机中输入正确的密钥，解密过程才能正确进行。 对称密钥加密技术编码时使用的密钥值和解码时一样，这就是对称密钥(symmetric-key)。 保持密钥的机密状态是很重要的，在很多情况下，编/解码算法都是众所周知的，因此密钥就是唯一保密的东西了。好的加密算法会迫使攻击者试遍每一个可能的密钥，才能破解代码。用暴力去尝试所有的密钥值称为枚举攻击(enumeration attack)。可用密钥的数量取决于密钥中的位数，以及可能的密钥中有多少是有效的。 对称密钥加密技术的缺点之一就是发送者和接受者在互相对话之前，一定要有一个共享的保密密钥。每对通信实体都需要自己的私有密钥。如果有N个节点，每个节点都要和其他所有的N-1个节点进行安全对话，总共需要N的平方个保密密钥，这将是一个管理噩梦。 公开密钥加密技术公开密钥使用了2个非对称密钥:一个用来对主机报文编码，另外一个用来对主机报文解码。编码密钥是众所周知的，但只要主机才知道私有的解密密钥。所有的公开密钥非对称加密系统所面临的共同挑战是，要确保即便有人拥有了下面所有的线索，也无法计算出保密的私有密钥: 公开密钥 一小片拦截下来的密文(可通过对网络的嗅探获取) 一条报文及与之相关的密文(对任意一段文本运行加密器就可以得到) 混合加密系统和会话密钥 两节点间通过便捷的公开密钥加密技术建立起安全通信，然后再用那条安全的通道产生并发送临时的随即对称密钥，通过更快的对称加密技术对其余的数据进行加密。 数字签名除了加/解密报文之外，还可以用加密系统对报文进行签名(sign)，以说明是谁编写的报文，同时证明报文未被篡改过。这种技术被称为数字签名(digital signing)。 客户端将变长报文提取为定长的摘要 客户端对摘要应用了一个”签名”函数，这个函数会将用户的私有密钥作为参数。因为只有用户才知道私有密钥，所以正确的签名函数会说明签名者就是其所有者。 一旦计算出签名，客户端就将其附加在报文的末尾，并将报文和签名都发送给对方。 在接收端，会用公开密钥对签名进行检查，如果不匹配则表示已被篡改。 使用数字签名的好处 签名可以验证是作者编写了这条报文，只有作者才会有最机密的私有密钥，因此，只有作者才能计算出这些校验和。校验和就像来自作者的个人“签名”一样。 签名可以防止报文被篡改，如果有恶意攻击者在报文传输过程中对其进行了修改，校验和就不再匹配了。由于校验和只有作者保密的私有密钥才能产生，所以攻击者无法为篡改了的报文伪造出正确的校验码。 数字证书数字证书中包含了由某个受信任组织担保的用户或公司的相关信息。数字证书都是由官方的”证书颁发机构”以数字方式签发的。通过HTTPS建立了一个安全web事务之后，现代浏览器都会自动获取所连接服务器的数字证书。如果服务器没有证书，安全连接就会失败。浏览器收到证书的时候会对签名颁发机构进行检查。 HTTPS——细节介绍HTTPS将HTTP协议与一组强大的对称，非对称和基于证书的加密技术结合在一起，使得HTTPS不仅很安全，而且很灵活，很容易在处于无序状态的，分散的全球互联网上进行管理。 客户端会对web资源执行某事务时，他会去检查URL的方案，如果URL的方案是https，客户端就会打开一条到服务器端口443(而不是传统的http默认的80端口)的连接，然后与服务器进行SSL”握手”，以二进制格式与服务器交换一些SSL安全参数，附加上加密的HTTP命令。 站点证书的有效性 日期检测 签名颁发者可信度检测 签名检测 站点身份检测 通过代理以隧道形式传输安全流量客户端通常会用web代理服务器代表它们来访问web服务器。但只要客户端开始用服务器的公开密钥对发往服务器的数据进行加密，代理就再也不能读取HTTP首部了！就无法知道应该将请求转向何处了。为了使HTTPS与代理配合工作，可以用HTTPS SSL隧道协议。使用HTTPS隧道协议，客户端首先告诉代理，它想要连接的安全主机和端口。这是在开始加密之前，以明文形式告知的。","categories":[{"name":"网络","slug":"网络","permalink":"https://sfegsq.github.io/categories/网络/"}],"tags":[{"name":"HTTP权威指南","slug":"HTTP权威指南","permalink":"https://sfegsq.github.io/tags/HTTP权威指南/"}]},{"title":"HTTP结构","slug":"HTTP结构","date":"2016-04-27T05:16:48.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/27/HTTP结构/","link":"","permalink":"https://sfegsq.github.io/2016/04/27/HTTP结构/","excerpt":"第二部分的5章主要介绍了HTTP服务器，代理，缓存，网关和机器人应用程序，这些都是Web系统架构的构造模块。","text":"第二部分的5章主要介绍了HTTP服务器，代理，缓存，网关和机器人应用程序，这些都是Web系统架构的构造模块。 Web服务器 第五章Web服务器会对HTTP请求进行处理并提供响应。术语”web服务器”可以用来表示Web服务器的软件，也可以用来表示提供Web页面的特定设备或计算机。 实际的Web服务器会做些什么 建立连接—-接受一个客户端连接，或者如果不希望与这个客户端建立连接，就将其关闭 接收请求—-从网络中读取一条HTTP请求报文 处理请求—-对请求报文进行解释，并采取行动 访问资源—-访问报文中指定的资源 构建响应—-创建带有正确首部的HTTP响应报文 发送响应—-将响应回送给客户端 记录事务处理过程—-将与已完成事务有关的内容记录在一个日志文件中 第一步——接受客户端连接如果客户端已经打开了一条到服务器的持久连接，可以使用那条连接来发送它的请求。否则，客户端需要打开一条新的到服务器的连接。处理新连接客户端请求一条道web服务器的TCP连接时，Web服务器会建立连接，判断连接的另一端是哪个客户端，从TCP连接中将IP地址解析出来。一旦新连接建立起来并被接受，服务器就会将新连接添加到其现存Web服务器连接列表中，并做好监视连接上数据传输的准备。 客户端主机名识别可以用”反向DNS”对大部分Web服务器进行配置，以便将客户端IP地址转换成客户端主机名。但需要注意的是，主机名的查找可能会花费很长时间，这样会降低Web事务处理的速度。因此，很多大容量Web服务器要么会禁止主机名解析，要么只允许对特定内容进行解析。 第二步——接收请求报文连接上有数据到达时，web服务器会从网络连接中读取数据，并将请求报文中的内容解析出来。解析请求报文时，web服务器会不定期地从网络上接收输入数据。网络连接可能随时都会出现延迟。web服务器需要从网络中读取数据，将部分报文数据临时存储在内存中，直到收到足以进行解析的数据并理解其意义为止。报文的内部表示法有些Web服务器还会用便于进行报文操作的内部数据结构来存储请求报文，这样就可以将这些报文的数据存放在一个快速查询表中，以便快速访问特定首部的具体值了。 连接的输入/输出处理结构不同的Web服务器结构以不同的方式为请求服务，如下。 单线程Web服务器 多进程及多线程Web服务器 复用I/O的服务器 复用的多线程Web服务器 第三步——处理请求一旦web服务器收到了请求，就可以根据方法，资源，首部和可选的主体部分对请求进行处理了。 第四步——对资源的映射以及访问Web服务器是资源服务器。他们负责发送预先创建好的内容，比如HTML页面或者JPEG图片，以及运行在服务器上的资源生成程序所产生的动态内容。在web服务器将内容传送给客户端之前，要将请求报文中的URI映射为Web服务器上适当的内容或内容生成器，以识别出内容的源头。 docroot通常，web服务器的文件系统会有一个特殊的文件夹专门用于存放web内容。这个文件夹被称为文档的根目录(document root)。web服务器从请求报文中获取URI，并将其附加在文档根目录的后面。 目录列表Web服务器可以接收对目录URL的请求，其路径可以解析为一个目录，而不是文件。我们可以对大多数Web服务器进行配置，使其在客户端请求目录URL时采取不同的动作。 返回一个错误 不返回目录，返回一个特殊的默认”索引文件” (DirectoryIndex index.html home.html) 扫描目录，返回一个包含目录内容的HTML界面 (在Aapche中可以通过指令Options -Indexes禁止) 第五步——构建响应一旦web服务器识别出了资源，就执行请求方法中描述的动作，并返回响应报文。响应报文中包含了响应状态码，响应首部，如果生成了响应主体的话，还包括响应主体。 第六步——发送响应Web服务器通过连接发送数据时也会面临与接收数据一样的问题。服务器要记录连接的状态，还要特别注意对持久连接的处理。对非持久连接而言，服务器应该在发送了整条报文之后，关闭自己这一端的连接。对持久连接来说，连接可能仍保持打开状态，在这种情况下，服务器要特别小心，要正确的计算Content-Length首部，不然客户端就无法知道响应什么时候结束了。 第七步——记录日志当事务结束之后，web服务器会在日志文件中添加一个条目，来描述已执行的事务。 代理 第六章web上的代理服务器是代表客户端完成事务处理的中间人。如果没有Web代理，HTTP客户端就要直接与HTTP服务器进行对话，有了Web代理，客户端就可以与代理进行对话，然后由代理代表客户端与服务器进行交流，客户端仍然会完成事务的处理，但它是通过代理服务器提供的优质服务来实现的。 代理与网关的区别严格的来说，代理连接的是两个或多个使用相同协议的应用程序，而网关连接的则是两个或多个使用不同协议的端点。 代理的应用代理服务器可以实现各种有用的功能，他们可以改善安全性，提高性能，节省费用。代理服务器可以看到并接触所有流过的HTTP流量，所有代理可以监视流量并对其进行修改，以实现很多有用的增值Web服务。 儿童过滤器 文档访问控制 安全防火墙 web缓存 反向代理 内容路由器 转码器 匿名者 代理服务器的部署可以根据其目标用途，将代理放在任意位置。 出口代理 访问(入口)代理 反向代理 网络交换代理 层次化的代理可以通过代理层次结构将代理级联起来。在代理的层次结构中，会将报文从一个代理传给另外一个代理，直到最终抵达原始服务器为止(然后通过代理传回客户端)。 如何使用代理 修改客户端的代理配置 修改网络，对流量进行拦截并导入一个代理 修改DNS的命名空间，假扮web服务器的名字和IP地址。 修改Web服务器，服务器发送重定向命令 客户端的代理设置 手工配置 预先配置浏览器 代理的自动配置 PAC WPAD的代理发行 缓存 第七章web缓存是可以自动保存常见文档副本的HTTP设备。当Web请求抵达缓存时，如果本地有”已缓存的”副本，就可以从本地存储设备而不是原始服务器中提取这个文档。 缓存可以优化一下问题 冗余的数据传输 带宽瓶颈 瞬间拥塞 距离时延 命中和未命中的缓存无法保存世界上的每一份文档。可以用已有的副本为某些到达缓存的请求提供服务，这被称为缓存命中 (cache hit)，其他一些请求可能因为没有副本可用，而被转发给原始服务器，这被称为缓存未命中(cache miss)。 文档命中率 (说明了阻止了多个通往外部网络的Web事务，有效降低整体时延) 字节命中率 (说明了阻止了多少字节传向因特网，有利于节省带宽)再验证缓存可以在任意时刻，以任意频率对副本进行再验证。如果验证过没有更新则将副本提供给客户端，这被称为再验证命中或缓慢命中，这种方式确实要与原始服务器进行核对，所以会比单纯的缓存命中要慢，但它没有从服务器中获取对象数据，所以要比缓存未命中快一些。 缓存的处理步骤 接收——缓存从网络中读取抵达的请求报文 解析——缓存对报文进行解析，提取出URL和各种首部 查询——缓存查看是否有本地副本可用，如果没有，就获取一份副本(并将其保存在本地) 新鲜度检测——缓存查看已缓存副本是否足够新鲜，如果不是，就询问服务器是否有任何更新 创建响应——缓存会用新的首部和已缓存的主体来构建一条响应报文 发送——缓存通过网络将响应发回给客户端 日志——缓存可选地创建一个日志文件条目来描述这个事务 保持副本的新鲜文档过期 (document expiration)通过特殊的HTTP Cache-Control: max-age = 484200首部和Expires: Fri, 05,2016, 17:20:30 GMT首部,HTTP让原始服务器向每个文档附加了一个过期日期。在缓存文档过期之前，可以以任意频率使用这些副本，而无需与服务器联系。HTTP/1.0+的Expires首部使用的是绝对日期而不是相对时间，所以我们更倾向于使用比较新的HTTP/1.1的Cache-Control，绝对日期依赖于计算机时钟的正确设置。 服务器再验证 (server revalidation)文档过期并不意味着它和服务器上目前活跃的文档有实际的区别，这只是意味着到了要进行核对的时间了。 如果再验证显示内容发生了变化，缓存会获取一份新的文档副本，并将其缓存在旧文档的位置上，然后将文档发送给客户端。 如果再验证显示内容没有发送变化，缓存只需要获取新的首部，包括一个新的过期时间，并对缓存中的首部进行更新就行了。 用条件方法进行再验证HTTP定义了5个条件请求首部，对缓存再验证来说最有用的2个首部是If-Modified-Since:date和If-None-Match:tag(只有两个条件都满足时，才能返回304响应)。 另外3个条件首部包括If-Unmodified-Since(在进行部分文件的传输时，获取文件的其余部分之前要确保文件未发生变化，此时这个首部是非常有用的)，If-Range(支持对不完整文档的缓存)和If-Match(用于与web服务器打交道时的并发控制) If-Modified-Since:Date 再验证 如果从指定日期之后文档被修改过了，就执行请求的方法。可以与Last-Modified服务器响应首部配合使用，只有在内容被修改后与已缓存版本有所不同时才去获取内容。 If-None-Match:实体标签再验证有些情况下仅使用最后修改日期进行再严重是不够的 有些文档可能会被周期性地重写(比如，从一个后台进程中写入)，但实际包含的数据常常是一样的。经内容没有变化，但修改日期会发生变化。 有些文档可能被修改了，但所做修改并不重要，不需要让世界范围内的缓存都重装数据(比如对拼写或注释的修改) 有些服务器无法准确地判定其页面的最后修改日期 有些服务器提供的文档会在亚秒间隙发生变化(比如，实时监视器)，对这些服务器来说，以一秒为粒度的修改日期可能就不够用了 为了解决这些问题，HTTP允许用户对被称为实体标签(ETag)的“版本标识符”进行比较。实体标签是附加到文档上的任意标签(引用字符串)。当发布者对文档进行修改时，可以修改文档的实体标签来说明这个新的版本，这样，如果实体标签被修改了，缓存就可以用If-None-Match条件首部来GET文档的新副本了。 控制缓存的能力服务器可以通过HTTP定义的几种方式来指定在文档过期前可以将其缓存多长时间。按照优先级递减的顺序，服务器可以： Cache-Control: no-store Cache-Control: no-cache Cache-Control: must-revalidate Cache-Control: max-age 附加一个Expires日期首部到响应中去 不附加过期信息，让缓存确定自己的过期日期 集成点：网关，隧道及中继 第八章网关 gatewayHTTP扩展和接口的发展是由用户需求驱动的。要在web上发布更复杂的资源的需求出现时，单个应用程序无法处理所有这些能想到的资源。 为了解决这个问题，开发者提出了网关的概念，网关可以作为某种翻译器使用，他可以自动将HTTP流量转换为其他协议，这样HTTP客户端无需了解其他协议，就可以与其他应用层序进行交互了。 可以用一个斜杠来分割客户端和服务器端协议，并以此对网关进行描述&lt;客户端协议&gt;/&lt;服务器端协议&gt; CGI Common Gateway InterfaceCGI是一个标准接口集，web服务器可以用它来装载程序以响应对特定URL的HTTP请求，并收集程序的输出数据，将其放在HTTP响应中回送。 隧道web隧道允许用户通过http连接发送非http流量，这样就可以在http上捎带其他协议数据了。使用web隧道最常见的原因就是要在http连接中嵌入非http流量，这样，这类流量就可以穿过只允许web流量通过的防火墙了。 中继 relay中继是没有完全遵循http规范的简单http代理。中继负责处理http中建立连接的部分，然后对字节进行盲转发。 Web机器人 第九章Web爬虫是一种机器人，它们会递归地对各种信息性Web站点进行遍历，获取第一个Web页面，然后获取那个页面指向的所有web页面，然后是那些页面指向的所有页面，以此类推。递归地跟踪这些web链接的机器人会沿着HTML超链接创建的网络”爬行”，所有称其为爬虫(crawler)或蜘蛛(spider)。 爬虫根集在把爬虫放出去之前，需要给他一个起始点。爬虫开始访问的URL初始集合被称作根集(root set)。 避免环路机器人必须知道他们到过何处，以避免环路(cycle)的出现。 面包屑留下的痕迹管理大规模web爬虫对其访问过的地址进行管理时使用的一些有用的技术 树和散列表 有损的存在位图 检查点 分类 别名由于URL“别名”的存在，即使使用了正确的数据结构，有时也很难分辨出以前是否访问过某个页面，如果两个URL看起来不一样，但实际指向的是同一资源，就称这两个URL互为”别名”。 避免循环和重复的一些方法 规范化URL 广度优先的爬行 节流 限制URL大小 URL/站点黑名单 模式检测 内容指纹 人工监视 机器人的HTTP虚拟主机机器人实现者要支持Host首部，随着虚拟主机的流行，请求中不包含Host首部的话，可能会使机器人将错误的内容与一个特定的URL关联起来。 条件请求对时间戳或实体标签进行比较，看看它们最近获取的版本是否已经升级以减少获取未更新的内容。","categories":[{"name":"网络","slug":"网络","permalink":"https://sfegsq.github.io/categories/网络/"}],"tags":[{"name":"HTTP权威指南","slug":"HTTP权威指南","permalink":"https://sfegsq.github.io/tags/HTTP权威指南/"}]},{"title":"HTTP:Web基础","slug":"HTTP-Web基础","date":"2016-04-26T05:16:12.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/26/HTTP-Web基础/","link":"","permalink":"https://sfegsq.github.io/2016/04/26/HTTP-Web基础/","excerpt":"概述HTTPHTTP协议是因特网的多媒体信使。HTTP可以从遍布世界的Web服务器上将这些信息快迅速，便捷，可靠地搬移到人们桌面上的Web浏览器上去。 HTTP协议主要分Web客户端和服务器。其中Web服务器是Web资源的宿主。Web资源可以包含任意媒体类型内容，HTTP协议为了标识各种媒体类型，会给通过Web传输的对象都打上MIME类型的数据标签格式。(MIME科普:最初设计MIME(Multipurpose Internet Mail Extension，多用途因特网邮件扩展)是为了解决在不同的电子邮件系统之间搬移报文时存在的问题。HTTP随后也采用了它，用他来描述并标记多媒体内容。)","text":"概述HTTPHTTP协议是因特网的多媒体信使。HTTP可以从遍布世界的Web服务器上将这些信息快迅速，便捷，可靠地搬移到人们桌面上的Web浏览器上去。 HTTP协议主要分Web客户端和服务器。其中Web服务器是Web资源的宿主。Web资源可以包含任意媒体类型内容，HTTP协议为了标识各种媒体类型，会给通过Web传输的对象都打上MIME类型的数据标签格式。(MIME科普:最初设计MIME(Multipurpose Internet Mail Extension，多用途因特网邮件扩展)是为了解决在不同的电子邮件系统之间搬移报文时存在的问题。HTTP随后也采用了它，用他来描述并标记多媒体内容。) 同时，每个web服务器资源都有一个名字去标识，这被称为统一资源标识符(Uniform Resource Identifier)。URI有两种类型，一种是我们常见的统一资源定位符URL，另外一种被称为统一资源名URN。后者仍处于试验阶段，未大范围使用。 web页面可以包含多个对象，如一个页面会包括许多图片，视频，音频等内容。客户端通过向Web服务器发送请求命令来进行事务处理。服务器响应客户端请求，并传送相应数据。 请求和响应报文都有固定的规范。报文由一行一行简单字符串组成的。HTTP报文都是纯文本，而不是二进制代码，所以人们可以很方便的进行读写(但难以解析)。报文分为三部分 起始行 GET /index.html HTTP/1.0 首部字段 每个首部字段包含一个名字和一个值，为了便于解析，两者之间用冒号来分割。首部以一个空行结束。 主体 起始行和首部都是文本形式且都是结构化的，主体则可以包含任意的二进制数据，当然也可以包含文本。 HTTP协议的报文是通过传输控制协议(Transmission Control Protocol,TCP)连接从一个地方搬移到另外一个地方去的。TCP提供了 无差错的数据传输 按序传输 (数据总是会按照发送的顺序到达) 未分段的数据流 (可以在任意时刻以任意尺寸将数据发送出去) 在HTTP客户端向服务器发送报文之前，需要用网际协议(Internet Protocol,IP)地址和端口号在客户端和服务器之间建立一条TCP/IP连接。首先需要将URL进行DNS解析成IP地址，再用IP地址连接Web服务器，默认端口是80。 除了客户端与服务器之外，还有许多比较重要的Web结构组件 代理 位于客户端和服务器之间的HTTP中间实体 缓存 HTTP的仓库，使常用页面的副本可以保存在离客户端更近的地方 网关 连接其他应用程序的特殊Web服务器 隧道 对HTTP通信报文进行盲转发的特殊代理 Agent代理 发起自动HTTP请求的半智能Web客户端 URL与资源URL提供了一种统一的资源命名方式，大多数URL都有同样的:”方案://服务器位置/路径”结构。 URL的语法&lt;scheme&gt;://&lt;user&gt;:&lt;password&gt;@&lt;host&gt;:&lt;port&gt;/&lt;path&gt;;&lt;params&gt;?&lt;query&gt;#&lt;frag&gt;几乎没有哪个URL包含了所有这些组件。URL最重要的3个部分是方案(scheme)，主机(host)和路径(path)。 URL编码转义表示法包含一个百分号%，后面跟着两个表示字符ASCII码的十六进制数。例子http://www.baidu.com/%7Ejoe ~ 126(0x7E) HTTP报文HTTP报文是在HTTP应用程序之间发生的数据块。这些数据块以一些文本形式的元信息(meta-information)开头，这些信息描述了报文的内容及含义，后面跟着可选的数据部分。这些报文在客户端，服务器和代理之间流动。 报文的语法所有的报文都可以分为两类:请求报文(request message)和响应报文(response message)。 请求报文 1234&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; 响应报文 1234&lt;version&gt; &lt;status&gt; &lt;reason-phrase&gt;&lt;headers&gt;&lt;entity-body&gt; 起始行方法 方法 描述 GET 从服务器获取一份文档 HEAD 只从服务器获取文档的首部 POST 向服务器发送需要处理的数据 PUT 将请求的主体部分存储在服务器上 PUT 对可能经过代理服务器传送到服务器上去的报文进行追踪 OPTIONS 决定可以在服务器上执行哪些方法 DELETE 从服务器上删除一份文档 并不是所有服务器都实现了上述7种方法，而且，由于HTTP设计的易于扩展，所以其他服务器可能还会实现一些自己的请求方法。 状态码 整体范围 已定义范围 分类 100 ~ 199 100~101 信息提示 200~299 200~206 成功 300~399 300~305 重定向 400~499 400~415 客户端错误 500~599 500~505 服务器错误 当前的HTTP版本只为每类状态定义了几个代码，随着协议的发展，HTTP规范中会正式的定义更多的状态码，如果收到了不认识的状态码，可能是有人将其作为当前协议的扩展定义的。可以根据其所处范围，将它作为那个类别中一个普通的成员来处理。 首部首部分类： 通用首部 既可以出现在请求报文中又可以出现在响应报文中 请求首部 提供更多有关请求的信息 响应首部 提供更多有关响应的信息 实体首部 描述主体的长度和内容，或者资源自身 扩展首部 规范中没有定义的新首部 实体的主体部分HTTP报文的第三部分是可选的实体主体部分。实体的主体是HTTP报文的负荷，就是HTTP要传输的内容。 连接管理世界上几乎所有的HTTP通信都是由TCP/IP承载的，TCP/IP是全球计算机及网络设备都在使用的一种常用的分组交换网络分层协议集。客户端应用程序可以打开一条TCP/IP连接，连接到可能运行在世界任何地方的服务器应用程序。 web浏览器通过TCP连接与web服务器进行交互的流程https://github.com:80/WilsonLiu95 浏览器利用解析出主机名 github.com 浏览器查询这个主机名的IP地址 192.30.252.122 浏览器获得端口号 80 浏览器发起到192.30.252.122端口80的连接 浏览器向服务器发送一条HTTP GET报文 浏览器从服务器读取HTTP响应报文 浏览器关闭TCP连接 HTTP事务的时延与建立TCP连接，以及传输请求和响应报文的时间相比，事务处理时间可能是很短的。除非客户端或服务器超载，或正在处理复杂的动态资源，否则HTTP时延就是由TCP网络时延构成的。 HTTP事务时延的有以下几种主要原因 客户端首先需要根据URI确定Web服务器的IP地址和端口号。其中IP地址需要通过DNS解析URL中的主机名获得，这可能花费数十秒的时间。 客户端向服务器发送TCP连接请求，即著名的”三次握手”。这个值通常最多只有一两秒钟，但如果有数百个HTTP事务的话，这个值就会快速叠加上去。 因特网传输报文，以及服务器处理请求报文都需要花费时间。 web服务器回送HTTP响应也需要时间。这些TCP网络时延取决于硬件速度，网络和服务器的负载，请求和响应报文的尺寸，以及客户端和服务器之间的距离。TCP协议的技术复杂性也会对时延产生巨大的影响。 性能聚焦区域一下是其余一些会对HTTP产生影响，最常见的相关时延 TCP连接建立握手 TCP慢启动拥塞控制 数据聚焦的Nagle算法 用于捎带确认的TCP延迟确认算法 TIME_WAIT时延和端口耗尽 TCP连接建立握手TCP连接握手需要经过一下几个步骤 酷虎的向服务器发送一个小的TCP分组(通常是40-60字节)。这个分组中设置了一个特殊的SYN标记，说明这是一个连接请求。 如果服务器接收了连接，就会对一些连接参数进行计算，并向客户端回送一个TCP分组，这个分组中的SYN和ACK标记都被置位了，说明连接请求已经被接收了。 最后，客户端向服务器回送一条确认信息，通知它连接已成功建立。现代的TCP栈都允许客户端在这个确认分组中发送数据。 如果连接只用来传送少量的数据，这些交换过程就会严重降低HTTP的性能。小的HTTP事务可能会在TCP建立上花费50%或者更多的时间。 延迟确认每个TCP段都有一个序列号和数据完整性校验和。每个段的接收者收到完好的段时，都会向发送者回送小的确认分组。如果发送者没有在指定的窗口时间内收到确认信息，发送者就认为分为已被破坏或损毁，并重发数据。为了增加确认报文找到同向传输数据分组的可能性，很多TCP栈都实现了一种”延迟确认”算法。延迟确认算法会在一个特定的窗口时间(通常是100~200毫秒)内将输出确认存放在缓冲区中，以寻找能够捎带它的输出数据分组。如果在那个时间段内没有输出数据分组，就讲确认信息放在单独的分组中传送。通常，延迟确认算法会引入相当大的时延，所以可以调整或者禁止延迟确认算法。 TCP慢启动TCP数据传输的性能还取决于TCP连接的使用期(age)。TCP连接会随着时间进行自我“调谐”，起初会限制连接的最大速度，如果数据成功传输，会随着时间的推移提高传输的速度。这种调谐被称为TCP慢启动(slow start)，用于防止因特网的突然过载和拥塞。 Nagle算法与TCP_NODELAYNagle算法鼓励发送全尺寸(LAN上最大尺寸的分组大约是1500字节，在因特网上是几百字节)的段。只有当所有其他的分组都被确认之后，Nagle才允许发送非全尺寸的分组，如果其他分仍然在传输过程中，就将那部分数据缓存起来。只有当挂起分组被确认，或者缓存中积累了足够发送一个全尺寸分组的数据时，才会将缓存的数据发送出去。Nagle算法会引发几种HTTP性能问题。首先小的HTTP报文无法填满一个分组，可能会因为等待那些永远不会到来的额外数据而产生时延。其次，Nagle算法与延时确认之间的交互存在问题——Nagle会阻止数据的发送，直到有确认分组抵达为止，但确认分组自身会被延迟确认算法延迟100-200毫秒。因此，HTTP应用程序常常会在自己的栈中设置参数TCP_NODELAY,禁用Nagle算法，提高性能。 TIME_WAIT累计和端口耗尽当某个TCP端点关闭TCP连接时，会在内存中维护一个小的控制块，用来记录最近所关闭连接的IP地址和端口号。这类信息会维持一小段时间，以确保在这段时间内不会创建于相同地址和端口号的新连接。客户端每次连接到服务器上去时，都会获得一个新的端口号，以实现连接的唯一性。但由于可用的源端口数量有限，因此会出现端口耗尽的情况。就会无法建立新的连接。解决办法：增加客户端负载生成机器的数量，或者确保客户端和服务器在循环使用几个虚拟的IP地址以增加更多的连接组合。 HTTP连接的处理HTTP允许在客户端和最终的源端服务器之间存在一串HTTP中间实体(代理，高速缓存等)。可以从客户端开始，逐跳地将HTTP报文经过这些中间设备，转发到源端服务器上去(或者进行反向传输)。 Connection首部在某些情况下，两个相邻的HTTP应用程序会为它们共享的连接应用一组选项。HTTP的Connection首部字段中有一个由逗号分隔的连接标签列表，这些标签为此连接指定了一些不会传播到其他连接中去的选项。Connection首部可以承载3种不同类型的标签 HTTP首部字段名，列出了只与此连接有关的首部 任意标签值，用于描述此连接的非标准选项 值close，说明操作完成之后需关闭这条持久连接 串行事务处理时延如果支队连接进行简单的管理，TCP的性能时延可能会叠加起来。串行加载的另外一个缺点是，有些浏览器在对象加载完毕之前无法获知对象的尺寸，而且它们可能需要尺寸信息来决定将对象放在屏幕的什么位置上，所以在加载了足够多的对象之前，无法在屏幕上显示任何内容。 以下为4种提高HTTP连接性能的技术。 并行连接 通过多条TCP连接发起并发的HTTP请求 持久连接 重用TCP连接，以消除连接及关闭时延 管道化连接 通过共享的TCP连接发起并发的HTTP请求 复用的连接 交替传送请求和响应报文 (实验阶段) 并行连接HTTP允许客户端打开多条连接，并行地执行多个HTTP事务。 并行连接可以提高符合页面的传输速度，但并行连接也有一些缺点: 每个事务都会打开/关闭一条新的连接，好耗费时间和带宽 由于TCP慢启动特性的存在，每条新连接的性能会有所降低 可打开的并行连接数量实际上是有限的 持久连接Web客户端经常会打开到同一个站点的连接。因此，初始化了对某服务器的HTTP请求的应用程序很可能会在不久的将来对那台服务器发起更多的请求。这种性质被称为站点局部性。因此，HTTP/1.1允许HTTP设备在事务处理结束之后将TCP连接保持在打开状态，以便为将来的HTTP请求重用现存的连接。 在事务处理结束之后仍然保持在打开状态的TCP连接被称为持久连接。非持久连接会在每个事务结束之后关闭。持久连接会在不同事务之间保持打开状态，直到客户端或服务器决定将其关闭为止。重用已对目标服务器打开的空闲持久连接，就可以避开缓慢的连接建立阶段。而且，已经打开的连接还可以避免慢启动的拥塞适应阶段，以便更快速地进行数据的传输。 持久连接有一些比并行连接更好的地方。持久连接降低了时延和连接建立的开销，将连接保持在已调谐状态，而且减少了打开连接的潜在数量。(持久连接有两种类型:比较老的HTTP/1.0+ “keep-alive”连接，以及现代的HTTP/1.1 “persistent”连接) 并行连接与持久连接配合使用可能是最高效的方式。 管道化连接允许在持久连接上可选的使用请求管道，这是相对于keep-alive连接的又一性能优化。在响应到达之前，可以将多条请求放入队列。当第一条请求通过网络流向地球另一端的服务器时，第二条和第三条请求也可以开始发送了。在高时延网络条件下，这样做可以降低网络的环回时间。 总结本文为《http权威指南》的第一部分，由第一到四章组成，介绍了HTTP的基础构件和HTTP的核心技术。希望大家能够喜欢。","categories":[{"name":"网络","slug":"网络","permalink":"https://sfegsq.github.io/categories/网络/"}],"tags":[{"name":"HTTP权威指南","slug":"HTTP权威指南","permalink":"https://sfegsq.github.io/tags/HTTP权威指南/"}]},{"title":"端到端协议","slug":"端到端协议","date":"2016-04-24T05:30:51.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/24/端到端协议/","link":"","permalink":"https://sfegsq.github.io/2016/04/24/端到端协议/","excerpt":"从前几章研究的主机到主机的分组传递服务到转向进程到进程之间的通信信道，这正是网络体系结构中传输层(transport)的任务，由于它支持端点应用程序之间的通信，因此传输层协议有时也被称为端到端(end to end)协议。 因特网提供尽力而为(best-effort)的服务，为满足应用程序所需的高级服务，不同传输层协议用于不同的算法组合。代表性的4种有：一个简单的异步多路分解服务，一个可靠的字节流服务，一个请求/应答服务和一个用于实时应用的服务。","text":"从前几章研究的主机到主机的分组传递服务到转向进程到进程之间的通信信道，这正是网络体系结构中传输层(transport)的任务，由于它支持端点应用程序之间的通信，因此传输层协议有时也被称为端到端(end to end)协议。 因特网提供尽力而为(best-effort)的服务，为满足应用程序所需的高级服务，不同传输层协议用于不同的算法组合。代表性的4种有：一个简单的异步多路分解服务，一个可靠的字节流服务，一个请求/应答服务和一个用于实时应用的服务。 5.1 简单的多路分解协议 (UDP)可能最简单的传输协议是把下层网络的主机到主机的传递服务扩展到进程到进程的通信服务。任何主机上都有可能运行多个进程，因此该洗衣至少需要增加一个多路分解功能，以便每台主机上的多个进程能够共享网络。除此之外，传输协议不再下层网络提供的服务增加任何其他功能。因特网提供的用户数据报协议(User Datagram Protocol),就是这样的传输协议。 值得注意的是标识目的进程的地址形式(可以用操作系统赋予的进程标识符pid使进程之间直接地相互识别，但无法扩展至多个不同的系统),UDP采用的方式是使用一个称谓端口port的抽象定位器，使进程之间能够间接的相互识别。基本思想是源进程向端口发送消息而目的进程从端口接收消息。 &lt;主机，端口&gt;构成了UDP协议的多路分解密钥。 如何相互知道进程端口号？ 策略是服务器进程在一个知名端口well-known port接收消息，即知名端口只有一个。有时候，知名端口仅仅是通信的开始点：客户机和服务器用这个端口达成一致，并在另外一个端口进行后续的通信，以便释放知名端口给其他客户进程使用。 一般来说一个端口是由一个消息队列实现的，当一个消息到达时，协议会把该消息加到队列的末尾，如果队列满了，消息会被丢弃。这里并没有让发送发减慢发送速度的流量控制机制。 虽然UDP没有实现流量控制或可靠的/有序的传输，但它不仅仅是简单地把消息多路分解给某个应用进程，而是多做了工作，通过在首部中的校验和部分进行校验确保消息的正确性。 5.2 可靠的字节流 Transmission Control ProtocolTCP能保证可靠的，有序的字节流传输，它是全双工协议，也就是说每个TCP连接直接一对字节流，每个方向上一个字节流，他还有流量控制机制，另外，像UDP一样，TCP支持多路分解机制。此外，TCP也实现了一个高度调整的拥塞控制机制，这种机制的思想是控制TCP发送方发送数据的速度，其目的不是为了防止发送方发出的数据超出方的接收能力，而是防止发出方发出的数据超出网络的容量。 流量控制与拥塞控制的区别 流量控制防止发送方发出的数据超出接收方的接收能力，拥塞控制防止过多的数据注入网络而造成交换机或链路超载。因此流量控制是一个端到端的问题，而拥塞控制则是主机如何同网络交互的问题。 5.2.1 端到端的问题TCP的核心是滑动窗口算法。因为TCP是在整个因特网上而不是在一个点到点链路上运行，所以它们存在着很多重要的差别。 在连接建立阶段发生的事件之一，是双方建立某种共享状态使滑动窗口算法开始运行。连接断开阶段是必要的，因为只有这样双方主机才知道是释放这种状态的时候。 TCP连接与点到点链路连接的区别 第二章描述的滑动窗口算法运行在总是连接两台计算机的一条物理链路上，但TCP仍然支持运行在因特网中任意两台计算机上的进程之间的逻辑连接。 尽管来连接两台相同的计算机的一条物理链路具有固定的RTT，但是TCP连接很可能具有差异很大的往返时延。 分组通过因特网时可能重排序，这在点到点链路上是不可能的，因为在链路一段先发送的分组一定先到达另一端。 连接点到点链路的计算机通常被设计成支持这种链路。流量控制问题 因为一个直连链路的发送方不能以超出链路带宽所允许的速率发送数据，而且只有一台主机向链路注入数据，所以它不可能不知道链路拥塞。但是TCP并不知道。 在TCP中，下层IP网络被认为是不可靠的，而且会使传递消息错序，TCP在端到端的基础上利用滑动窗口算法提供可靠/有序的传送。 5.2.2 报文段格式TCP是面向字节的协议，这就是说发送方向一个TCP连接写入字节，接收方从这个TCP连接读出字节。 实际上，源主机上的TCP收集发送进程交付的字节，存储到缓冲区中，积累到足够的数量，将其一起放入一个大小适宜的分组，再发送给目的主机上的对等实体。目的主机上的TCP把这个分组的内容存入一个接收缓冲区，接收进程在空闲时从这个缓冲区读出字节。 5.2.3 连接的建立和终止注意，尽管连接的建立是一个非对称的活动(一方执行被动打开而另一方执行主动打开)，但是连接的断开则是对称的活动(每一方必须独立的关闭连接)。因此有可能一方已经完成了关闭连接，意味着它不再发生数据，但是另一方却仍保持双向连接的另一半为打开状态并且继续发生数据。 三次握手TCP使用的建立和终止连接的算法称为”三次握手”(three-way handshake)，指客户机和服务器之间要交换三次消息。 算法的思想是双方需要商定一些参数，在打开一个TCP连接的时候，参数就是双方打算为各自的字节流使用的开始序号。首先，客户机(主动参与方)发送一个报文段给服务器(被动参与方)，声明它将使用的初始序号(Flags = SYN,SequenceNum=x),服务器用一个报文段响应确认客户端的序号(Flags = ACK,Ack= x+1)，同时声明自己的初始序号(Flags=SYN,SequenceNum=y),最后，客户机用第三个报文段响应，确认服务器的序号(Flags = ACK,Ack=y+1)。每一段的确认序号比发送来的序号大一的原因是Acknowledgment字段实际指出”希望接收的下一个序号”，从而隐含地确认前面所有的序号。前两个报文段都使用计时器，如果没有收到所希望的应答，就会重传报文段。 TCP规范要求连接的每一方随机地选择一个初始序号，是为了防止同一个连接的两个实例过快地重复使用同一个序号，也就是说，仍旧有可能出现以前的连接实例的一个数据段干扰后来的连接实例的情况。 状态转换初始都为closed，客户端主动打开并发送SYN信号，客户端进入SYN_SENT，服务器端被动打开进入LISTEN状态，之后当服务器端收到客户端发来的SYN，进入SYN_RCVD状态并发送SYN+ACK报文段响应，这个报文段到达客户端后，会使客户端进入ESTABLISHED状态并向服务器发送一个ACK报文段，当这个报文段到达后，服务器转移到ESTABLISHED。到此结束三次握手的状态转换。 5.2.4 滑动窗口再讨论TCP窗口算法服务于这样三个目的 保证数据的可靠传递 确保数据的有序传递 增强发送方和接收方之间的流量控制。 TCP与以前算法不同之处在于增加了流量控制功能，特别是TCP并不使用一个固定尺寸的滑动窗口，而是由接收方向发送方通知(advertise)它的窗口尺寸。这是通过TCP首部的AdvertisedWindow字段完成。接收方根据分配给连接用于缓存数据的内存数量，为AdvertisedWindow选择一个合适的值。 可靠和有序的传输发送方的TCP维护一个发送缓冲区，该缓冲区用来存储那些已被发出但未被确认的数据和已被发送应用程序写入但未发出的数据。在接收方，TCP维护一个接收缓冲区，存放那些到达的错序数据和那些按正确顺序到达但应用进程无暇读出的数据。 发送方缓冲区维护3个指针 LastByteAcked,LastByteWritten,LastByteSent 同样，接收方缓冲区也维护着3个指针 LastByteRead,NextByteExpected,LastByteRcvd 流量控制缓冲区具有有限的大小。接收方通过给发送方通知一个不大于他所能存储数据量的窗口，就能控制发送方的发送速率。 TCP只会当接收到报文段时发出一个报文段回应，这个响应包含Acknowledgment和AdvertisedWindow字段的最新值，即使这两个值自上次发送以来没有改变。问题就在于此，当窗口为0后，就不允许发送方发送任何数据，就意味着它没办法发现在将来的某个时刻通知窗口不再是0.接收方的TCP不会自发的发送不包含数据的报文段，他只在响应到达的报文段时发送他们。 TCP按如下方式处理这种情况，当窗口为0时，发送方仍然坚持不停的发送一个只有1字节的报文段。 发送方周期性的发送探测报文段的原因是:TCP被设计成使接收方尽可能的简单，即他只响应从发送方发来的报文段，而它字节从不发起任何活动。我们称其为聪明的发送方/笨拙的接收方(smart sender/dumb receiver)规则。 5.2.5 触发传输TCP有三种机制触发一个报文段的传输。 TCP维护着一个变量，称为最大报文段长度(MSS)，一旦TCP从发送进程收集到MSS个字节，它就发送一个报文段，通常把MSS设置为TCP能发送而且不造成本地IP分段的最大报文段长度，也就是说，MSS被设置成直接连接网络的MTU减去TCP和IP的首部的大小。 发送进程明确要求TCP发送一个报文段，特别是TCP支持push操作，发送进程调用这个操作能使TCP将缓冲区中所有未发送的字节发送出去， 定时器激活，结果报文段中包含当前缓冲区中所有需要被发送出去的字节， 傻瓜窗口症状一味地利用任何可用窗口的策略会导致现在称作傻瓜窗口症状的情形。 所有问题又回到了：发送方决定什么时候才传输一个报文段？ Nagle算法引入了一种完美的自计时(self-clocking)方案,其思想是只要TCP发出了数据，发送方终究会收到一个ACK，可以把这个ACK看成激活的定时器，触发传输更多的数据。 Nagle提供了一条决定何时传输数据的简单统一规则：如果窗口大小允许，就可以发出一个满载的报文段。如果当前没有处于传输中的报文段，也可以立即发出一个小报文段，但是如果有传输的报文段，发送方就必须等待有ACK到达才可传输下一个报文段。 5.2.6 自适应重传由于TCP保证可靠的数据传输，所有如果在一定的时限内没有收到ACK，那么它就会重传每个报文段。TCP把这个超时设置成它期望的连接两端的RTT函数。选择一个合适的超时值并不容易。为了处理这个问题，TCP使用了一种自适应重传机制。 原始算法维持一个RTT的平均运行值，并把超时值作为这个RTT的一个函数计算。 Karn/Partridge算法原始算法有个明显的缺陷，问题是ACK实际上并不确认一次传送，它实际上确认数据的接收，无法确定收到的ACK是针对第一个报文段还是第二个重发的报文段。 解决办法相当简单，当TCP重传一个报文段时，停止计算RTT的样本值，它只为仅发送一次的报文段测量。同时对TCP重传机制做了一个小修整。每次TCP重传，它设置下次的超时值为上次的两倍。","categories":[{"name":"网络","slug":"网络","permalink":"https://sfegsq.github.io/categories/网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://sfegsq.github.io/tags/计算机网络/"}]},{"title":"网络互联","slug":"网络互联","date":"2016-04-23T05:29:40.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/23/网络互联/","link":"","permalink":"https://sfegsq.github.io/2016/04/23/网络互联/","excerpt":"我们已经见到如何用点到点链路，共享介质 和 交换机 建立单一的网络。 网络互联需要强调两个重要的问题：异构性(heterogeneity)和可扩展性(scale)。 异构性问题指的是一种类型网络上的用户希望能够同其他类型网络上的用户通信。 可扩展性问题因特网规模快速扩张，使得面临许多挑战，其中之一是路由(routing):你如何在有几百万个到几十亿个节点的网络中去找到一条高效的路径。与此密切相关的是编址(addressing)，即给所有节点疼合适标识符的任务。","text":"我们已经见到如何用点到点链路，共享介质 和 交换机 建立单一的网络。 网络互联需要强调两个重要的问题：异构性(heterogeneity)和可扩展性(scale)。 异构性问题指的是一种类型网络上的用户希望能够同其他类型网络上的用户通信。 可扩展性问题因特网规模快速扩张，使得面临许多挑战，其中之一是路由(routing):你如何在有几百万个到几十亿个节点的网络中去找到一条高效的路径。与此密切相关的是编址(addressing)，即给所有节点疼合适标识符的任务。 4.1 简单的网络互联(IP)4.1.1 什么是互联网我们用小写i的internetwork(互联网)这个词或仅用internet指可提供某种主机到主机的分组传送服务的相互连接的网络的任意集合。 4.1.2 服务模型可以将IP服务模型看成两部分：一是编址方案，提供标识互联网中所有主机的方法；二是传送数据的数据报(无连接的)模型。这种服务模型有时也称为尽力服务(best-effort)模型,这是因为尽管IP尽力传送数据报，但并不提供保证。 数据报传送数据报传送是IP的基础。数据报详情请见3.1.1。 分组格式在没有其他选项的时候，首部通常是5个字长(20个字节)。首部信息中有一个16位的length指定数据报的字节数目，故而IP数据报最大尺寸为65535个字节。然而IP运行的物理网络可能不支持如此长的分组，因此IP支持分段和重组。 分段和重组每个网络类型都有一个最大传输单元(Maximum Transmission Unit,MTU),这是一帧能够携带的最大数据报。 通常，当路由器接到一个想要在一个网络上转发的数据报，而这个网络的MTU比所接受到的数据报小时，在路由器上将进行分段，为了在目的主机上可以重组，所以都标识符(Ident)字段上携带同样的标识符。这个标识符由发送主机选择，并且对于所有可能在某个合理时段内从这个源主机到达目的主机的数据报来说是唯一的。 4.1.3 全局地址以太网地址也是全局唯一的，但是以太网地址是扁平的flat，也就是说他们没有结构，且几乎不对路由协议提供线索。 相比之下IP地址是分层次的hierarchical，即他们由对应于互联网某种层次结构的几个部分构成。IP地址分为两个部分：网络部分和主机部分。 更确切的说IP地址属于接口而不是属于主机。 A类 第一位为0 7位网络，24位主机 B类 第一位为0，第二位为1 14位网络，16位主机 C类 第一二位为0，第三位为1 21位网络 8位主机 4.1.4 IP中的数据报转发转发数据报按一下方法处理：一个数据报从源主机发往目的主机，沿途可能经过多个路由器。任何一个节点，无论是主机还是路由器，首先试图确定自己是否与目的主机连接在同一个物理网络上(通过比较目的地址的网络部分和它的每一个网络接口地址的网络部分)。 网桥，交换机和路由器的区别： 他们都是从一条链路把消息转发到另一条链路上。 人们根据分层对他们做出区分：网桥是链路层的节点(他们在链路间转发帧，实现可扩展的LAN)，交换机是网络层节点(他们在链路间转发分组实现分组交换网络)，路由器是互联网层节点(他们在网络之间转发数据报实现互联网)。 交换机和路由器有什么区别：关键区别是转发包的种类，路由器转发IP数据报，而以太网帧或者ATM信元是用交换机转发的。 交换机构造的ATM网络和路由器构造的因特网之间有一个很大的区别就是，因特网可以适应异构性，而ATM只能包含同构链路。 4.1.5 地址转换 ARP上一节，我们讨论了如何使IP数据报到达正确的物理网络，但是掩饰了一个数据报如何到达该网络上某一个特定主机或路由器的问题。主要问题是IP数据报包含IP地址，但是你想要传送到的主机或者路由器上的物理接口硬件只理解特定网络的编址方案。这样，我们就需要将IP地址转换为这个网络所能理解的链路层地址。(如一个48位的以太网地址) Address Resolution Protocol,ARPARP的目标是使网络上每个主机都简历一张IP地址到链路层地址间的映射表。 例：如果一个主机要发送一个数据报给已知为同一网络内的另一个主机(或路由器)(即发送和接收节点有同样的网络号)，那么它首先检查缓存中的映射，如果映射不存在，就调用ARP。即通过向网络广播一个ARP查询来实现，这个查询包括询问的IP地址，每个主机收到这个查询并检查是否与自己的IP地址匹配。如果匹配，该主机发送一个包含它的链路层地址的应答信息给发送出查询的源主机。源主机将次应答的包含的信息添加到自己的ARP表中。 同时查询信息中也包含源主机的IP地址和链路层地址，这样，每台主机都会知道源主机的链路层地址和IP地址，并更新自己的ARP表。 4.1.6 主机配置 Dynamic Host Configuration ProtocolDHCP依赖于DHCP服务器的存在，DHCP服务器负责向主机提供配置信息。一个管理域中至少有一个DHCP服务器。 为了与一个DHCP服务器相连，一台新自举或新连接的主机发送一条DHCPDISCOVER消息到一个特殊的IP地址(255.255.255.255)—-广播地址。DHCP服务器应答产生这条发现消息的主机(所有其他节点忽略这条消息)。然而，并不是每个网络都需要一个DHCP服务器，因此，DHCP使用一个中继代理(relayagen)的概念。每个网络中至少有一个中继代理，它只配置有一条消息：DHCP服务器的IP地址。 DHCP允许地址一段时间内被”租用”。一旦租用期满，服务器将地址回收。一个租用地址的主机，如果事实仍然连在网络上并功能正常，显然需要定期重新租用地址。 当然,DHCP也引入了更多的复杂性到了网络管理，因为它使物理主机与IP地址之间的绑定更为动态化。 4.1.7 差错报告 ICMPIP总是和网际控制报文协议(Internet Control Message Protocol)配置在一起的，这个协议定义了当一个路由器或主机不能成功处理一个IP数据报时，向源主机发回的错误消息的集合。(与http状态码类似) 4.2 路由转发(forwarding):转发过程包括接收一个分组，查看它的目的地址，查询转发表，按表中决定的路径把分组转发出去。转发是在一个节点本地执行的一个相对简单，定义良好的过程。 路由(routing):用于建立转发表的一个过程，依赖于在网络发展过程中不断演进的，复杂分布式算法。 构造转发表是为优化转发分组时查找网络号的过程，而优化路由表是为了计算拓扑结构的改变。 4.2.1 用图表示网络路由本质上是图论中的一个问题。 图中的边对应于网络中的链路，每条边都有一个相应的开销(cost),表示希望通过这段链路发送的通信量。 路由最基本的问题就是找出任意两个节点之间开销最小的路径，一条路径的开销等于组成这条路径的所有边上开销之和。 4.2.2 距离向量 RIP每个节点构造一个包含到所有其他节点”距离”(开销)的一维数组(一个向量)，并将这个向量分发给它的邻接点。对距离向量路由所作的最初假设是每个节点都知道到其直接邻接点的链路开销。到不相邻节点的链路开销被指定为无穷大。 网络中没有任何一个节点有网络路由表的所有信息，每个节点只知道它自己路由表的内容。像这种分布式算法的优点就是它能够使所有节点在没有任何集中授权的情况下取得对网络的一致视图。 路由表更新:第一种为定期更新(periodic),第二种为触发(triggered)更新。 两种改进稳定路由时间的技术；第一种是使用一个相对较小的数作为无穷大的近似值，第二种被称为水平分割(splithorizon),其思想是当一个节点把路由的更新消息发送给相邻节点时，它并不把从各个相邻节点处学到的路由再回送给该节点。 4.2.3 链路状态 OSPF假设每个节点都能找出到它的相邻节点的链路状态以及每条链路的开销，我们还希望提供给每个节点足够的信息，使他能找出到达任一目标的最小开销路径。 基本思想：每个节点都知道怎样到达它的邻接点，如果我们确保这种信息被完整地传播到每个节点，那么每个节点都有足够的网络信息来简历一个完整的网络映像。 链路状态路由协议依靠两种机制：链路状态信息的可靠传播和根据所有积累的链路状态指示的总和进行的路由计算。 4.2.4 度量标准 第一版本的度量标准是在每条链路上排队等待发送的分组的数量。 第二版本的度量，即考虑了链路带宽，又考虑了链路时延，并使用延迟而不是队列长度作为负载的衡量标准。 第三版本的度量，主要的改进是大量缩减度量值的动态范围。 4.3 全球因特网4.3.1 划分子网划分子网是减少分配网络号总数的一个很好的简单方法。 基本思想是只用一个网络号，把具有这个网络号的IP地址分配给多个物理网络，每个物理网络叫做一个子网(subnet)。在很多个网络当中共享一个网络号的机制涉及到使用子网掩码(subnetmask)配置每个子网中的所有节点。 因此现在我们可以认为IP地址分为3部分：网络部分，子网部分和主机部分。即我们将原来用于表示主机的部分划分为子网部分和主机部分。 当主机要发送一个分组到一个特定的IP地址时，它所做的第一件事就是用它的子网掩码与目标IP地址做按位与运算。如果结果等于发送主机的子网号，那么它就得知目的主机在同一子网内，分组可以在子网中直接传送，如果不等于，就需要把分组发送给一个路由器以便转发到另一个子网。 引入子网后，路由器的工作也跟着发生变化，原先的转发表是由成对形式的(网络号，下一跳)的记录组成，现在变为(子网号，子网掩码，下一跳)的形式。 路由器将分组的目的地址与每个记录的子网掩码依次进行按位与运算，如果结果与某一记录的子网号相匹配，那么这就是要使用的记录，然后将分组转发到指定的下一跳路由器。 4.3.2 无类路由 CIDRClasslessInter-DomainRouting技术用于解决因特网中两种可扩展问题：第一，越来越多的网络号需要存在于主干网路由表中，从而导致了它的增长；第二，在第40亿台主机连接到因特网之前，32位的IP地址就可能已经耗尽。 CIDR尝试在减少一个路由器所需要知道的路由数的愿望与有效分配地址的需求之间取得平衡。为了做到这一点，CIDR帮我们汇聚路由。它通过打破地址分类间的严格界限。 CIDR通过一种新型标注或者用已知的前缀来表示网络号，因为前缀可以任意长，所以通常是放置一个”/X”在前缀后，其中”/X”表示前缀的位长度。 如20位的前缀可以表示为 192.4.16/20。 4.4 多播如第二章中，以太网和令牌环这样的多点访问网络用硬件实现多播。 为了更好的支持多对以及一对多的连接，IP提供了一种IP级模拟多播用于多点访问网络。 基本的IP多播模型是基于多播组的多对多模型，每个组都有自己的IP多播地址，组里的任何主机收到任何的分组拷贝都会发送到组的多播地址 这样发送主机不需要发送多个分组拷贝，因为路由器无论何时都会在需要的时候将分组转发给多个链接，相比于使用单播IP传送相同的分组给多个接受者，IP多播更可测，因为它消除了一些需要在同一个链路上发送多次的冗余流量，特别是靠近发送主机的链路。 IP的原始多对多播(任意源多播，ASM)已经增强为可支持的一对多播的形式。在一对多播模型中，即源特定多播(SSM)，接收主机指定一个多播组和特定发送主机，接收主机仅将从特定主机收到的多播地址发送给特定的组。 4.4.1 多播地址IP中有一个子空间是保留给多播地址的。在IPV4中，这些地址被分配在D类地址空间中。 4.4.2 多播路由多播路由是一个多播分配树的决策过程，更具体的书，是一个多播转发表的建立过程。 距离向量多播路由协议 DVMRP PIM MSDP 4.5 多协议标记交换 Multi-protocol Lavel Switching ,MPLSMPLS的好处 使不具备按正常方式转发IP数据报能力的设备能支持IP 按”显示路由”—-即预先计算的路由转发IP数据报，而无需匹配普通IP路由协议选择的路由 支持特定类型的虚拟专用网服务 4.5.1 基于目的地的转发链式索引(threaded index) 当一个路由器能够支持MPLS时，他给路由表中的每个前缀都分配一个标记，并将标记和所表示的前缀通知相邻路由器，此通知的分发由标记分发协议(LabelDistributionProtocol,LDP)携带。 标记边缘路由器(Label Edge Router,LER)对到达的IP分组进行完全的IP查找，然后用他们的标记作为查找的结果并附加到这个分组的头部。 这样，我们就用标记查找代替正常的IP目的地址查找。(IP地址查找算法需要查找最长匹配，与将要转发的分组中的IP地址高比特部分相匹配的最长前缀。相反，标记转发机制则是一种精确匹配算法，建立一个数组，标记为数组的索引) 4.5.2 显示路由源路由并未广泛使用，MPLS提供了一种方便的方法将类似源路由的能力添加到IP网络中，这种能力被称为显示路由。两者之间的区别在于。显示路由通常不是选择此路由的分组的真正源，在更多情况下它是服务提供者网络中的一个路由器。 资源预留协议(RSVP)","categories":[{"name":"网络","slug":"网络","permalink":"https://sfegsq.github.io/categories/网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://sfegsq.github.io/tags/计算机网络/"}]},{"title":"分组交换","slug":"分组交换","date":"2016-04-23T05:28:43.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/23/分组交换/","link":"","permalink":"https://sfegsq.github.io/2016/04/23/分组交换/","excerpt":"第二章讲述的直接相连的网络有两个局限性：第一，该网络限制可以连接到网络上的主机数。第二，这种网络限制一个单独的网络能跨越的地区范围。 计算机网络使用分组交换机(packet switch)，使分组能从一台主机传输到另外一台主机上，即使这些主机没有直接相连。 争用(contention)：如果指定的分组到达交换机的某个输出端口，并且分组到达的速率超出该输出端口的能力，就会产生争用问题。 分组转发技术分为无连接的和面向连接的两大类。有两个特殊的技术需要详细说明，第一种是局域网交换技术(LAN switching)技术，它由以太网的网桥(bridging)发展而来，并成为当前局域网环境中居于支配地位的技术之一。第二章值得注意的交换技术是异步传输模式(Asynchronous Transfer Mode,ATM),它广泛的应用于电信服务提供商的广域网中。","text":"第二章讲述的直接相连的网络有两个局限性：第一，该网络限制可以连接到网络上的主机数。第二，这种网络限制一个单独的网络能跨越的地区范围。 计算机网络使用分组交换机(packet switch)，使分组能从一台主机传输到另外一台主机上，即使这些主机没有直接相连。 争用(contention)：如果指定的分组到达交换机的某个输出端口，并且分组到达的速率超出该输出端口的能力，就会产生争用问题。 分组转发技术分为无连接的和面向连接的两大类。有两个特殊的技术需要详细说明，第一种是局域网交换技术(LAN switching)技术，它由以太网的网桥(bridging)发展而来，并成为当前局域网环境中居于支配地位的技术之一。第二章值得注意的交换技术是异步传输模式(Asynchronous Transfer Mode,ATM),它广泛的应用于电信服务提供商的广域网中。 3.1 交换和转发交换是一种允许我们互联链路以形成一个更大规模网络的机制。 交换网比共享介质网更具有可扩展性(scalable)，即具备增加更多节点的能力，因为交换网支持更多主机以完全链路速度传输数据。 交换机被连接到许多链路上，为了与链路的另一端的节点进行通信，每一条链路都运行相应的数据链路协议。一般的，我们假设每条链路分成输入和输出两部分，因此即支持输入，也指出输出。 问题是：交换机如何决定把每个分组放到哪一个输出端口上呢？ 一般的解决方法是交换机查看分组首部的标识符。 第一种称为数据报(datagram)或称为无连接(connectionless)的方法，第二种是虚电路(virtual circuit)或称为面向连接(connection)的方法。第三种方法不如前两种常用，称为源路由选择(source routing)。 所有的网络都需要有一种方法来标识端节点，这种方法通常称为地址，例如以太网中使用的48位MAC地址。 我们所需要做的另外一种假设就是有一些方法用来标识每台交换机的输入和输出端口。至少有两种实用的方法标识端口：一种是给每个端口进行编号，另一种是用输入和输出端口所连接的节点的名字标识来识别端口。现在，我们采用给端口编号的方法。 3.1.1 数据报每个分组都带有足够的信息，使得任何一个交换机都能决定怎么样使它到达目的地。这就是说，每个分组都导游完整的目的地址。交换机需要查阅转发表(forwarding table)有时也称为路由表(routing table)。 数据报(无连接)网络有以下特点： 一台主机无论何时都可以发送分组，因为任何到达交换机的分组都能够立即转发。 当一台主机发送分组的时候，主机无法知道网络是否可以传送该分组或目的主机是否可以接收 每个分组的转发都是独立于前面的分组的。可能沿着完全不同的路径。 当一台交换机或一段链路出现故障时，会在故障点周五找到一条可替代的路径，并相应地更新转发表，那么对通信部会产生任何严重的影响。 3.1.2 虚电路交换首先在源主机与目的主机之间建立一条虚连接，之后再发生数据。 在建立连接阶段，需要在源主机和目的主机之间的每一个交换机上建立“连接状态”，连接状态由连接经过的每个交换机的VC(Virtual Circuit)表。 在一个交换机上的VC表中的一条记录包括： 虚电路标识符(Virtual Circuit Identifier,VCI),在这个交换机上唯一标识连接，并且将放在属于这个连接的分组首部内传送； 由这个VC到达交换机的分组的输入接口； 从这个VC离开交换机的分组的输出接口 用于输出分组的一个可能不同的VCI 有两大类方法建立连接状态，一类是由网络管理员配置连接状态，这样的虚电路是”永久的”，自然，管理员也可以删除它，因此永久虚电路(Permanent Virtual Circuit,PVC)最好看作长期生存的或可管理配置的VC。另一类是主机能够发送消息给网络，建立连接状态，发送的消息称为信令(signalling),这样建立的虚电路称为是交换的(switched)。一个交换的虚电路(SVC)的突出特性是主机可以动态的建立和删除这个虚电路，而不需要网络管理员的参与。 虚电路技术最流行的例子是帧中继和异步传输模式(ATM),帧中继的应用之一是构造虚拟专用网(Virtual Private Network)。 3.1.3 源路由选择由源主机提供通过网络交换分组时所需的全部网络拓扑结构信息。实际上源路由选择有各种不同的方法。一种方法是给每个交换机的每个输出端口编号，把编号放入分组的首部。 3.2 网桥(bridge)和局域网交换机在共享介质局域网(如以太网)中转发分组的一类交换机(通称为局域网交换机，历史上也被称为网桥)。 假设现有两个想要互联的以太网，你必须做的第一件事是在他们之间放一个中继器，但任一对主机之间最多只能有2个中继器。所以，必须在两个以太网之间放一个节点，由节点来转发从一个以太网到另外一个以太网的帧。 由一个或多个网桥连接的LAN集合通常称为扩展局域网(extended LAN)。网桥仅在他们输入端口上接收局域网的帧，并在所有其他输出端口上讲这些帧转发出去。 3.2.1 学习型网桥优化：不需要转发所有收到的帧。建立转发表。 3.2.2 生成树算法问题：扩展局域网产生环路，造成帧永远在扩展局域网中循环。让网桥运行一个分布式生成树算法(spanning tree)。 3.2.3 广播和多播广播：每个网桥将带有目标广播地址的帧转发到除了接收它的端口以外的其他活动的端口。多播：组M的每个成员主机都必须定时的发送一个帧，在首部的源字段中携带组M的地址，这个帧的目标地址就是网桥的多播地址。 3.2.4 网桥的局限性局限只能用来连接少数相似的LAN，当我们考虑到可扩展性和异构性问题时，这种局限性就变得很明显。 可扩展性网桥连接过多LAN是不现实的，一般情况下不多于几十个。首先，因为生成树算法是线性扩展的，即没有为扩展局域网提供分层结构。另一个原因是网桥转发所有的广播帧，太大范围内的所有主机不可能都愿意受到相互广播信息的打扰。所以，广播的规模不能太大。 异构性网桥完全受限于他们所能互联的网络的类型，特别是网桥使用网络帧的首部，因此只能支持那些地址格式相同的网络。 增强扩展局域网的可扩展性的一种方法是虚拟LAN(VLAN)。VLAN允许一个扩展局域网被划分成几个看起来独立的LAN，给每个VLAN赋一个标识符，只要当两个网段有相同的标识符时，分组才能从一个网段传送到另外一个网段。这样可以限制接收任何给定广播分组的扩展局域网上的网段数目。 3.3 信元交换 ATMATM是一种面向连接的分组交换技术。按照ATM的术语,连接建立阶段称为发信令(signalling),同时在路径中的各个交换机中分配资源，这样做是为了保证电路具有特别的服务质量QoS。 与ATM网络中与众不同的一点事，用于交换的分组长度是固定的。一个分组是53个字节，5字节为首部信息，紧接48字节的有效载荷。 为了区分固定长度的分组和计算机网络中更常用的可变长度的分组，我们给定长的分组取名为信元(cell) 3.3.1 信元分组长度可变优点。 第一，发送小字节时，不必为发送而填充任何额外的信息。 第二，发送大文件时，可以降低首部字节数与数据字节数的比例，由此提高带宽利用率。同时，也可以使发送分组的总量减少，从而减少每分组操作的处理量。这一点对于获得高吞吐量来说非常重要，因为许多网络设备不受每秒能够处理多少个比特的限制，而是受到每秒能处理多少个分组的限制。信元长度不可变的优点 构建硬件来做简单的工作比较容易 所有分组长度相同，那么，可以让多个交换单元以并行方式做同样的事，他们中的每一个交换单元都花费相同时间去完成自己的工作。 3.3.2 分段和重组到目前为止，我们假设低层协议正好能接收高层协议传下来的分组，然后给分组加上首部信息，再继续向下传。然而，在ATM中这是不可能的，因为从上层传下来的分组经常大于48字节。故需要把高层的信息在源节点分段(fragment)成低层的分组，通过网络传输单独的低层分组，然后在目的地重组起来(reassembly)。 3.3.3 虚路径ATM使用24位标识符标明虚电路。并且分为两部分，8位虚路径标识符(VPI)和16位虚电路标识符(VCI)。这样一来在标识符中建立虚连接的两级层级结构。优点：尽管有成千上万条通过公用网的虚连接，但是公用网中交换机就像只有一条连接一样工作(只识别8位VPI)。 3.4 实现和性能3.4.1 端口端口的任务之一就是处理真实世界的复杂事物以便网状结构处理其中相对简单的工作。另一个关键功能是缓存。 3.4.2 网状结构 共享总线 (Shared-bus) 共享内存 (Shared-memory) 纵横式 (Crossbar) 自选路由 (Self-routing)","categories":[{"name":"网络","slug":"网络","permalink":"https://sfegsq.github.io/categories/网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://sfegsq.github.io/tags/计算机网络/"}]},{"title":"直接连接的网络","slug":"直接连接的网络","date":"2016-04-22T05:27:36.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/22/直接连接的网络/","link":"","permalink":"https://sfegsq.github.io/2016/04/22/直接连接的网络/","excerpt":"在节点能够成功的交换分组之前，必须先解决的五个问题。 对传送到铜线等介质上的比特编码(encoding) 把在链路上传输的比特序列描述为完整的消息，以便传送到端节点，这称为组帧(framing) 传输过程中帧有时候会出现错误，所以有必要检测这类差错并且采取适当的行动，这称为差错检错(error detection) 在帧尽管一次又一次出错的情况下，建立一条看起来可靠的链路 在多台主机共享一条链路(而不是用一条简单的点到点链路)的情况下，必须调解对这个链路的访问，这是介质访问控制(media access control)","text":"在节点能够成功的交换分组之前，必须先解决的五个问题。 对传送到铜线等介质上的比特编码(encoding) 把在链路上传输的比特序列描述为完整的消息，以便传送到端节点，这称为组帧(framing) 传输过程中帧有时候会出现错误，所以有必要检测这类差错并且采取适当的行动，这称为差错检错(error detection) 在帧尽管一次又一次出错的情况下，建立一条看起来可靠的链路 在多台主机共享一条链路(而不是用一条简单的点到点链路)的情况下，必须调解对这个链路的访问，这是介质访问控制(media access control) 2.1 网络构件网络由两类硬件构件组成:节点node和链路link 2.1.1 节点 node节点是指通用的计算机。为方便介绍，假设节点是工作站类的机器。 网络中最稀缺的两者资源：带宽与内存。内存之所以是稀缺资源，是因为当一个节点作为交换机或路由器时，分组在等待传输到一个输出链路之前必须在内存中缓存。同时，内存的时延改善速度远远不如CPU，作为一个网络节点，工作站是以其内存速度在运行，而不是CPU速度。 网络适配器适配器输出一个控制状态寄存器(control state register),它对于CPU来说是可读写的。 主机上的软件(设备驱动程序)对CSR写入信息，指示它传送/接收一个帧，并从CSR读出信息获得适配器的当前状态。为了通知主机像收到一帧这样的异步事件，适配器中断主机。 网络适配器最重要的问题之一就是数据字节如何在适配器和主机内存之间传递。 直接存储器访问(Direct Memory Access,DMA)和可编程输入输出(Programmed I/O,PIO)。 DMA：适配器直接读写主机内存而不必CPU介入，主机只是给适配器一个内存地址，适配器可读写它。 PIO：CPU直接负责在主机内存与适配器之间传递数据。 2.1.2 链路 link网络链路可用各种不同的物理介质实现。 在点到点链路上通常可用同时传输两个比特流，每个方向一个。这样的链路称为全双工(full-duplex)。一次仅支持数据向一个方向流动的点到点链路，称为半双工(half-duplex)，要求连接到骑上的两个节点轮流使用这条链路。 2.2 编码 NRZ,NRZI,Manchester,4B/5BNRZ Non-Return to Zero 不归零将数据值1映射为高电平，数值0映射为低电平。一长串的0和1导致两个基本问题第一个问题是导致基线漂移(baseline wander)的状态。接收方保持一个它所看到的信号的平均值，然后用这个平均值区分高低电平。第二个问题是由高到底和由低到高的频繁转换，必须使用时钟恢复(clock recovery)。时钟恢复问题就是：编码和解码过程都由一个时钟来驱动，每个时钟周期发送方发送1bit，接收方恢复1bit。为了使接收方能够恢复发送方发送的比特，发送方和接收方的时钟必须精确同步。只要有从1到0货从0到1的跳变，接收方就知道这是在时钟周期的边界上，他能够自己进行重新同步，然而，如果长时期没有这样的跳变就会导致时钟偏移。 NRZI Non-Return to Zero Inverted 不归零反转发送方以当前信号的一个跳变编码一个1，以保持当前信号编码一个0。这样就解决了连续1的问题，但是显然未解决连续0的问题。 Manchester 曼彻斯特编码通过传输NRZ编码数据与时钟的异或值使时钟与信号明显合并，(把本地时钟看作是一个从低到高变化的内部信号；一对低/高变化的电平看作是一个时钟周期)。注意曼彻斯特编码将0作为一个由低到高的跳变，1作为一个由高到低的跳变。不过曼彻斯特编码方案存在的问题是它使链路上信号跳变的速率加倍，这就意味着接收方有一半的时间在检测信号的每一个脉冲。信号变化的速率称为链路的波特率(baud rate)。在曼彻斯特编码中，比特率是波特率的一半，所以认为编码的效率仅为50%。 4B/5B这是一种力求不扩大高信号或低信号的持续期而解决曼彻斯特编码的低效问题。4B/5B的思想是在比特流中插入额外的比特打破一连串的0或1。准确的来说，就是用5个bit来编码4个比特的数据，再传送给接收方。5比特代码是由以下方式选定的:每个代码最多有1个前导0，并且末端最多有两个0。由于5比特代码足够用来编码32个不同的代码，因此剩下的16个可用于不同的目的。 2.3 组帧2.3.1 面向字节的协议最早的组帧方法是把每一帧看成一个字节(字符)集，而不是一个比特集。比如PPP与BISYNC。 检测文件结束的两种方法 起止标记法 字节计数法 当要在帧的数据部分出现与起止字符相同的数据时，需要在帧的数据部分插入额外的字符，所以这种方法常备称为字符填充法。 2.3.2 面向比特的协议(HDLC)与面向字节的协议不同，面向比特的协议不关心字节的边界，它只会把帧看成比特的集合。同样，如果数据部分出现起止控制比特序列，则需要利用比特填充法。 2.3.3 基于时钟的组帧(SONET)略 2.4 差错检测帧中有时会发生比特错误。例如，由于电干扰或热噪音，就会发生这样的错误。检错只是问题的一部分，另一部分是一发现差错就立即纠错。当消息的接收方检测到差错时，可以采取两种基本方法。一种，是通知发送方消息收到破坏，使发送方能重发消息的副本。如果比特错很少，那么重传的副本很可能没有差错。另一种方法是用集中差错检测算法，他们使接收方即使在消息出错后重新构造正确的消息。这些算法依赖于下面讨论的纠错码(error-correcting codes)。 任何差错检测方案的基本思想都是在帧中加入冗余信息来确定是否存在差错。 2.4.1 二维奇偶校验它基于“简单的”（一维）奇偶校验——通常把额外的1比特附加到7比特编码上，来平衡字节中1的个数。例如，奇校验根据字节中1的个数置位第8比特位，使8个比特中1的个数为奇数；而偶校验则置位第8比特位使8个比特中1的个数为偶数。二维奇偶校验对帧中每一字节的每一比特位置进行类似的计算。结果除了每一字节增加1个奇偶校验位外，整个帧产生了一个额外的奇偶校验字节。可以证明，二维奇偶校验可检测所有1、2、3比特错及大部分4比特错。在这种情况下，我们给42比特的消息加入了14比特的冗余信息。简单的二维奇偶校验码，也要弄清楚！ 2.4.2 因特网校验和算法因特网校验和的思想非常简单——将传输的所有字加起来，然后传输这个相加的结果，此结果称为校验和。接收方对收到的数据执行同样的计算，然后把得到的结果与收到的校验和进行比较。如果传输的任何数据（包括校验和本身）出错，那么结果将不相同，接收方就知道发生了错误。 这个算法比重复编码要好，因为它使用很少的冗余比特，即对任意长度的消息仅用16位，但是它的差错检测能力却不太好。例如，有一对单比特错，一个比特错使一个字增加1，而另一个比特错使另一个字减少1，若两种差错数量相同便无法检测。虽然在检错能力上相对较弱（例如与CRC相比），但我们仍然使用这种算法，原因很简单：这个算法易于用软件实现。ARPANET网的经验表明，这种形式的校验和就足够了。理由是校验和是端到端协议的最后一道防线，大部分差错将由链路层上更强的差错检测算法（如CRC）检查出来。网际校验和算法 2.4.3 循环冗余校验略 2.5 可靠传输即使在用纠错码时（例如在无线链路上），某些差错也可能过于严重而无法纠正。因此，某些差错帧必须丢弃。一个想要可靠传输帧的链路层协议必须能以某种方式恢复这些丢弃（丢失）的帧。通常使用两种基本机制——确认（acknowledgement）和超时（timeout）的组合来完成上述工作。确认（简称ACK）是协议发给它的对等实体的一个小的控制帧，告知它已收到刚才的帧。所谓控制帧就是一个无任何数据的首部，但是协议也可以将ACK捎带（piggyback）在一个恰好要发向对方的数据帧上。原始帧的发送方收到确认，表明帧发送成功。如果发送方在一段相当长的时间后未收到确认，那么它重传（retransmit）原始帧。等待一段相当长的时间的动作称为超时。使用确认和超时实现可靠传输的策略有时称为自动请求重发（Automatic Repeat Request, ARQ）。 2.5.1 停止和等待 stop and wait发送方传输一帧后，在传输下一帧之前等待一个确认。如果在一段时间之后确认没有到达，则发送方超时，并重传原始帧。在停止和等待算法中有一个重要的细节，如果发送方发送了一个帧，并且接收方确认它，但这个确认丢失或迟到了。在这两种情况下，发送方超时并重传原始帧，但接收方认为那是下一帧，因为他正确的接收并确认了第帧。这就引起重复传送帧的问题，为解决这个问题，可以在首部包含一比特的序号，即序号可以取0和1，并且每一帧交替使用序号。缺点：只允许发送方每次在链路上只有一个未确定的帧，这可能远远低于链路的容量。 2.5.2 滑动窗口 sliding window三个任务： 在不可靠的链路上可靠的传输帧 保持帧的传输顺序 流量控制 flow control发送方滑动窗口算法的工作过程如下。首先，发送方对每一帧赋予一个序号（sequence number），记作SeqNum。现在，忽略SeqNum是由有限大小的首部字段实现的事实，而假设它能无限增大。发送方维护三个变量：发送窗口大小（send window size），记作SWS，给出发送方能够发送但未确认的帧数的上界；LAR表示最近收到的确认帧（last acknowledgement received）的序号；LFS表示最近发送的帧（last frame sent）的序号。发送方还遵循如下的不等式： LFS－LAR≤SWS 接收方当确认到达时，发送方向右移动LAR，从而允许发送方发送另一帧。同时，发送方为所发的每个帧设置一个定时器，如果定时器在接收到ACK之前超时，则重传此帧。注意，发送方必须最多能缓存SWS个帧，因为在它们得到确认之前必须准备重传。 接收方维护下面三个变量：接收窗口大小（receive window size），记为RWS，给出接收方所能接收的无序帧数目的上界；LAF表示最大的可接收帧（largest acceptable frame）的序号；LFR表示最后收到的帧（last frame received）的序号。接收方也遵循如下不等式： LAF－LFR≤RWS 2.5.3 并发逻辑信道 concurrent logical channels在一个点到点的链路上多路复用多个逻辑信道，并且在每个逻辑信道上运行停止和等待算法。在任意逻辑信道上传输的帧之间没有任何关系，同时，因为在每个逻辑信道上可以有一个不同的待确认帧，所以发送方可保持链路满载。更准确的说，发送方为每一信道状态留3个比特：一个布尔量，说明信道当前是否忙；一比特序号，用于说明下次在这个逻辑信道上发送的帧的序号；以及下一帧的序号，用于说明期望到达这一信道的一个帧的序号。当节点有一个帧要发送时，它使用序号最小的空闲信道，其他方面表现就和停止和等待一样。 2.6 以太网以太网是一个正在使用的，更通用的带冲突检测的载波监听多路访问局域网技术的例子。(CSMA/CD) 2.6.1 物理特性以太网是在一个长度最高可达500m的同轴电缆上实现的。多个以太网可以由中继器(repeater)连接起来，中继器是一个转发数字信号的设备，很像转发模拟信号的放大器。然而在任一对主机之间最多可以安装4个中继器，这意味着以太网总共只能达到2500m。以太网最多支持1024台主机。一个主机送到以太网上的任何信号都是向全网广播的，即信号在两个方向传播，并由中继器将信号转发到所有输出网段。连接到每一网段末端的终结器吸收信号并阻止它反射而干扰到后继的信号。以太网使用之前提到的曼彻斯特编码。 2.6.2 访问协议控制访问共享以太网链路的算法——以太网的介质访问控制(Media Access Control,MAC)。通常在网络适配器上以硬件的方式实现。 帧格式 64bit 48bit 48bit 16bit 46-1500byte 32bit 前同步码 目的地址 源地址 类型 帧体 CRC 地址以太网上的每台主机都有一个唯一的以太网地址。从技术上来说，地址属于适配器而不是主机，通常固话在ROM中，以可读的方式显示，即由冒号分隔的6个数，每个数字对应于6字节地址的一个字节，并且由一对16进制数给出。 发送器算法线路一空闲就立即发送(1-persistant)当个两个适配器同时开始传输则两个或多个帧在网上冲突(collide)。因为以太网支持冲突检测，所以每个发送方能确定冲突的发生。当适配器检测出自己的帧与其他帧冲突时，它首先确保传输32位干扰序列，然后停止传输。因此，发送器在冲突的情况下将最少发送96位：64位前同步码加32位干扰序列。 一旦适配器检测到冲突并停止传输，它会等待一定的时间后再尝试。在每次尝试发送但失败后，适配器把等待时间加倍，然后再试。每次使重传尝试间的延迟间隔加倍的策略，一般称为指数退避（exponential backoff）技术。 2.7 环网 802.5,FDDI,rpr环网和以太网有两个共同的重要特征：第一，它包括一个分布式算法，控制每个节点何时可以传输；第二，所有的节点一般可以看到所有的帧，帧流过时，在帧首部中标识为目的的节点保留一个该帧的副本。 环网早期最常见的形式都令牌(token)环。当一个有帧要传输的节点看到令牌时，它把令牌从环上取下，而将直接的帧插入环中。沿路的每个节点简单的转发帧，目的节点保存帧的副本，然后将消息转发给环的下一个节点，当帧返回到发送方时，这个节点将帧取下，然后再插入令牌。以这种方式， 某个下游的节点将有机会发送一个帧，介质访问算法是公平的，因为令牌绕着环循环，每个节点都有机会发送帧，令牌环以轮转的方式为节点提供服务。 使用环拓扑，任何链路或节点的故障会造成整个网络的失效。该问题通过使用一个机电中继器将每个站点连接到环上来解决。多站访问单元(MSAU) 2.7.1 令牌环介质访问控制令牌包含一个3比特的优先级字段，因此，我们可以认为令牌在任何时候都有某个优先级n。希望发送分组的每个设备给该分组制定一个优先级。帧首部使用3个保留比特来改变令牌的优先级。 发送方可以在发送帧之后立刻将令牌放回环上(这称为提前释放early release)，或者在发送的帧绕环一周冰杯删除后再交回令牌(这称为延迟释放delayed release)。 2.7.2 令牌环维护每个令牌环都有一个指定的站点作为监控站(monitor)。监控站的作用是确保环的状态良好。环上的任意站都可以成为监控站，当环第一次建立起来或者当前的监控站出现故障时，将由已定义的过程选出监控站。状态良好的监控站用一个特殊的控制消息定期通告它的存在，如果一个站点在一段时间内没有看到这种消息，就假设监控站出现了故障并试图成为监控站。(采用“最高地址获胜”类似的某个定义好的规则来决定)。 2.7.3 FDDI由双环构成：两个独立的环以相反方向传输数据。第二个环正常情况下不使用，仅当主环发生故障时启用。 2.7.4 弹性分组环 RPR弹性(从链路或节点故障中快速回复的能力)是一个关键的设计目标，这使得该技术特别适合于服务提供者网络。不使用令牌，而使用一种被称为缓冲插入(buffer insertion)的技术。","categories":[{"name":"网络","slug":"网络","permalink":"https://sfegsq.github.io/categories/网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://sfegsq.github.io/tags/计算机网络/"}]},{"title":"计算机网络基础篇","slug":"计算机网络基础篇","date":"2016-04-22T05:26:29.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/22/计算机网络基础篇/","link":"","permalink":"https://sfegsq.github.io/2016/04/22/计算机网络基础篇/","excerpt":"基础 第一章问题：建造一个网络","text":"基础 第一章问题：建造一个网络 1.1 应用统一资源定位符（uniform resource locator,URL）点击一个URL后，因特网上可能需要交换多达17条消息才能得到网页，并且网页本身要小到可以存放在一条消息中。这些消息中有6条用来把服务器名翻译成他所对应的因特网地址（即IP地址，这个过程称为DNS解析），3条消息用来建立浏览器到服务器之间的传输控制协议（Transmission Control Protocol,TCP）的连接，4条消息用来让浏览器发送HTTP的get请求，并让服务器回送被请求的页面（以及双方对收到消息的确认），还有4条用来关闭TCP连接。 1.2 需求1.2.1 连通交换网 switched network 电路交换 circuit switched (多用于电话系统) 分组交换 packet switched (多用于计算机网络) 电路交换首先通过一系列链路建立一条专用电路，然后允许源节点通过这条链路发送给比特流到目标节点。 分组交换分组交换网的主要特点是网络中的结点彼此间发送离散的数据块，我们称每个数据块为一个分组(packet)或一条消息(message)。分组交换网一般使用一种叫做存储转发(store-and-forward)的策略。 路由选择根据地址(mac或者ip)来确定如何将信息转发到目标节点的过程。 1.2.2 成本 同步时分多路复用(synchronous time-division multiplexing,STDM) 频分多路复用(frequency-division multiplexing,FDM) 统计多路复用(statistical multiplexing) 拥塞 congested如果一段时间内，交换机接收分组的速度比它转送分组的速度快，那么交换机将最终用尽他的缓存空间，一些分组就会被丢弃。 1.2.3 支持公共服务可靠性 比特错(bit error) 分组级别的错误，也就是网络丢失了整个分组原因：分组含有不可纠正的比特错；拥塞丢失；处理分组的一个节点上运行的软件出现错误。 节点和链路级物理链路被切断或连接的计算机崩溃。 网络体系结构 OSI体系结构 因特网体系结构 1.3.1 分层和协议抽象层当系统变得复杂后，系统设计者引入另一个抽象层。抽象的思想是定义一个能捕获系统的主要特征的统一模型，并将这种模型封装为一个对象，为系统其它部分提供一个可操作的接口，对象如何实现的细节对于对象的使用者来说是隐藏的。 网络分层结构首先，它将建造一个网络的问题分解为多个可处理的部分，你不必希望实现所有的功能都集中在一个软件中，而是可以分几层，每一层解决一部分问题。第二，它提供一种更为模块化的设计，如果你想要加一些服务上去，只需要修改一层的功能，而继续使用其他各层提供的功能。 协议(Protocol)构成网络系统各层的抽象对象称为协议(Protocol)。每种协议定义两种不同的接口。首先，他为同一计算机上想使用它的通信服务的其他对象定义一个服务接口(service interface)。第二，一个协议为另一个机器上的对等实体定义一个对等接口(peer interface)。 封装原因：在硬件层，对等实体之间通过一条链路直接进行通信，除此之外，对等实体通信是间接的。每个协议和它的对等实体的通信是将消息传给更低层的协议，再由更低层协议将消息发给它的对等实体。方式：更低层的协议收到消息后，会将一个首部(header)附到消息上，有些协议则添加到消息的尾部(tailer)。格式由其协议规范定义，消息的奇遇部分称为消息体(body)或有效载荷(payload) 1.3.2 OSI体系结构ISO制定的体系结构称为开放系统互联(Open Systems Interconnection,OSI)体系结构。 将网络按功能分为7层，其中由一个或多个协议实现分配给某个特定层的功能。传输层和更高层通常只在终端主机上运行，不在中间交换机或路由器上运行。 应用层 application 包括文件传输协议(FTP),它定义一个协议是的文件传输应用可以互操作 表示层 presentation 关注对等实体间交换的数据的格式，例如一个整数是16，32还是64位，最先传输还是最后传输最高有效位，或者如何格式化一个视频流。 会话层 session 提供一个名字空间用来将一个应用的各部分不同的传输流练习在一起。例如，在视频会议应用中，他可以同时管理一个音频流与一个视频流 传输层 transport进程对进程的信道，在此交换的数据单元通常称为消息(message) 网络层 network 处理分组交换网中节点的路由选择。在这一层，节点交换的数据单元通常称为分组(packet)而不是帧 数据链路层 data link 收集比特流形成一个更大的集合体称为帧(frame)，典型情况下，由网络适配器和运行在节点操作系统上的设备驱动程序实现数据链路层。 物理层 physical 处理通信链路上原始比特的传输 1.3.3 因特网体系结构因特网体系结构，有时也成为TCP/IP体系结构，TCP和IP是它的两个主要协议。 应用层 在传输层以上运行的应用协议，如FTP,普通文件传输协议(Trivial File Transport Protocol,TFTP),Telnet(远程登录)和简单邮件传输协议(Simple Mail Transfer Protocol,SMTP),使常用的应用可互操作。 TCP/UDP层 传输控制协议(Transmission Control Protocol)和用户数据报协议(User Datagram Protocol),TCP和UDP为应用程序提供可选的逻辑信道：TCP提供可靠的字节流信道，UDP提供不可靠的数据报传送信道(数据报可认为是消息的同义词)，在因特网语言中，TCP和UDP有时被称为端到端(end-to-end)的协议，还可以被认为是传输协议。 网际协议层 Internet Protocol 这个协议支持多种网络技术互联为一个逻辑网络 网络层 多种网络协议，表示为NET1,NET2等等，实际中，这些协议由硬件(如网络适配器)和软件(如网络设备驱动程序)共同实现。例如，以太网或光纤分布式数据接口(FDDI)协议。 因特网体系结构有3个特点，第一，因特网体系结构并没有严格的划分层，这样应用比较自由，可以跨过层直接使用IP或一个底层网络，事实上，程序员可以自由定义新的信道抽象或在任何已有协议上运行的应用程序。第二，IP作为体系结构的焦点，它定义各种网络中交换分组的一种共同方法。IP之上可以有多个传输协议，每个协议为应用程序提供一种不同的信道抽象。这样，从主机到主机传送消息的问题就完全从提供一种有用的进行到进程的通信服务的问题中分离了出来。IP之下，这个体系结构允许很多不同的网络技术，从以太网到FDDI，到ATM，到简单的点到点链路。第三，为了在网络体系结构中提出一个官方新协议，必须产生一个协议规范和至少一个该规范的典型实现。 沙漏的设计理念，沙漏的细腰部代表最小的，经过精心挑选的通用功能集，他允许高层应用和低层通信技术并存，共享各种功能，并快速发展。 1.4 实现网络软件每个协议提供一系列服务(service)，API则提供特定操作系统中调用这些服务所用的语法(syntax)。 1.4.1/1.4.2 应用编程接口(套接字) socket1.4.3 协议实现的问题进程模型大多数操作系统都提供一种称为进程(process)或线程(thread)的抽象概念。每个进程的运行很大程度上独立于其他进程，操作系统负责确保给所有当前进程分配如地址空间和CPU周期这样的资源。当操作系统停止正在CPU上执行的进程并启动另一进程时，我们成这一转换为上下文且含(context switch)。 进程/协议(process-per-protocol)模型每个协议由一个独立的进程实现，这就意味着当一条消息向协议栈的上方或下方移动时，他被从一个进程/协议传送到另一个进程/协议。一个进程/协议如何向下一个进程/协议传递消息依赖于主机操作系统提供的进程间通信支持。通常有一个简单的机制用于进程的消息入队。然后，最重要的一点是，协议图的每一层都要求上下文切换，这是一个典型的耗费时间的操作。 进程/消息(process-per-message)模型把每个协议当做一段静态编码并把进程同消息联系起来，也就是说，当一条消息从网络到达时，操作系统调度一个进程，使之负责消息在协议图中想上移动。在每一层调用实现协议的过程，由此导致调用实现下一个协议的过程，依此类推。 两个模型中，进程/消息模型更为高效，这是因为：在大多数计算机上，过程调用的效率比上下文切换高一个数量级。第一种模型要求每一层耗费一个上下文切换的代价，而第二种模型每一层只耗费一个进程调用。 消息缓冲区套接字第二个低效率在于当调用send操作时，应用程序进程提供缓冲区，该缓冲区保存向外发送的消息，类似于当调用receive操作时将进来的消息复制到缓冲区中。他强制最高层的协议把消息从应用程序缓冲区复制到网络缓冲区中，反之亦然。讲一个数据从一个缓存区复制到另一个缓存区是协议实现中开销最大的工作之一。这是因为处理器的速度飞速发展，而存储器的发展并不如处理器那么快。 为了不再协议栈的每一层都把消息从一个缓冲区复制到另一个缓存区中，大多数网络子系统定义了一种消息的抽象数据类型，它由协议图中的所有协议共享。这一抽象不仅允许消息不必复制就可以在协议图中向上或向下传递，而且它还提供其他无复制的方法来处理消息，如增加或去掉一个头部，将一个大的消息拆分成几个小的消息。消息抽象的确切格式随操作系统的不同而有所不同。 1.5 性能1.5.1 带宽和时延带宽bandwidth(也成为吞吐量throughput)网络的带宽是在一段特定时间内网络所能传送的比特数。 时延latency(也成延迟delay)将一个消息从网络的一段传到另一端所需花费的时间。在很多情况下，更重要的是知道一个消息从网络的一端传送到另一端并返回所花费的时间，而不只是单程的时延。我们称它为网络的往返时间(round-trip time)。 我们通常认为时延由三部分组成：第一，光速传播延迟；第二，发送一个数据单元花费的时间，它是网络带宽和运载数据分组的大小的函数；第三，网络内部的排队延迟，因为分组交换机在将分组转发出去之前通常需要将它存储一段时间。计算公式latency = propagation + transmit + queuepropagation = distance/SpeedOfLighttransmit = size/bandwidth 当消息只包括1比特且我们讨论一条链路而不是整个网络的情况时，那么transmit和queue就无关紧要了，时延只与传播延迟(propagation delay)有关。 1.5.2 延迟和带宽的乘积延迟和带宽的乘积相当于第一个比特到达接受者之前，发送者必须发送的比特数。如果发送者希望接收者给出比特已开始到达的信号，而且这个信号发回到发送者需经另一个信道时延(即我们队信道的往返时延比单程时延更感兴趣)，那么发送者在接收到接收者发出的信号之前能够发完两倍时延和带宽乘积的数据。","categories":[{"name":"网络","slug":"网络","permalink":"https://sfegsq.github.io/categories/网络/"}],"tags":[{"name":"计算机网络","slug":"计算机网络","permalink":"https://sfegsq.github.io/tags/计算机网络/"}]},{"title":"排序算法","slug":"排序算法","date":"2016-04-20T05:40:53.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/20/排序算法/","link":"","permalink":"https://sfegsq.github.io/2016/04/20/排序算法/","excerpt":"排序基本概念排序是计算机程序设计中的一种重要操作，他的功能是将一个数据元素(或记录)的任意排列，重新排列成一个按关键字有序的序列。待排序的记录序列中可能存在两个或两个以上的关键字相等的记录，且在排序前Ri在Rj前面(即i","text":"排序基本概念排序是计算机程序设计中的一种重要操作，他的功能是将一个数据元素(或记录)的任意排列，重新排列成一个按关键字有序的序列。待排序的记录序列中可能存在两个或两个以上的关键字相等的记录，且在排序前Ri在Rj前面(即i","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://sfegsq.github.io/categories/数据结构/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"},{"name":"数据结构","slug":"数据结构","permalink":"https://sfegsq.github.io/tags/数据结构/"}]},{"title":"查找算法","slug":"查找算法","date":"2016-04-19T05:40:53.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/19/查找算法/","link":"","permalink":"https://sfegsq.github.io/2016/04/19/查找算法/","excerpt":"查找表相关概念查找表是由同一类型的数据元素(或记录)构成的集合。由于”集合”中的数据元素之间存在着完全松散的关系，因此查找表是一种非常灵便的数据结构。","text":"查找表相关概念查找表是由同一类型的数据元素(或记录)构成的集合。由于”集合”中的数据元素之间存在着完全松散的关系，因此查找表是一种非常灵便的数据结构。静态查找表 static search table 动态查找表 dynamic search table 关键字 key 关键字是数据元素中某个数据项的值，用它可以标识一个数据元素。 静态查找表顺序表的查找顺序查找的过程：从表中的最后一个记录开始，逐个进行记录的关键字与给定的值进行比较，若某个记录的关键字和给定值比较相等，则查找成功。 小技巧：监视哨 在查找表的第一个记录中存储在要查找的值，则可以避免查找过程中每一步都要检测整个表是否查找完毕。优点算法简单且适应面广，对表的结构无任何要求。缺点平均查找长度较大。特别是当n很大时，查找效率较低，为(1+n)/2。 有序表的查找 折半查找先确定待查找记录所在的范围，然后逐步缩小范围直到找到或找不到该记录为止。折半查找的效率比顺序查找高，但折半查找只适用于有序表，且限于顺序存储结构(对线性链表无法有效地进行折半查找) 斐波那契查找123F0 =0，F1=1;Fi=F(i-1)+F(i-2); 斐波那契查找的平均性能优于折半查找，但是最坏情况下的性能却比折半查找差。O（logn），它还有一个优点就是分割时只进行加，减运算。 插值查找插值查找是根据给定值key来确定进行比较的关键字的查找方法。令i=(key-ST[l].key)(h-l+1)/(ST[h].key-ST[l].key)。其中ST[l].key和ST[h].key分别为有序表中具有最小关键字和最大关键字的记录。显然这种插值查找只适于关键字分布均匀的表，在这种情况下，对表长较大的顺序表，其平均性能比折半查找好。 静态树表的查找前面对有序表的查找性能的讨论是在“等概率”的前提下进行的。但有序表中各个记录的查找概率不等式，则可以采用静态树表的查找。 如果只考虑查找成功的情况，则使查找性能达到最佳的判定树是其带权内路径长度之和PH值取最小的二叉树(静态最优查找树 static optimal search table)。由于构建静态最优查找树花费的时间代价较高，因此仅介绍一种构造近似最优查找树(nearly optimal search table)的有效算法。 索引顺序表的查找若以索引顺序表表示静态查找表，则查找可以用分块查找。分块查找又称为索引顺序查找，这是顺序查找的一种改进方法。在这种查找方法中，除表本身外，还需要建立一个“索引表”。将所有记录划分成多个子表，对每个子表建立一个索引项，其中包括两项内容：关键字项(保存该子表内的最大关键字)和指针项(指示该子表的第一个记录在表中的位置)。 动态查找表动态查找表的特点是，表结构本身是在查找过程中动态生成的，即对于给定值key，若表中存在其关键字等于key的记录，则查找成功返回，否则插入关键字等于key的记录。 二叉排序树 binary sort tree定义 若左子树不为空，则左子树上所有结点的值(关键字)都小于根结点的值； 若右子树不为空，则右子树上所有结点的值(关键字)都大于根结点的值； 左、右子树都分别是二叉排序树。 结论：若按中序遍历一棵二叉排序树，所得到的结点序列是一个递增序列。 平衡二叉树 AVL balanced binary tree定义它是一棵空树或它的左右两个子树的高度差的绝对值不超过1，并且左右两个子树都是一棵平衡二叉树。 红黑树 AVLB-和B+树留键树(数字查找树)留 哈希表哈希表的构造方法 直接定址法：取关键字或关键字的某个线性函数值为散列地址。即H(key)=key或H(key) = a·key + b，其中a和b为常数（这种散列函数叫做自身函数）。若其中H(key）中已经有值了，就往下一个找，直到H(key）中没有值了，就放进去。 数字分析法：分析一组数据，比如一组员工的出生年月日，这时我们发现出生年月日的前几位数字大体相同，这样的话，出现冲突的几率就会很大，但是我们发现年月日的后几位表示月份和具体日期的数字差别很大，如果用后面的数字来构成散列地址，则冲突的几率会明显降低。因此数字分析法就是找出数字的规律，尽可能利用这些数据来构造冲突几率较低的散列地址。 平方取中法：当无法确定关键字中哪几位分布较均匀时，可以先求出关键字的平方值，然后按需要取平方值的中间几位作为哈希地址。这是因为：平方后中间几位和关键字中每一位都相关，故不同关键字会以较高的概率产生不同的哈希地址。 折叠法：将关键字分割成位数相同的几部分，最后一部分位数可以不同，然后取这几部分的叠加和（去除进位）作为散列地址。数位叠加可以有移位叠加和间界叠加两种方法。移位叠加是将分割后的每一部分的最低位对齐，然后相加；间界叠加是从一端向另一端沿分割界来回折叠，然后对齐相加。 随机数法：选择一随机函数，取关键字的随机值作为散列地址，通常用于关键字长度不同的场合。 除留余数法：取关键字被某个不大于散列表表长m的数p除后所得的余数为散列地址。即 H(key) = key MOD p,p&lt;=m。不仅可以对关键字直接取模，也可在折叠、平方取中等运算之后取模。对p的选择很重要，一般取素数或m，若p选的不好，容易产生同义词。 处理冲突的方法 开放定址法：Hi=(H(key) + di) MOD m,i=1,2，…，k(k&lt;=m-1），其中H(key）为散列函数，m为散列表长，di为增量序列，可有下列三种取法：1.1. di=1,2,3，…，m-1，称线性探测再散列；1.2. di=1^2,-1^2,2^2,-2^2，⑶^2，…，±（k)^2,(k&lt;=m/2）称二次探测再散列；1.3. di=伪随机数序列，称伪随机探测再散列。 再哈希法：Hi=RHi(key),i=1,2，…，k RHi均是不同的散列函数，即在同义词产生地址冲突时计算另一个散列函数地址，直到冲突不再发生，这种方法不易产生“聚集”，但增加了计算时间。 链地址法（拉链法）将所有关键字为同义词的记录存储在同一线性链表中 建立一个公共溢出区，一旦冲突全部填入溢出表 参考资料 动态查找–二叉排序树","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://sfegsq.github.io/categories/数据结构/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"},{"name":"数据结构","slug":"数据结构","permalink":"https://sfegsq.github.io/tags/数据结构/"}]},{"title":"串","slug":"串","date":"2016-04-18T05:40:07.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/18/串/","link":"","permalink":"https://sfegsq.github.io/2016/04/18/串/","excerpt":"串(string)(或字符串)是由零个或者多个字符组成的有限序列。","text":"串(string)(或字符串)是由零个或者多个字符组成的有限序列。 串的表示和实现定长顺序存储表示类似于线性表的顺序存储结构，用一组地址连续的存储单元存储串值的字符序列。 在串的定长顺序存储结构中，按照预定义的大小，为每个定义的串变量分配一个固定长度的存储区。 串的实际长度可在这预定义长度的范围内随意，超过预定义长度的串值则会被舍弃，称之为”截断”。 堆分配存储表示以一组地址连续的存储单元存放串值字符序列，但它们的存储空间是在程序执行过程中动态分配而得。在C语言中， 存在一个称之为”堆”的自由存储区，并由C语言的动态分配函数malloc()和free()来管理。 串的块链存储表示和线性表的链式存储结构相似，也可以采用链表方式存储串值。由于串结构的特殊性，串结构中的每个数据元素是一个字符，则 用链表存储串值时，存在一个”结点大小”的问题，即每个结点可以存放一个字符，也可以存放多个字符。 串的模式匹配算法12345678910111213141516171819function index(fatStr,sonStr)&#123; var fatStrLen = fatStr.length, sonStrLen = sonStr.length, gap = fatStrLen - sonStrLen, i = 0; while (i&lt;=gap) &#123; for (var j = 0; j &lt; sonStrLen; j++) &#123; if (fatStr.charAt(i+j)!==sonStr.charAt(j)) &#123; break; &#125; &#125; if (j === sonStrLen) &#123; return i; &#125;else &#123; i++; &#125; &#125; return -1;&#125; 模式匹配的一种改进算法 这种改进算法是 克努特，莫里斯，普拉特三人同时发现的，因此简称其为KMP算法。 这种算法的改进在于每当一趟匹配过程中出现字符比较不等时，不需要回溯，而是利用已经得到的”部分匹配”的结果将模式 向右滑动尽可能远的一段距离后，继续进行比较。 12345678910111213141516171819202122232425262728293031323334353637function kmpGetNext(str) &#123; var len = str.length, next = [0]; for (var i = 1; i &lt; len; i++) &#123; var tmp = 0; for (var j = 0; j &lt; i; j++) &#123; if (str.slice(0, j + 1) == str.slice(i - j, i + 1)) &#123; tmp = j + 1; &#125; &#125; next.push(tmp); &#125; return next;&#125;function kmp(fatStr, sonStr) &#123; var fatStrLen = fatStr.length, sonStrLen = sonStr.length, gap = fatStrLen - sonStrLen, next = kmpGetNext(sonStr), //替代 i = 0, j = 0; while (i &lt;= fatStrLen) &#123; if (fatStr.charAt(i) == sonStr.charAt(j)) &#123; i++; j++; &#125; else if (j !== 0) &#123; j = next[j]; //如果j不等于0就让j等于next[j] &#125; else &#123; i++; //j等于0，且不匹配，则i主串向右划 &#125; if (j === sonStrLen - 1) &#123; //当完全匹配时，返回i-j，即子串对应的序号 return i - j; &#125; &#125; return -1;&#125;","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://sfegsq.github.io/categories/数据结构/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"},{"name":"数据结构","slug":"数据结构","permalink":"https://sfegsq.github.io/tags/数据结构/"}]},{"title":"栈和队列","slug":"栈和队列","date":"2016-04-17T05:39:23.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/17/栈和队列/","link":"","permalink":"https://sfegsq.github.io/2016/04/17/栈和队列/","excerpt":"是限定仅在表尾进行插入或删除操作的线性表。因此对于栈来说，表尾端有其特殊含义，称为栈顶（top）， 表头端称为栈底(base)。因此，栈又称为后进先出的线性表。","text":"是限定仅在表尾进行插入或删除操作的线性表。因此对于栈来说，表尾端有其特殊含义，称为栈顶（top）， 表头端称为栈底(base)。因此，栈又称为后进先出的线性表。 栈的应用举例12345678910111213141516171819//行编辑器function lineEdit(str) &#123; var stack = []; for (var i = 0; i &lt; str.length; i++) &#123; switch (str.charAt(i)) &#123; case \"#\": //#代表退一个 console.log(\"出栈\" + stack.pop()); break; case \"@\": //清空 console.log(\"清空\" + stack); stack = []; break; default: //压入 stack.push(str.charAt(i)); &#125; &#125; console.log(stack.join(\"\"));&#125;lineEdit(\"nihaoyaa#wohenhao\"); 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768//表达式求值/*四则运算的法则1.先乘除，后加减2. 从左算到右3. 先括号内，再括号外*/function evaluateExpression(str) &#123; var num = &#123; \"+\": 0, \"-\": 1, \"*\": 2, \"/\": 3, \"(\": 4, \")\": 5, \"#\": 6 &#125;; var pri = [ //各个运算符的优先级 [1, 1, -1, -1, -1, 1, 1], [1, 1, -1, -1, -1, 1, 1], [1, 1, 1, 1, -1, 1, 1], [1, 1, 1, 1, -1, 1, 1], [-1, -1, -1, -1, -1, 0, null], [1, 1, 1, 1,null, 1, 1], [-1,-1,-1,-1,-1,null,0] ]; function precede(firChar, secChar) &#123; //比较输入的两个字符的优先级 var firNum = num[firChar], secNum = num[secChar]; return pri[firNum][secNum]; &#125; var opNum = [], //操作数 opChar = [\"#\"], //操作符 i = 0; while (str.charAt(i)!=\"#\" || opChar[opChar.length-1]!=\"#\") &#123; //查询到最后的#则表示运算表达式结束 var numPush=\"\"; //要压入的数字 可能是任何位数的数字 while (!(str.charAt(i) in num)) &#123; numPush+=str.charAt(i++); //拼接数字 &#125; if (numPush!==\"\") &#123; opNum.push(numPush); //如果numPush不为空，则压入 &#125; if ((str.charAt(i) in num))&#123; //如果当前位为运算符 var tmp = opChar[opChar.length - 1]; switch (precede(opChar[opChar.length - 1],str.charAt(i))) &#123; //调用precede方法比较运算符优先级 case -1: //小于，则将运算符压入 opChar.push(str.charAt(i++)); break; case 0: opChar.pop(); //将运算符推出 i++; break; case 1: var firstNum = opNum.pop(), secondeNum = opNum.pop(), optionChar = opChar.pop(), var result = eval(secondeNum+optionChar+firstNum); //拼接运算表达式 opNum.push(result); break; &#125; &#125; &#125; return opNum[opNum.length-1];&#125;console.log(evaluateExpression(\"1+2+2*(2+6/2)#\")); 栈与递归的实现通常，当在一个函数内，调用另外一个函数时，在运行被调用函数前，系统必须先完成3件事情， 将所有的实参，返回地址等信息传递给被调用函数保存 为被调用函数的局部变量分配存储区 将控制转移到被调用函数的入口 而被调用函数返回调用函数之前，系统也应该完成3件事情。 保存被调用函数的计算结果 释放被调用函数的数据区 依照被调用函数保存的返回地址将控制转移到调用函数 12345678910111213141516171819202122//n阶汉尼塔// n代表总共的圆盘数量，x,y,z代表3个hanoi塔// 将x上的n个圆盘移到z上，并以y为辅助function hanoi(n, x, y, z) &#123; if (n == 1) &#123; move(x, z); &#125; else &#123; hanoi(n - 1, x, z, y); move(x, z); hanoi(n-1, y, x, z); &#125;&#125;var x = [9,8,7,6,5,4,3, 2, 1], y = [], z = [];function move(x, z) &#123; var tmp = x.pop(); z.push(tmp);&#125;hanoi(9, x, y, z); 队列 queue和栈相反，队列是一种先进先出的线性表。他只允许在表的一端进行插入，而在另一端进行删除元素。 允许插入的一端叫做队尾(rear),允许删除的一端则称为队头(front) 链队列 循环队列 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106var waitQueue = [ [], [], [], [] ], //等待队列 closeTime, totolCus=0, eventQueue = [], //事件列表 customQueue = [];function Custom() &#123; this.arrivalTime = new Date(); this.nextCustom = Math.floor(Math.random() * 5); this.duration = Math.floor(Math.random() * 30); this.queue = \"\"; //排哪一队 this.leaveTime = function() &#123; this.leaveTime = new Date(); &#125;; this.totalTime = function() &#123; if (typeof this.leaveTime !== \"function\") &#123; this.totalTime = Math.floor((this.leaveTime - this.arrivalTime) / 1000); &#125; else &#123; alert(\"离开时间尚未设定\"); &#125; &#125;;&#125;function Event(type) &#123; this.type = type; this.custom = function() &#123; this.custom = new Custom(); &#125;;&#125;//用户到达事件处理函数function arrEvent(custom, waitQueue) &#123; var tmp = 0; for (var i = 0; i &lt; waitQueue.length; i++) &#123; if (waitQueue[tmp].length &gt; waitQueue[i].length) &#123; tmp = i; &#125; &#125; custom.queue = tmp; //达到后，将其插入排队 waitQueue[tmp].push(custom); if (waitQueue[tmp].length == 1) &#123; setTimeout(function () &#123; leaveCus(waitQueue[tmp][0]); &#125;, waitQueue[tmp][0].duration); &#125;&#125;// 用户离开事件处理函数function leaveEvent(custom, waitQueue) &#123; custom.leaveTime(); //标志离开时间 custom.totalTime(); //计算总时间 customQueue.push(waitQueue[custom.queue].shift()); //将离开的用户压入用户数组中 if (waitQueue[custom.queue]) &#123; setTimeout(leaveCus(waitQueue[custom.queue][0]),waitQueue[custom.queue][0].duration); &#125;&#125;//银行开业，初始化顾客function openBank() &#123; var firEvent = new Event(0); firEvent.custom(); eventQueue.push(firEvent); startCus(firEvent.custom);&#125;//生成用户到达事件，递归生成function startCus(custom) &#123; setTimeout(function() &#123; var eventTmp = new Event(0); eventTmp.custom(); //新建客户 if (eventTmp.custom.arrivalTime.getTime()&gt;closeTime) &#123; console.log(\"不欢迎新顾客\"); return \"不欢迎新顾客\"; &#125; eventQueue.push(eventTmp); totolCus++; startCus(eventTmp.custom); &#125;, custom.nextCustom);&#125;// 生成用户离开事件，递归离开function leaveCus(custom) &#123; var eventTmp = new Event(1); eventTmp.custom = custom; eventQueue.push(eventTmp); // setTimeout(leaveCus(waitQueue[eventTmp.custom.queue][1]), waitQueue[eventTmp.custom.queue][1].duration);&#125;function bankInit() &#123; closeTime = new Date(); closeTime = closeTime.getTime() + 1000; openBank(); while (eventQueue) &#123; var ev = eventQueue.shift(); switch (ev.type) &#123; case 0: arrEvent(ev.custom, waitQueue); break; case 1: leaveEvent(ev.custom, waitQueue); break; default: alert(\"事件无效\"); &#125; &#125;&#125;","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://sfegsq.github.io/categories/数据结构/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"},{"name":"数据结构","slug":"数据结构","permalink":"https://sfegsq.github.io/tags/数据结构/"}]},{"title":"线性表","slug":"线性表","date":"2016-04-16T05:38:37.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/16/线性表/","link":"","permalink":"https://sfegsq.github.io/2016/04/16/线性表/","excerpt":"线性表是是n个数据元素的有限序列。","text":"线性表是是n个数据元素的有限序列。 线性表的顺序表示和实现用一组地址连续的存储单元依次存储线性表的数据元素。 查找的时间复杂度为O(1)，但是插入和删除元素时，需要将插入或者删除以后的元素往前或往后移一个单位长度。时间复杂度为O(n)。 线性表的链式表示和实现用一组任意的存储单元存储线性表的数据元素。 123456789101112131415161718function logLinear()&#123;//构造链表并输出 // 构造链表 并输出链表的数据 function linearNode(value,next)&#123; //构造函数 构造线性表的节点结构 this.value = value; this.next = next; //指向下一个节点的指针 &#125; var linearHeadNode = new linearNode(null), //标识链表 node = linearHeadNode; //node 用来作为存储临时结点 for (var i = 0; i &lt; 20; i++) &#123; node.next = new linearNode(i); node = node.next; &#125; node = linearHeadNode; while (node.next) &#123; console.log(node.next); node = node.next; &#125;&#125; 1234567891011121314151617181920212223242526272829303132333435363738394041424344function mathlinear()&#123; //进行一元多项式的计算 // 构造链表 并输出链表的数据 function linearNode(qa,qb,next)&#123; //构造函数 构造线性表的节点结构 this.qa = qa; this.qb = qb; this.next = next; //指向下一个节点的指针 &#125; var linearListA = new linearNode(), //标识链表 linearListB = new linearNode(), linearListC = new linearNode(), nodeC = linearListC, nodeB = linearListB, nodeA = linearListA; //node 用来作为存储临时结点 for (var i = 0; i &lt; 4; i++) &#123; nodeA.next = new linearNode(i, i+3); nodeB.next = new linearNode(i+2, i+2); nodeA = nodeA.next; nodeB = nodeB.next; &#125; nodeA = linearListA; nodeB = linearListB; while (nodeA.next&amp;&amp;nodeB.next) &#123; if (nodeA.next.qb&lt;nodeB.next.qb) &#123; nodeC.next = nodeA.next; nodeC = nodeC.next; nodeA = nodeA.next; &#125;else if (nodeA.next.qb===nodeB.next.qb) &#123; nodeC.next = nodeA.next; nodeC.next.qa = nodeA.next.qa+nodeB.next.qa; nodeC = nodeC.next; nodeB = nodeB.next; nodeA = nodeA.next; &#125;else &#123; nodeC.next = nodeB.next; nodeC = nodeC.next; nodeB = nodeB.next; &#125; &#125; nodeC = linearListC; while (nodeC.next) &#123; console.log(\"系数：\"+nodeC.next.qa +\"指数：\"+nodeC.next.qb); nodeC = nodeC.next; &#125;&#125; 循环链表表中最后一个结点的指针域指向头结点。由此从表中任意位置出发都可以找到表中其他结点。 双向链表双向链表的结点中有两个指针域，其一指向直接后继，另一指向直接前继。 由于链表在空间的合理利用上和插入，删除时不需要移动等优点，因此在许多场合，她是线性表的首选存储结构","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://sfegsq.github.io/categories/数据结构/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"},{"name":"数据结构","slug":"数据结构","permalink":"https://sfegsq.github.io/tags/数据结构/"}]},{"title":"树和二叉树","slug":"树和二叉树","date":"2016-04-15T05:36:30.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/04/15/树和二叉树/","link":"","permalink":"https://sfegsq.github.io/2016/04/15/树和二叉树/","excerpt":"树的结点包含一个数据元素以及若干个指向其子树的分支。 结点拥有的子树数称为结点的度(degree). 度为0的结点称为叶子(leaf)或终端结点。度不为0的结点称为非终端结点或分支结点。 除根节点以外，分支结点也称为内部结点。 树的度是树内各结点的度的最大值。 结点的子树的根称为该结点的孩纸，相应的，该结点称为孩子的双亲(parent). 树中结点的最大层次称为树的深度(depth)或者高度。 如果将树中结点的各子树看成从左至右是有次序的(即不能互换)，则称该树为有序树，否则称为无序树。 森林(forest)是多颗互不相交的树的集合。","text":"树的结点包含一个数据元素以及若干个指向其子树的分支。 结点拥有的子树数称为结点的度(degree). 度为0的结点称为叶子(leaf)或终端结点。度不为0的结点称为非终端结点或分支结点。 除根节点以外，分支结点也称为内部结点。 树的度是树内各结点的度的最大值。 结点的子树的根称为该结点的孩纸，相应的，该结点称为孩子的双亲(parent). 树中结点的最大层次称为树的深度(depth)或者高度。 如果将树中结点的各子树看成从左至右是有次序的(即不能互换)，则称该树为有序树，否则称为无序树。 森林(forest)是多颗互不相交的树的集合。 二叉树 binary tree 性质 在二叉树的第i层上至多有2的(i-1)次方个结点 深度为k的二叉树至多有2的k次方-1个结点。 对任何一颗二叉树，如果其终端结点个数为n0，度为2的结点个数为n2，则n0=n2+1;(推导：n=n0+n1+n2,n=1+2n2+n1) 具有n个结点的完全二叉树的深度为[log2-n]+1 满二叉树 一颗深度为k且有2的k次方-1个结点的二叉树称为满二叉树。 完全二叉树 可以对满二叉树的结点进行编号，约定编号从根节点起，自上而下，自左至右。 由此可以引出完全二叉树的定义：深度为k的，有n个结点的二叉树，当且仅当其每一个结点都与深度为k的满二叉树中编号从1至n的结点一一对应时，称之为完全二叉树。 二叉树的存储结构 顺序存储结构 用一组地址连续的存储单元依次自上而下，自左至右存储完全二叉树上的结点元素，即将完全二叉树上编号为i的结点元素存储在如上定义的一维数组中下标为i-1的分量中。 对于一般二叉树。则应将其每个结点与完全二叉树上的结点相对照，存储在一维数组的相应分量中，0表示不存在此结点。 链式存储结构 二叉链表(数据域，左，右指针域)或者三叉链表(多一个指向双亲结点的链域)。 遍历二叉树构造二叉树 12345678910111213function BinaryNode(value,leftChild,rightChild)&#123; this.value=value; this.lChild=leftChild; this.rChild=rightChild;&#125;var binaryTree = new BinaryNode(\"-\");binaryTree.leftChild = new BinaryNode(\"10\");binaryTree.rightChild = new BinaryNode(\"7\");function visit(binaryNode)&#123; if (binaryNode.value) &#123; console.log(binaryNode.value); &#125;&#125; 递归先序遍历 12345678preOrderVisit(binaryTree);function preOrderVisit(binaryTree)&#123; if (binaryTree) &#123; visit(binaryTree); preOrderVisit(binaryTree.leftChild); preOrderVisit(binaryTree.rightChild); &#125;&#125; 非递归中序遍历 123456789101112131415function InorderVisit(binaryTree)&#123; var stack = []; stack.push(binaryTree); while (stack.length) &#123; while (stack[stack.length-1]) &#123; stack.push(stack[stack.length-1].leftChild); &#125; stack.pop(); if (stack.length) &#123; var tmp = stack.pop(); visit(tmp); stack.push(tmp.rightChild); &#125; &#125;&#125; 12345678910111213function InorderVisit(binaryTree)&#123; var stack = [], tmp = binaryTree; while (tmp || stack.length) &#123; if (tmp) &#123; stack.push(tmp);tmp = tmp.leftChild; &#125;else&#123; tmp = stack.pop(); visit(tmp); tmp = tmp.rightChild; &#125; &#125;&#125; 制造二叉树 1234567891011121314151617//空格用来退出createBiTreevar valArr = [0,1,2,\"\",\"\",\"\",3,4,\"\",5,\"\",\"\",6,\"\",\"\",\"\"];function createBiTree()&#123; //按照先序遍历制造二叉树 while (valArr.length) &#123; var binaryNode; var tmp = valArr.shift(); if (tmp !== \"\") &#123; binaryNode = new BinaryNode(tmp); binaryNode.leftChild = createBiTree(binaryNode.leftChild); binaryNode.rightChild = createBiTree(binaryNode.rightChild); &#125;else &#123; return null; &#125; return binaryNode; &#125;&#125;var test = createBiTree(); 线索二叉树 thread binary tree从上节的讨论可知，遍历二叉树是以一定规则将二叉树中结点排列成一个线性序列。这实质上是一个非线性结构进行线性化操作，使每个结点(除第一个与最后一个)在这些线性序列中有且仅有一个直接前驱和直接后继。 但是，当以二叉链表为结构存储二叉树时，只能找到结点的左右孩子结点，而不能直接得到任一结点的直接前驱和后继。 解决方案 原理：在有n个结点二叉树中必然会有n+1个空链域,利用这n+1个空链域存储前继后继信息。 故可以在左右孩子指针上新增一个布尔值标识，当左链域指向左孩子结点时为0，当指向前区时为1。 以这种结点结构构成的二叉链表作为二叉树的存储结构，叫做线索链表。 中序遍历双向线索表12345678910111213141516171819202122232425262728function BinaryThrNode(obj) &#123; this.val = obj.value || null; this.lChild = obj.lChild || null; this.lTag = obj.lTage || 0; //0表示指向结点，1表示线索 this.rChild = obj.rChild || null; this.rTag = obj.rTag || 0;&#125;function visit(binaryNode)&#123; if (binaryNode.val) &#123; console.log(binaryNode.val); &#125;&#125;// 对双向线索表进行中序遍历function InOrderTraverse(biThrTree)&#123; //biThrTree指向头结点 var tmp = biThrTree.lChild; while (tmp!==biThrTree) &#123; while (!tmp.lTag) &#123; tmp = tmp.lChild; &#125; visit(tmp); while (tmp.rTag &amp;&amp; tmp!==biThrTree) &#123; tmp=tmp.rChild; visit(tmp); &#125; tmp=tmp.rChild; &#125; return biThrTree;&#125; 线索化二叉树12345678910111213141516171819202122232425262728293031323334//线索化二叉树function InOrderThreading(biThrTree,biTree)&#123; biThrTree = new BinaryThrNode(); biThrTree.lChild = biTree; biThrTree.rTag = 1; biThrTree.rChild = biThrTree; if (!biTree) &#123; biThrTree.lTag = 1; biThrTree.lChild = biThrTree; &#125;else &#123; biThrTree.lChild = biTree; var pre = biThrTree; InThreading(biTree); pre.rChild = biThrTree; pre.rTag = 1; biThrTree.rChild = pre; &#125; return biThrTree;&#125;function InThreading(binaryNode)&#123; if (binaryNode) &#123; InThreading(binaryNode.lChild); if (!binaryNode.lChild) &#123; binaryNode.lTag = 1; p.lChild = pre; &#125; if (!pre.rChild) &#123; pre.rTag = 1; pre.rChild = binaryNode; &#125; InThreading(binaryNode.rChild); &#125;&#125; 赫夫曼树及其应用赫夫曼树又称最优树，是一种带权路径长度最短的树。 最优二叉树树的路径长度是从树的根到每一个结点长度的和。 树的带权路径长度为树中所有叶子结点的带权路径长度之和。 根据n个权值{w1, w2, ⋯,wn}，构造成n棵二叉树的集合F={T1, T2, ⋯,Tn}，其中每棵二叉树只有一个权值为wi的根结点，没有左、右子树； 在F中选取两棵根结点权值最小的树作为左、右子树构造一棵新的二叉树，且新的二叉树根结点权值为其左、右子树根结点的权值之和； 在F中删除这两棵树，同时将新得到的树加入F中； 重复2，3，直到F只含一棵树为止。 构造Huffman树时，为了规范，规定F={T1,T2, ⋯,Tn}中权值小的二叉树作为新构造的二叉树的左子树，权值大的二叉树作为新构造的二叉树的右子树；在取值相等时，深度小的二叉树作为新构造的二叉树的左子树，深度大的二叉树作为新构造的二叉树的右子树。 赫夫曼编码若要设计长短不等的编码，则必须是任一个字符的编码都不是另一个字符的编码的前缀，这种编码称为前缀编码。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758// 赫夫曼树和赫夫曼编码的存储结构function HuffmanNode(weight, parent, leftChild, rightChild) &#123; this.weight = weight || 0; this.parent = parent || 0; this.leftChild = leftChild || 0; this.rightChild = rightChild || 0;&#125;// 创建一棵叶子结点数为n的Huffman树function buildHuffmanTree(weights, n) &#123; n = n || weights.length; var m = 2 * n - 1; var huffmanTree = []; // 初始化 for (var i = 0; i &lt; n; i++) huffmanTree[i] = new HuffmanNode(weights[i], 0, 0, 0); for (; i &lt; m; i++) huffmanTree[i] = new HuffmanNode(0, 0, 0, 0); for (i = n; i &lt; m; i++) &#123; // 在HT[1..i-1]选择parent为0且weight最小的两个结点，返回其序号为[s1, s2] var ret = select(huffmanTree, i); var s1 = ret[0]; var s2 = ret[1]; huffmanTree[s1].parent = i; huffmanTree[s2].parent = i; huffmanTree[i].leftChild = s1; huffmanTree[i].rightChild = s2; huffmanTree[i].weight = huffmanTree[s1].weight + huffmanTree[s2].weight; &#125; return huffmanTree;&#125;function select(huffmanTree, len) &#123; var ret = []; for (var i = 0; i &lt; len; i++) &#123; var node = huffmanTree[i]; if (node.parent !== 0) continue; if (ret.length &lt; 2) &#123; ret.push(i); &#125; else &#123; var index = huffmanTree[ret[0]].weight &gt; huffmanTree[ret[1]].weight ? 0 : 1; if (node.weight &lt; huffmanTree[ret[index]].weight) ret[index] = i; &#125; &#125; if (ret[0] &gt; ret[1]) &#123; var temp = ret[0]; ret[0] = ret[1]; ret[1] = temp; &#125; return ret;&#125; 参考资料 javascript实现数据结构： 树和二叉树,二叉树的遍历和基本操作 树和二叉树的应用","categories":[{"name":"数据结构","slug":"数据结构","permalink":"https://sfegsq.github.io/categories/数据结构/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"},{"name":"数据结构","slug":"数据结构","permalink":"https://sfegsq.github.io/tags/数据结构/"}]},{"title":"webpack替代fekit的折腾小记","slug":"webpack替代fekit的折腾小记","date":"2016-01-23T04:53:23.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/01/23/webpack替代fekit的折腾小记/","link":"","permalink":"https://sfegsq.github.io/2016/01/23/webpack替代fekit的折腾小记/","excerpt":"前言早就想尝试webpack的，却一直没有时间，恰逢周末，又时值最近在公司实习的时候尝到用fekit做模块化的构建工具的爽。所以就开始以公司的项目结构去使用webpack的，当然最后还是有点问题的，只能折中解决了。公司的方案是前后端完全分离，html代码放在后端服务器上，css，js，images等资源文件放在前端服务器，两者是不同的域名。问过之后，才知道原来是因为，js每次请求会带上cookie，增加了不必要的带宽，所以将其放在前端服务器上，因为script的标签可以跨域引用(这也是jsonp的原理)。 所以主要的目录结构大概是，当然我说的折中是把html直接放进了prd文件夹下，这个之后要说明原因。","text":"前言早就想尝试webpack的，却一直没有时间，恰逢周末，又时值最近在公司实习的时候尝到用fekit做模块化的构建工具的爽。所以就开始以公司的项目结构去使用webpack的，当然最后还是有点问题的，只能折中解决了。公司的方案是前后端完全分离，html代码放在后端服务器上，css，js，images等资源文件放在前端服务器，两者是不同的域名。问过之后，才知道原来是因为，js每次请求会带上cookie，增加了不必要的带宽，所以将其放在前端服务器上，因为script的标签可以跨域引用(这也是jsonp的原理)。 所以主要的目录结构大概是，当然我说的折中是把html直接放进了prd文件夹下，这个之后要说明原因。 1234+html+src+prd+fekit-module 安装首先，你需要安装了node.js 第一步，全局安装npm install webpack -g 第二步，初始化package.json信息，这个可以直接回车到底npm init 第三步，局部安装webpack，添加依赖到package.json疑问：没有使用过相关构建工具的小伙伴，肯定疑惑。为什么全局安装后还需要局部安装？ 原因：每个项目需要的依赖不同，如果都安装在全局，那么不同项目我们就无法做到定制化的服务，而是大锅粥式的服务，无法满足高效生产的目标。所以需要局部安装。 npm install webpack --save-dev //--save-dev 添加依赖到package.json 如何使用依赖？ 当你再兴建一个文件的时候，就不需要一个个插件安装了，将package.json文件复制到当前文件下，并输入npm install，即通过package.json里的依赖关系，自动把依赖安装好了。当然，其他文件结构还是要自己新建。这里提供一下我的package.json文件。Javascript { “name”: “angular”, “version”: “0.0.0”, “description”: “practice”, “main”: “gulpfile.js”, “scripts”: { “test”: “echo \\”Error: no test specified\\” &amp;&amp; exit 1” }, “author”: “”, “license”: “BSD-2-Clause”, “devDependencies”: { “webpack”: “~1.12.11”, “style-loader”: “~0.13.0”, “extract-text-webpack-plugin”: “~1.0.1”, “file-loader”: “~0.8.5”, “url-loader”: “~0.5.7”, “css-loader”: “~0.23.1” } } 第四步 新建配置文件默认的配置文件在项目目录下为 webpack.config.js。 简单的操作可以参看下面这个文档。 《Webpack 中文指南》 恭喜入坑完成，上面四步，可以说你就已经走进了webpack的大门了。 但是，要想个性化的定制服务，理解每一个参数～ 查看了许多博客，讲的都差不多，都不是非常深入。所以，还是得去看官方文档 webpack 参数真的是非常多，一个个把认为会用到的敲过去，调了调，试了试。 接下来，本文，根据自己的学习历程，讲下我用到的重要部分，首先贴一下，项目结构，和配置文档。 12345678910111213141516171819202122232425262728293031323334353637383940414243-app +node_modules -prd +html +css +js +images -src +css+js +images -gulpfile.js -webpack.config.js -README.md var webpack = require('webpack');var ExtractTextPlugin = require(\"extract-text-webpack-plugin\");module.exports = &#123; context: __dirname + \"/src\", entry: &#123; test:[\"./js/test.js\",\"./js/test1.js\"] test2:\"./js/test2.js\", &#125;, output: &#123; path: __dirname + \"/prd\", publicPath: \"../\", filename: \"js/[name].js\" &#125;, module: &#123; loaders: [ &#123; test: /\\.css$/, loader: ExtractTextPlugin.extract(\"style-loader\", \"css-loader\")&#125;, &#123; test: /\\.json$/, loader: \"json\"&#125;, &#123;test: /\\.html$/, loader: \"html\"&#125;, &#123; test: /\\.(gif|jpg|png|woff|svg|eot|ttf)\\??.*$/, loader: 'url-loader?limit=50000&amp;name=[path][name].[ext]'&#125; ] &#125;, plugins: [ new ExtractTextPlugin(\"css/[name].css\"), ] &#125; 参数说明因为webpack是基于node.js所有，采用的是common.js的写法，common.js具体语法我在这里就不解释了。 首先，webpack是需要定义输入与输出文件的，entry为输入，output为输出。 context这个是输入entry的上下文环境，__dirname代指整个项目路径，即directory name。我的项目结构中，开发目录是src，所有在__dirname后面，加上路径的 /src。 entry列出输入的文件 entry: { test:[“./js/test.js”,”./js/test1.js”], test2:”./js/test2.js”, }, entry有三种定义方式，第一个直接一个字符串路径名，代表唯一一个输入；第二个一个数组代表多个文件对应一个输出，第三种，如上写，以字面对象量的方式，test，test2总共对应着3个输入2个输出。 output12345output: &#123; path: __dirname + \"/prd\", publicPath: \"../\", filename: \"js/[name].js\"&#125;, path和entry的一样。代表所有文件输出时的前缀路径。 这里要加重了publicPath: &quot;../&quot;,这个属性一直没重视，认为这个和path应该是一样一样的，为何还要多设置一个，所有一开始，我是只设置了path，并没有设置publicPath的。那么这里为什么设置了publicPath: &quot;../&quot;,呢。 我们通过一个例子来说明原因。123456789101112131415161718192021222324div &#123; background-image: url(../images/test/icon.jpg);&#125; //我在src目录下的css文件夹中的index.css中设置背景图片require(../images/icon.png) //我在src目录下的js文件的index.js中引入图片var img = require('../images/test/icon.jpg');document.getElementById('image').setAttribute('src', img);&lt;!DOCTYPE html&gt; //prd下的html文件夹中的indexhtml代码&lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;test&lt;/title&gt; &lt;link href=\"../css/test.css\"&gt; &lt;/head&gt; &lt;body&gt; &lt;div id=\"test\"&gt; test &lt;/div&gt;&lt;img src=\"\" id=\"image\" /&gt;&lt;script src=\"../js/test.js\"&gt;&lt;/script&gt; &lt;/body&gt;&lt;/html&gt; 如上所述，我用css与js两种方式引入图片。只是在src中的话，那样是没有问题的，但要是在prd中，因为prd为打包后文件。对于这些地址的处理，是没有太多介绍的，所有只能一个个试。如果我不加publicPath: &quot;../&quot;,的话，那么这些图片对应的路径 __dirname/prd/css/images/test/icon.png /第一种 __dirname/prd/html/images/test/icon.png//第二种 __dirname/prd/images/test/icon.png //正确路径 所以问题出在了webpack打包的时候，处理地址的时候会将前面”../“给消除了，所有你再到chrome里看他是他的地址是 images/test/icon.jpg，没有前面哪个../,当然了，我的研究也暂时只到这里，你能够通过public设置../来达到目的。而我之所以把html放入prd中，而不是直接在项目目录下，也是因为这个～放在项目目录下，这个publicPath路径就没法统一了，所有只能先折中一下，将html也放入prd中。这样上述的图片就应该正常显示了。但是这样的话，也就达不到我想做的前后端完全分离的效果了，所有，这里先留下一笔，折腾了一天，还没找到解决方案。 filename: &quot;js/[name].js&quot; 这个是设置输出路径在紧接着前面path与publicPath两个深一层的 设置，这个对应着entry的输入文件，name就是entry对象里的键值名，即test，test2。 loader大体上module里面，我暂时用到的只有loaders，所有这里只讲解loaders。12345678910module: &#123; loaders: [ &#123; test: /\\.css$/, loader: ExtractTextPlugin.extract(\"style-loader\", \"css-loader\")&#125;, &#123; test: /\\.json$/, loader: \"json\"&#125;, &#123;test: /\\.html$/, loader: \"html\"&#125;, &#123; test: /\\.(gif|jpg|png|woff|svg|eot|ttf)\\??.*$/,loader: 'url-loader?limit=50000&amp;name=[path][name].[ext]'&#125; ]&#125;, loaders是一个数组，数组里是对每种文件的打包处理。因为webpack本身只支持js打包的处理，所有我们要是想把css，json，html，图片一起打包了，就得另外下各种各样的加载器了。简单说下用法，在我们的entry的入口js文件中，require(../images/icon.png)既可以引入一个png格式的文件，此时，webpack打包时，会检测require的文件，并采用对应的规则去解析，如果你没有对应的加载器就会报错，这里我们引入了url-loader，所以他会正确解析打包。 (url-loader用法，url-loader?这里的？表示query查询的意思，后面跟的是规则，当文件大小小于50kb的时候，采用base64格式，如果大于50kb则采用链接) 不得不说，大部分加载器的说明文档还是太简单了，寥寥几句，暂时还不知道如何高度的定制化需求。list of loaders testtest中对应的是一个正则表达式，没有什么好说的，不知道的可以找相关的文档看看，也可以点我这篇博客看看正则表达小结与小知识点集锦 loaderloader对应的就是，匹配该规则时指定的加载器，比如匹配到json文件时，采用“json”加载器，全称是”json-loader”，当然简称也没有问题。至于css中那个是一个额外的插件，表示匹配到css时采用这个插件，至于插件的声明与用法，请看下面的参数。 plugins plugins: [ new ExtractTextPlugin(&quot;css/[name].css&quot;), ] plugins 是插件的声明与用法，首先用new实例化一个插件，参数是一个地址规则的字符串，表示把require的css文件输出的地址。插件也有许多，想要高度定制需求，肯定是要结合插件与加载器的。list of plugin 使用相关使用的时候，直接到项目目录下，使用webpack就会自动执行。当然，输入webpack -w每次更改后会自动执行。另外webpack提供node.js的服务器供调试。满复杂的文档，看花了。webpack-dev-server 安装 npm install webpack-dev-server --save-dev 执行 webpack-dev-server好了，使用的时候，还有许多其他的小细节，可以去探索 。当然大部分时候有这些也足够了。感兴趣的可以继续去探索 结语其实，如果不喜欢折腾也可以来尝试一下fekit，学习成本较低，并且非常强大。前端构建工具fekit文中有什么纰漏，欢迎大家指出～","categories":[{"name":"前端","slug":"前端","permalink":"https://sfegsq.github.io/categories/前端/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"}]},{"title":"innerHTMLVScreateElement","slug":"innerHTMLVScreateElement","date":"2016-01-21T04:49:25.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/01/21/innerHTMLVScreateElement/","link":"","permalink":"https://sfegsq.github.io/2016/01/21/innerHTMLVScreateElement/","excerpt":"两者生成dom的方式有什么优劣呢？首先让我们看一个小问题再引入正题～","text":"两者生成dom的方式有什么优劣呢？首先让我们看一个小问题再引入正题～ 如何重复插入一个相同的html结构呢？1234567//错误的window.onload = function()&#123;var el = document.createElement('div');el.appendChild(document.createTextNode('Hi'));for (var i = 10; i &gt; 0; --i)document.body.appendChild(el);&#125;; //同一元素无法重复插入， 1234567//正确的 同时注意不要设置插入多次的元素的id,否则造成错误window.onload = function()&#123;var el = document.createElement('div');el.appendChild(document.createTextNode('Hi'));for (var i = 10; i &gt; 0; --i)document.body.appendChild(el.cloneNode(true));&#125;; 上述之所以要用clone，是因为当时我的需求是克隆一个复杂的html结构，而并非生成一个简单的dom元素。 重排与重绘上述方法，虽然能够成功生成相同的dom元素，但是性能上是存在问题的。每次插入dom元素到body后，dom树会重排，之后页面会因为新的dom元素的插入而重新绘制，这两个过程是极其耗时的。因此，推荐使用文档碎片document.createDocumentFragment()。 使用方法 123456789//利用文档碎片 提高性能 frag相当于一个容器 frag并不会插入body而是把frag的内部元素全部插入bodywindow.onload = function()&#123;var frag = document.createDocumentFragment();var el = document.createElement('div');el.appendChild(document.createTextNode('Hi'));for (var i = 10; i &gt; 0; --i)frag.appendChild(el.cloneNode(true)); //先将生成的dom全部插入frag先，这个过程并不会触发重排与重绘&#125;;document.body.appendChild(frag); //将生成的frag插入body中，将10此重排重绘的过程压缩为一次 接下来，进入正题的比较 innerHTML vs createElement生成Dom的两种方式，孰优孰劣呢？就我们的经验看来，innerHTML这种采用字符串拼接生成dom的方式似乎更加方便，并且效率更高。但是那原生的createElement又有什么优势呢？以下，优势观点来自于stack overflow的言论，翻译的也不一点准确，欢迎探讨。 createElement，当元素插入后仍然保留对dom元素的指针。而innerHTML插入后，并没有对dom元素的指针，你需要再通过getElementById重新选取。 createElement能够获得事件处理函数，而innerHTML生成的新dom无法获得原先设置的事件处理函数。 某些情况下，createElement更加快速。如果你需要反复操作字符串，在每次处理后再次插入。每次插入都将进行解析与制作dom，在性能上会很差。 可读性与可维护上createElement会优秀一些 下面提供一段封装好了的让你方便的使用createElement的函数123456789101112131415161718192021222324252627282930313233function isArray(a) &#123; return Object.prototype.toString.call(a) === \"[object Array]\";&#125;function make(desc) &#123; if (!isArray(desc)) &#123; return make.call(this, Array.prototype.slice.call(arguments)); &#125; var name = desc[0]; var attributes = desc[1]; var el = document.createElement(name); var start = 1; if (typeof attributes === \"object\" &amp;&amp; attributes !== null &amp;&amp; !isArray(attributes)) &#123; for (var attr in attributes) &#123; el[attr] = attributes[attr]; &#125; start = 2; &#125; for (var i = start; i &lt; desc.length; i++) &#123; if (isArray(desc[i])) &#123; el.appendChild(make(desc[i])); &#125; else &#123; el.appendChild(document.createTextNode(desc[i])); &#125; &#125; return el;&#125; 使用方式 make([&quot;p&quot;, &quot;Here is a &quot;, [&quot;a&quot;, { href:&quot;http://www.google.com/&quot; }, &quot;link&quot;], &quot;.&quot;]); 你会得到这样一个html结构 &lt;p&gt;Here is a &lt;a href=&quot;http://www.google.com/&quot;&gt;link&lt;/a&gt;.&lt;/p&gt; 综上，两者各有各的好处。无疑，在大多数情况下，innerHTML更为快速且更加易用，但是使用innerHTML的时候小心上述的那个问题就好。 Advantages of createElement over innerHTML? Advantages of createElement over innerHTML? JavaScript: Is it better to use innerHTML or (lots of) createElement calls to add a complex div structure?","categories":[{"name":"前端","slug":"前端","permalink":"https://sfegsq.github.io/categories/前端/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"}]},{"title":"正则表达小结与小知识点集锦","slug":"正则表达小结与小知识点集锦","date":"2016-01-16T01:02:22.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2016/01/16/正则表达小结与小知识点集锦/","link":"","permalink":"https://sfegsq.github.io/2016/01/16/正则表达小结与小知识点集锦/","excerpt":"背景介绍 这几天，刚来公司，导师安排点任务增加些功能，以便熟悉了开发环境。接到的任务中，有一个环节需要处理一个业务的json数据，具有多级嵌套，我要做的是让使用者可以修改其中的”userName”。 有两个思路 利用正则表达式进行匹配替代 利用遍历修改键值 当然，看到两个思路的高下，在大部分情况下都是可以直接得出结论的，正则肯定是优于遍历的。","text":"背景介绍 这几天，刚来公司，导师安排点任务增加些功能，以便熟悉了开发环境。接到的任务中，有一个环节需要处理一个业务的json数据，具有多级嵌套，我要做的是让使用者可以修改其中的”userName”。 有两个思路 利用正则表达式进行匹配替代 利用遍历修改键值 当然，看到两个思路的高下，在大部分情况下都是可以直接得出结论的，正则肯定是优于遍历的。 正则表达式小结创建方式 直接量语法/pattern/attributes 创建RegEx对象的语法new RegExp(pattern,attributes) 语法属性说明：pattern我们写的正则表达式的规则，而attributes则是规则的修饰符，g为全局匹配，i为区分大小写的匹配，m为多行匹配。 语法括号用于查找某个范围内的字符 12345[acg] //匹配acg任一项即可[^acg]//匹配acg之外的任何一个字符[a-z] //匹配a到z 26个小写字母的任何一个即可[A-Z] //匹配A到Z 26个大写字母的任何一个即可(red|blue|green) //匹配red或者blue或者green任何一个即可 元字符拥有特殊含义的字符 123456. //查找单个字符，除了换行以及行结束符\\w //查找单词字符\\W //查找非单词字符\\d //查找数字\\D //查找非数字\\xxx //查找八进制书xxx规定的字符 量词描述规则执行的次数要求以及位置要求 12345678910n+ //匹配任何包含至少一个n的字符串n? //匹配任何包含零个或者一个n的字符串n* //匹配包含任一个n的字符串n&#123;x,y&#125; //匹配包含x到y次n的字符串^n //匹配开头含有n的字符串n$ //匹配结尾有n的字符串?=n //匹配任何其后紧跟指定字符串n的字符串?!n //匹配任何其后没有紧跟字符串n的字符串\\b //匹配一个字边界，即字与空格间的位置\\B //非字边界匹配 方法RegExp的方法 compile 编译正则表达式 exec 执行正则表达式，并返回找到的值与位置 test 检测是否真的含有符合正则表达式的字符串，返回布尔值 String对象的方法 search 检索与正则表达式相匹配的值 match 找到一个或者多个正则表达式的匹配 replace 替换与正则表达式相匹配的子串 split 把字符串分割为字符串数组 小知识点集锦子表达式一个正则表达式可分为许多子表达式例子：利用子表达式可以将通用资源指示符 (URI) 分解为其组件。假定您想将下面的 URI 分解为协议（ftp、http 等等）、域地址和页/路径 1234567891011121314var test = http://www.w3cschool.cc:80/html/html-tutorial.html;/\\w+:\\/\\/[^/:]+:\\d*?[^# ]*/.exec(test) //只可以匹配到链接//输出结果[\"http://www.w3cschool.cc:80/html/html-tutorial.html\", index: 0, input: \"http://www.w3cschool.cc:80/html/html-tutorial.html\"] /(\\w+):\\/\\/([^/:]+)(:\\d*)?([^# ]*)/.exec(test) //不仅可以匹配到链接，还可以把链接分为各个部分输出//输出结果[\"http://www.w3cschool.cc:80/html/html-tutorial.html\", \"http\", \"www.w3cschool.cc\", \":80\", \"/html/html-tutorial.html\", index: 0, input: \"http://www.w3cschool.cc:80/html/html-tutorial.html\"] 贪婪的量词 ? * + 三者都是贪婪的 因为他们会尽可能多的匹配字符串，只要在他们后面再加一个？就可以实现非贪婪或者最小匹配实例如下 12345&lt;h1&gt;Hello world!&lt;h1&gt;//下面的表达式匹配从 &lt; 到关闭h1标记的 &gt;之间的所有内容/&lt;.*&gt;///如果你只需要匹配开始的h1标记，下面的非贪婪表达式只匹配&lt;h1&gt;/&lt;.*?&gt;/ 圆括号的副作用消除圆括号有一个副作用，那就是相关匹配会被缓存，此时可在在圆括号中加上?:在写正则表达式 1/(?:&lt;.*&gt;)/ String.match(/&lt;.+&gt;/g) 与 RegExp.exec(string)的区别不得不说这个是让我迷惑的很久的坑 String.match(/&lt;.+&gt;/g)这个是字符串方法，返回数组，包括与正则表达式匹配的第一个或者所有字符串，是否返回多个值由修饰符g决定（不返回子表达式的匹配结果） RegExp.exec(string)这个是正则表达式对象的特有方法，返回一个数组。数组包含：正则表达式匹配到的第一个字符串，各个子字符串匹配到的字符串，另外还有两个键值index与input，分别输出匹配到的字符串的第一个字符的位置与被检测的字符串。所以想要输出()的子字符串匹配的字符串必须要用exec，(?:)同样也只要在用exec的时候才能检测到效果。 RegExp.exec(string) 总结介绍 这个可以取到各个子表示的结果，并且可以返回对应的index值。拥有非常大的想象空间。比如我想获取&quot;userName&quot;：&quot;test&quot;的值使用match，我们需要先匹配整个键值对，再对这个键值对进行处理才能取到键值。而使用exec，通过子表达式，我们则直接可以获取到键值。 当然，exec有个蛋疼的地方是只能取到第一个匹配的字符串，也就是说修饰符g设置没设置对他来说都一样。 那我们如何用exec来全局匹配呢？ 首先，我们来了解一下exec的一个特殊地方 当exec执行全局匹配模式时，exec的行为就略有变化。这时它会定义lastIndex属性，以指定下一次执行匹配时开始检索字符串的位置。在找到了与表达式相匹配的文本之后，exec方法将把正则表达式的lastIndex属性设置为下一次匹配执行的第一个字符的位置。也就是说，可以通过反复地调用exec方法来遍历字符串中的所有匹配文本。当exec再也找不到匹配的文本时，将返回null，并且把属性lastIndex重置为0。 12345678910var s = \"Hello world Hello world\"; // 测试使用的字符串直接量var r = /Hello/g; // 匹配模式 一定要加上修饰符gwhile((a = r.exec(s)) != null)&#123; // 循环执行匹配操作 console.log(a); console.log(r.lastIndex); /* 显示每次匹配操作时返回的结果数组信息*/&#125; 测试结果 1234[\"Hello\", index: 0, input: \"Hello world Hello world Hello world\"]5[\"Hello\", index: 12, input: \"Hello world Hello world Hello world\"]17 bingo，完成全局匹配。注意正则表达式，一定要加上修饰符g。要不然lastindex并不会改变，循环会始终为真，不断执行。 结语这篇小结，也是花了好几个小时去查资料，测试最后写出来的，之前也看过许多正则的资料，却始终停留在看看，认为知道了，每次想起来的时候，又都忘了，前几天，用的时候就手忙脚乱的边查资料边coding。终于认识到了自己的学习方式给自己带来的深刻问题。 其实，走上技术的路，时间也不短了。但确实在技术学习的路上，有许多观点，随着时间与自身情况的变化，并未及时的更新。 曾经，在决定未来走向的时候，为了海量的获取信息来看到更远的未来，从而找寻一条能够坚定走下路。读书与阅读的时候，采用快速阅读的方式，不去细细咀嚼，只觉得看过一遍，迅速了解扩展视野，了解更多的东西就好。开始的时候，这种方式为我建立了认知，获得了远大于自身水平的视野。但是视野不曾有技术的支撑，只是一幢危楼而已。行之今日，这种学习方式暴露的问题，越来越大。后来，虽有意识，却不曾有动力予以改正。 幸得近来被人指正，得以真正意识到问题的严重性。 非自己所研究的方向，有一定认识就好，用不着过度深入，采用快速阅读的方式，自然是极好的。能够快速建立认识。但是真正自己的研究方向，发散性阅读才是更好的方式，对于每个点，都不仅仅局限于理解这一个点，能够另行查阅许多相关的资料，这样的方式，看一本书读懂一本书，并扩展阅读了许多相关的资料。这确实是更为行之有效的技术学习方式。而不像之前的方式，看似读过，却处处有漏洞，不曾真正的读透一本书，希望临到项目，临到业务。再去真正实践，去真正的掌握。是一种极为不靠谱的方式。 学习的方法的重要性，不亚于学习本身，也是值得我们去反思并改进的。 参考资料正则表达式|菜鸟教程W3Cschool正则表达式使用exec增强正则表达式功能","categories":[{"name":"前端","slug":"前端","permalink":"https://sfegsq.github.io/categories/前端/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"}]},{"title":"calc 与 box-sizing 的替代","slug":"calc与box-sizing的替代","date":"2015-12-21T16:00:00.000Z","updated":"2017-01-12T15:13:18.000Z","comments":true,"path":"2015/12/22/calc与box-sizing的替代/","link":"","permalink":"https://sfegsq.github.io/2015/12/22/calc与box-sizing的替代/","excerpt":"背景之前发现calc这个布局新属性之后就非常喜欢，爱不释手。在公司的实习的时候，开发微信端的页面，使用了几次calc，后来发现在Android的上的不支持～蛋疼。于是到处找替代方案，终于在stackoverflow上找到一个满意的答复，好～接下来进入正文～ calc 与 box-sizing 简单介绍calc 属性calc()能让你给元素的做计算，你可以给一个div元素，使用百分比、em、px和rem单位值计算出其宽度或者高度，比如说“width:calc(50% + 2em)”，这样一来你就不用考虑元素DIV的宽度值到底是多少，而把这个烦人的任务交由浏览器去计算。","text":"背景之前发现calc这个布局新属性之后就非常喜欢，爱不释手。在公司的实习的时候，开发微信端的页面，使用了几次calc，后来发现在Android的上的不支持～蛋疼。于是到处找替代方案，终于在stackoverflow上找到一个满意的答复，好～接下来进入正文～ calc 与 box-sizing 简单介绍calc 属性calc()能让你给元素的做计算，你可以给一个div元素，使用百分比、em、px和rem单位值计算出其宽度或者高度，比如说“width:calc(50% + 2em)”，这样一来你就不用考虑元素DIV的宽度值到底是多少，而把这个烦人的任务交由浏览器去计算。calc()的运算规则： 使用“+”、“-”、“*” 和 “/”四则运算; 可以使用百分比、px、em、rem等单位； 可以混合使用各种单位进行计算； 表达式中有“+”和“-”时，其前后必须要有空格，如”width: calc(12%+5em)”这种没有空格的写法是错误的； 表达式中有“*”和“/”时，其前后可以没有空格，但建议留有空格。 兼容性 浏览器对calc()的兼容性还算不错，在IE9+、FF4.0+、Chrome19+、Safari6+都得到较好支持，同样需要在其前面加上各浏览器厂商的识别符，不过可惜的是，移动端的浏览器还没仅有“firefox for android 14.0”支持，其他的全军覆没。 box-sizing语法1box-sizing ： content-box || border-box || inherit 取值说明 border-box：元素的宽度/高度（width/height）等于元素边框宽度（border）加上元素内边距（padding）加上元素内容宽度/高度（content width/height）即：Element Width/Height = border+padding+content width/height。 content-box：元素的宽度/高度等于元素内容的宽度/高度。兼容性 布局比较相比于box-sizing而言 calc的Android browser的支持性太差了，所以布局的时候，box-sizing可以用来解决calc的问题 1234567891011121314151617181920212223&lt;div class=\"sideBar\"&gt;sideBar&lt;/div&gt;&lt;div class=\"content\"&gt;content&lt;/div&gt;&lt;style&gt; .content &#123; // 使用calc width: 65%； //照顾Android 平稳退化 width: calc(100% - 300px);&#125;//使用box-sizing.sideBar &#123; position: absolute; top:0; left:0; width: 300px;&#125;.content &#123; padding-left: 300px; width: 100%; -moz-box-sizing: border-box; box-sizing: border-box;&#125;&lt;/style&gt; 以上的代码来自于stackoverflow，非常棒的解决方案～ bootstrap中的box-sizing之后在工作中，发现bootstrap的源码有这么一段代码～box-sizing这个货还是非常有用的呀～ 1234567891011* &#123; -webkit-box-sizing: border-box; -moz-box-sizing: border-box; box-sizing: border-box;&#125;*:before,*:after &#123; -webkit-box-sizing: border-box; -moz-box-sizing: border-box; box-sizing: border-box;&#125; 最后记第一篇通过解决自己遇到的问题而来的文章～ 参考资料： CSS3的calc()使用 CSS3 Box-sizing Stackoverflow的问答","categories":[{"name":"前端","slug":"前端","permalink":"https://sfegsq.github.io/categories/前端/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"https://sfegsq.github.io/tags/Javascript/"}]}]}